{"pages":[{"title":"About Me","text":"2019.9- Computer Science and Technology, Shandong University. 2021.7- Computer Architecture &amp; Embedded System Research Center, Shandong University.","link":"/about/index.html"}],"posts":[{"title":"RocksDB和db_bench安装与配置","text":"Start from a new Ubuntu OS. Introduction After remaking N times, I made this blog finally. Let’s start from a new Ubuntu now. Steps Step 1 首先安装gcc、g++等工具。 1sudo apt install build-essential 然后安装一些必要的库，用于RocksDB的Compression。 1sudo apt-get install libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev libgflags-dev Step 2 下载RocksDB源码并解压。 12wget https://github.com/facebook/rocksdb/archive/v6.25.1.zipunzip rocksdb-6.25.1.zip Tips: 版本号可自己选择，下面涉及到版本号的命令需要对应更改。e.g. v6.6.4 (2020-01-31) 此过程需要的时间可能较长，可以通过其他方法下载zip压缩包，拷贝至Ubuntu系统。(Recommended) 如果压缩包名字略有不同，自行更改。 Step 3 编译生成动态链接库和静态链接库 123cd rocksdb-6.25.1make shared_lib &amp;&amp; sudo make install-sharedmake static_lib &amp;&amp; sudo make install-static Tips: 如果先生成静态链接库再生成动态链接库，在生成动态链接库的时候会报错。 12make static_lib &amp;&amp; sudo make install-staticmake shared_lib &amp;&amp; sudo make install-shared 解决办法如下： 123make cleanmake shared_libmake static_lib 此过程需要的时间较长（约10min）。 最后执行sudo make install命令。 1sudo make install Step 4 设置环境变量 123#echo &quot;/usr/local/lib&quot; |sudo tee /etc/ld.so.conf.d/rocksdb-x86_64.confsudo ldconfig -vmake shared_lib &amp;&amp; sudo make install-sharedsudo ldconfig -v Tips: #echo &quot;/usr/local/lib&quot; |sudo tee /etc/ld.so.conf.d/rocksdb-x86_64.confsudo ldconfig -v: refresh the ldconfig cacheINSTALL_PATH=/usr sudo ldconfig -v: refresh the ldconfig cache Test 新建测试程序rocksdbtest.cpp 12345678910111213141516171819202122232425262728293031323334353637#include &lt;cstdio&gt;#include &lt;string&gt;#include &quot;rocksdb/db.h&quot;#include &quot;rocksdb/slice.h&quot;#include &quot;rocksdb/options.h&quot;using namespace std;using namespace rocksdb;const std::string PATH = &quot;/tmp/rocksdb_tmp&quot;;int main() { DB* db; Options options; options.create_if_missing = true; Status status = DB::Open(options, PATH, &amp;db); assert(status.ok()); Slice key(&quot;foo&quot;); Slice value(&quot;bar&quot;); std::string get_value; status = db-&gt;Put(WriteOptions(), key, value); if(status.ok()) { status = db-&gt;Get(ReadOptions(), key, &amp;get_value); if(status.ok()) { printf(&quot;get %s success!!\\n&quot;, get_value.c_str()); } else { printf(&quot;get failed\\n&quot;); } } else { printf(&quot;put failed\\n&quot;); } delete db;} 动态编译 1g++ -std=c++11 -o rocksdbtest rocksdbtest.cpp -lrocksdb -lpthread 执行 1./rocksdbtest 正确结果 1get bar success!! db_bench 1make clean 1make db_bench 1./db_bench Tips: 运行db_bench时设置参数 e.g.1./db_bench -benchmarks=&quot;fillrandom,stats&quot; -statistics -key_size=16 -value_size=65536 -db=./test_db1 -wal_dir=./test_db1 -duration=6000 -level0_file_num_compaction_trigger=1 -enable_pipelined_write=true -compression_type=None -stats_per_interval=1 -stats_interval_seconds=10 -max_write_buffer_number=6 Reference https://blog.51cto.com/u_15081048/2592774 https://www.jianshu.com/p/575b2e27b028 https://blog.csdn.net/zhangpeterx/article/details/96869454 https://www.cxyzjd.com/article/zhangpeterx/96869454","link":"/2021/10/14/Embedded/db-bench/"},{"title":"Visual Studio Code环境配置和使用技巧","text":"This is different from most blogs and videos about the configuration for vscode and it takes only 2 minutes starting from zero. Overview 无数的博客和视频都在讲怎么配置vscode的环境，但99%都会教你怎么copy他们在用的json文件，解释一大通有的没的，不是说json文件的含义不重要，只是作为一个beginner关注点不在这里，而是我怎么配才能跑出来一个Hello World。横向对比不同博客提供的json文件，你会发现千差万别，然后开始怀疑到底谁的json文件是对的或者纠结到底用谁的… 这篇博客不会摆长篇的json文件让你copy，而是让你通过vscode的选项生成json文件，以最快的速度能够在vscode中run code successfully，最后根据自己的需要修改一些json文件的配置选项。 Windows:下载mingw，添加环境变量，然后在文件夹下新建测试文件，点击运行和调试，在弹出的窗口中直接选择gcc或g++即可自动生成json文件。 Linux:打开Terminal通过sudo apt install安装gcc和g++，然后在文件夹下新建测试文件，点击运行和调试，在弹出的窗口中直接选择gcc或g++即可自动生成json文件。 Windows Step1: 下载MinGW 官网下载地址: MinGW-w64 - for 32 and 64 bit Windows 不同版本区别如下： 这里建议选择x86_64-posix-sehz。下载后，解压到自己常用的软件安装路径下，这里以D盘为例。 Step2: 添加环境变量 1.以windows10为例，右键此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量。 2.找到系统变量下的Path，点击编辑，新建，将bin目录的路径复制即可。 Step3: 生成json文件 1.打开vscode，选择或新建一个空文件夹目录打开作为项目目录。 2.新建test.cpp 123456789#include &lt;iostream&gt;using namespace std;int main(){ cout&lt;&lt;&quot;Hello world!\\n&quot;; getchar(); return 0;} 3.Ctrl+F5以非调试模式运行 4.选择C++(GDB/LLDB) 5.选择g++.exe 点击终端，已经正常运行显示结果。 Step4: 运行和调试 launch.json文件中的 1&quot;externalConsole&quot;: false, // 调试时是否显示控制台窗口，true使用控制台（小黑框），false使用内置终端 若使用控制台，需要在main函数return之前暂停一下，否则小黑框会一闪而过，可以使用stdlib.h库中的system(“pause”)，也可简单地使用getchar()。 若使用内置终端，则会直接在内置的终端输出。 调试过程与其他IDE类似，略。 Hint: 使用freopen重定向输入输出流，可以不用每次都复制一遍输入，或者无法辨别某个数据是输入还是输出（不方便比对正确结果）。 Demo: 插件推荐 1.Code Runner 安装后即可直接运行代码，使用内置终端。一些设置如下： Warning: 一定要将“Run In Terminal”的选项勾上，否则运行之后你找不到任何地方可以输入数据！ 2.Theme Light: Atom one light, Night Owl Light, GitHub Light. Dark: One Dark Pro, Dark+. 3.Icon: Material Icon Theme. 4.filesize: 统计文件大小。 5.gitlens: 方便用git。 Linux 略 真的是非常easy啊！毕竟，一个连虚拟机或者双系统都拥有的人难道还不会配vscode吗？ Update 1.2021-03-27: C17标准不支持#include&lt;bits/stdc.h&gt;，编译时会报一长串错误，C14标准支持，如果想使用这个头文件，可以在json文件中将C标准改为C++14。终于解决了一个困扰已久的问题。 2.2021-04-23：vscode-cpptools占用C盘空间过大问题 vscode-cpptools中是为了加速cpp编译的预编译文件，默认为5120MB约为5G，可以改为512MB（给vscode个面子）或者0（我觉得不过分）。 点击文件-&gt;首选项-&gt;设置-&gt;搜索C_Cpp.intelliSenseCacheSize-&gt;设置大小","link":"/2021/03/20/Configuration/vscode/"},{"title":"MySQL Buffer Pool Design","text":"MySQL存储引擎InnoDB的buffer pool设计思路。 MySQL(InnoDB) buffer pool 配置参数 innodb_buffer_pool_size: buffer pool大小 innodb_buffer_pool_instances: buffer pool实例个数（若bufferpool较大，可划分为多个instances，每个instance通过各自的list独立管理，提高读并发度） innodb_buffer_pool_chunk_size: 当增加或减少innodb_buffer_pool_size时，innodb_buffer_pool_chunk_size相应变化 If the new innodb_buffer_pool_chunk_size value * innodb_buffer_pool_instances is larger than the current buffer pool size when the buffer pool is initialized, innodb_buffer_pool_chunk_size is truncated to innodb_buffer_pool_size / innodb_buffer_pool_instances. Buffer pool size must always be equal to or a multiple of innodb_buffer_pool_chunk_size * innodb_buffer_pool_instances. If you alter innodb_buffer_pool_chunk_size, innodb_buffer_pool_size is automatically adjusted to a value that is equal to or a multiple of innodb_buffer_pool_chunk_size * innodb_buffer_pool_instances. The adjustment occurs when the buffer pool is initialized. innodb_old_blocks_pct: controls the percentage of “old” blocks in the LRU list（LRU链表中插入点的位置） 替换策略：变种LRU 普通LRU会产生的问题：预读失效和缓冲池污染。 预读失效：预先加载的一些page后续没有被访问，反而丢弃了原本LRU链表末尾的一些page。 缓冲池污染：一次性扫描大量数据，buffer pool中所有page被替换出去。 解决方案：冷热数据分离 将LRU链表分为两部分，热数据区和冷数据区。 当某一page第一次被加载到buffer pool中，先将其放到冷数据区域的链表头部。 经过innodb_old_blocks_time（单位：ms）后，若该page再次被访问，将其移动到热数据区域的链表头部。 若page已经在热数据区，再次被访问，不需要每次都移动到热数据区链表头部，MySQL的优化方案是，热数据区的后3/4部分被访问需要移动到链表头部，前1/4部分不移动。 LRU链表 分为两个部分：New Sublist，Old Sublist。 innodb_old_blocks_pct控制插入点Midpoint。 全表扫描时，设置innodb_old_blocks_time的时间窗口可以有效的保护New Sublist。 预读机制 Linear read-ahead Random read-ahead API buf0buf.h: The database buffer pool high-level routines dberr_t buf_pool_init(ulint total_size, ulint n_instances): Creates the buffer pool. void buf_pool_free_all(): Frees the buffer pool at shutdown. void buf_resize_thread(): This is the thread for resizing buffer pool. void buf_pool_clear_hash_index(void): Clears the adaptive hash index on all pages in the buffer pool. static inline ulint buf_pool_get_curr_size(void): Gets the current size of buffer buf_pool in bytes. static inline ulint buf_pool_get_n_pages(void): Gets the current size of buffer buf_pool in frames. get bool buf_page_optimistic_get(ulint rw_latch, buf_block_t *block, uint64_t modify_clock, Page_fetch fetch_mode, const char *file, ulint line, mtr_t *mtr): Get optimistic access to a database page. bool buf_page_get_known_nowait(ulint rw_latch, buf_block_t *block, Cache_hint hint, const char *file, ulint line, mtr_t *mtr): Get access to a known database page, when no waiting can be done. const buf_block_t *buf_page_try_get_func(const page_id_t &amp;page_id, const char *file, ulint line, mtr_t *mtr): Given a tablespace id and page number tries to get that page. buf_block_t *buf_page_get_gen(const page_id_t &amp;page_id, const page_size_t &amp;page_size, ulint rw_latch, buf_block_t *guess, Page_fetch mode, const char *file, ulint line, mtr_t *mtr, bool dirty_with_no_latch = false): Get access to a database page. buf_block_t *buf_page_create(const page_id_t &amp;page_id, const page_size_t &amp;page_size, rw_lock_type_t rw_latch, mtr_t *mtr): Initializes a page to the buffer buf_pool. void buf_page_make_young(buf_page_t *bpage): Moves a page to the start of the buffer pool LRU list. void buf_page_make_old(buf_page_t *bpage): Moved a page to the end of the buffer pool LRU list. static inline ibool buf_page_peek(const page_id_t &amp;page_id): Returns TRUE if the page can be found in the buffer pool hash table. buf0dblwr.h: Doublewrite buffer module buf0rea.h: The database buffer read buf0dump.h: Implements a buffer pool dump/load buf0flu.h: The database buffer pool flush algorithm buf0lru.h: The database buffer pool LRU replacement algorithm Reference MySQL源码 buffer pool API声明 buffer pool API实现 MySQL InnoDB文档","link":"/2021/09/07/Embedded/mysql-buffer-pool-design/"},{"title":"The Use of &quot;(void)val&quot;","text":"Have you ever seen “(void)val” in codes ? Why (void)val 作用是避免编译器警告。如果声明/定义了但未使用的变量，在编译时会生成warning。如果项目里打开了-Werror选项，会将warning视为error，这样的话无法通过编译，所以需要用这种方法绕过无关紧要的warning。","link":"/2021/10/11/Tricks/void/"},{"title":"DSA：（一）递归","text":"递归的核心部分在于找到目标问题的递归部分和基础部分，本文通过求子集和全排列这两个问题来具体分析递归思想的运用。 P1001:子集价值 算法描述 问题包括两个子问题，求子集和序列价值。 求子集：利用标记数组通过0、1标记对应元素是否在子集中，递归部分为从第一个元素开始依次标记，每个元素位置上的标记包括0和1两种情况，通过递归遍历2^n个子集，基础部分为最后一个元素被标记，子集中的元素全部确定。 求序列价值：当子集中的元素确定时，按照标记数组得到子集数组，若标记位为1，子集数组对应元素设置为原数，同时记录子集长度。然后通过子集数组名和子集长度调用价值函数，求出子集价值，返回至上一层。 C++实现代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;int value(T* p,int cnt)//求序列的价值{ if(cnt==0) return 0; T sum=0; for(int i=0;i&lt;cnt;i++) { sum+=(i+1)*p[i]; } return sum;}template &lt;class T&gt;int subset(T* p,int* mark,int pos,int cnt)//求子集价值的异或和{ int res=0,res1=0,res2=0; //基础部分 if(pos==cnt) { int curr[cnt];//当前的子集 int size=0; for(int i=0;i&lt;cnt;i++) { if(mark[i]==1)//mark标记位为1，取该元素 curr[size++]=p[i]; } res=value(curr,size); return res; } //递归部分 mark[pos]=0; res1=subset(p,mark,pos+1,cnt); mark[pos]=1; res2=subset(p,mark,pos+1,cnt); return res1^res2;}int main(){ int n,result=0; cin&gt;&gt;n; int input[n],flag[n]; //输入n个非负整数 for(int i=0;i&lt;n;i++) { cin&gt;&gt;input[i]; } result=subset(input,flag,0,n); cout&lt;&lt;result; return 0;} 结果分析 在求n个元素的所有子集价值的异或和的问题中，分析递归调用时res1和res2的意义，res1表示在当前位置的元素标记为0和之前位置元素的标记的约束下，满足约束条件的所有子集价值的异或和，res2表示在当前位置的元素标记为1和之前位置元素的标记的约束下，满足约束条件的所有子集价值的异或和。例如，对于{1,2}这个集合，递归的执行步骤如下： 设置元素1标记位mark[0]=0 调用subset 设置元素2标记位mark[1]=0 调用subset，res1接收返回值 满足pos==cnt条件，进入基础部分，计算子集价值后返回res 设置元素2标记位mark[1]=1 调用subset，res2接收返回值 满足pos==cnt条件，进入基础部分，计算子集价值后返回res 返回res1^res2 res1接收返回值，即两个子集价值的异或和 设置元素1标记位mark[0]=1 调用subset 设置元素2标记位mark[1]=0 调用subset，res1接收返回值 满足pos==cnt条件，进入基础部分，计算子集价值后返回res 设置元素2标记位mark[1]=1 调用subset，res2接收返回值 满足pos==cnt条件，进入基础部分，计算子集价值后返回res 返回res1^res2 res2接收返回值，即两个子集价值的异或和 返回res1^res2，即4个子集价值的异或和 如果子集函数subset的返回类型设计为void，则需要定义一个全局变量或者在子集函数内部定义一个静态局部变量res来存储子集价值的异或和，每次求出一个子集价值后与res进行异或运算，最后在主函数中直接输出res的结果即可。但是需要注意，在C++中要尽可能少的使用全局变量，所以子集函数的返回类型设计为int更好，通过每一次的值返回可以对递归过程有更深刻的认识。 P1002:全排列问题 算法描述 问题包括两个子问题，求全排列和序列价值。 求全排列：将待求排列的数组分为前缀和后缀，递归部分为通过循环依次将后缀中的每个元素与后缀中的第一个元素交换作为前缀，求剩余后缀的排列，然后复原到交换前的状态。基础部分为后缀仅有一个元素，此时得到一个确定的排列。 求序列价值：当后缀部分仅有一个元素时，此时的排列确定，通过数组名和数组长度调用价值函数，求出子集价值，返回至上一层。 C++实现代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;int value(T *p,int cnt) //求序列价值{ T sum=0; for(int i=0;i&lt;cnt;i++) { sum+=p[i]^(i+1); } return sum;}template &lt;class T&gt;int permutations(T* list,int k,int m,int cnt) //求所有排列价值的或{ int res=0; //基础部分 if(k==m) //仅有一个排列 { res=value(list,cnt); return res; } //递归部分 else //有多于一个的排列 { for(int i=k;i&lt;=m;i++) { swap(list[k],list[i]); //交换 res|=permutations(list,k+1,m,cnt); swap(list[k],list[i]); //复原 } return res; }}int main(){ int n,result=0; cin&gt;&gt;n; int input[n]; //输入n个非负整数 for(int i=0;i&lt;n;i++) { cin&gt;&gt;input[i]; } result=permutations(input,0,n-1,n); cout&lt;&lt;result; return 0;} 结果分析 在求全排列的过程中，递归部分需要注意在进行后缀的每个元素与后缀的第一个元素的交换后，一定要进行复原。res的意义是在已有前缀的约束下，对后缀进行所有排列的价值的或。 这里求全排列的函数permutations的返回类型也可以设计为void,只不过需要定义一个全局变量res，每次求出排列的价值后与res进行或运算,最后在主函数输出res的结果。这样思路上更简单，但是能不用全局变量最好还是不用。","link":"/2020/10/02/CS/DSA/DSA_1/"},{"title":"ffmpeg","text":"ffmpeg常用命令。 常用命令 查看媒体文件详细信息 $ ffmpeg -i video.mp4 转换视频格式flv-&gt;mp4 $ ffmpeg -i input.flv output.mp4 从一个媒体文件移除视频流 $ ffmpeg -i input.mp4 -vn output.mp3 从一个视频文件移除音频流 $ ffmpeg -i input.mp4 -an output.mp4 预览或测试视频或音频文件 $ ffplay video.mp4 $ ffplay audio.mp3 增加视频播放速度 $ ffmpeg -i input.mp4 -vf &quot;setpts=0.5*PTS&quot; output.mp4 减少视频播放速度 $ ffmpeg -i input.mp4 -vf &quot;setpts=4.0*PTS&quot; output.mp4 获取帮助 $ man ffmpeg Reference https://zhuanlan.zhihu.com/p/67878761","link":"/2021/09/27/Tools/ffmpeg/"},{"title":"DSA：（二）排序","text":"本文讲述四种简单排序算法，名次排序、及时终止的选择排序、及时终止的冒泡排序、插入排序。 P1003:排序算法 算法描述 定义排序类，私有成员包括指向动态数组的指针和数组的大小，公有成员包括构造函数，复制构造函数，析构函数，名次排序，及时终止的选择排序，及时终止的冒泡排序，插入排序，输入、输出函数。 名次排序需要计算出元素在序列的名次，即所有比它小的元素个数加上左侧出现的大小相同的元素个数，然后根据元素的名次进行排序，可以使用附加数组，也可以原地重排。 及时终止的选择排序是每次从无序段中找出最大元素，然后和无序段的末端元素进行交换，继续进行下一次排序。在寻找最大元素的过程中，如果判断出无序段已经有序，即每个元素均小于等于后面的元素，排序及时终止。 及时终止的冒泡排序是比较两个相邻元素的大小，将较大的元素交换至后面，每次冒泡过程可将序列中最大的元素调整到末端。如果在冒泡过程中判断出未进行交换，即任意相邻的两个元素均满足前面的元素小于后面的元素，排序及时终止。 插入排序是从序列中的第2个元素开始到第n个元素，每个元素依次作为被插入元素，在前n-1个元素构成的有序段中按照元素大小寻找合适位置进行插入。在寻找插入位置时，通过从后向前寻找，如果当前位置的元素大于被插入元素，当前位置元素后移一个位置，如果当前位置的元素小于等于被插入元素，则将被插入元素插入到当前元素的后一个位置。如果从前向后寻找插入位置，需要额外声明变量存储数据。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class SORT{private: T* pArray; //保存动态数组 int size; //数组大小public: SORT(int s); //构造函数 SORT(const SORT&lt;T&gt;&amp; S); //复制构造函数 ~SORT(); //析构函数 void rank_sort(); //名次排序 void selection_sort(); //及时终止的选择排序 void bubble_sort(); //及时终止的冒泡排序 void insert_sort(); //插入排序 void input(); //输入 void output(); //输出};template &lt;class T&gt;SORT&lt;T&gt;::SORT(int s) //构造函数{ size=s; pArray=new T[size];}template &lt;class T&gt;SORT&lt;T&gt;::SORT(const SORT&lt;T&gt;&amp; S) //复制构造函数{ size=S.size; pArray=new T[size]; for(int i=0;i&lt;size;i++) { pArray[i]=S.pArray[i]; }}template &lt;class T&gt;SORT&lt;T&gt;::~SORT() //析构函数{ delete []pArray;}template &lt;class T&gt;void SORT&lt;T&gt;::rank_sort()//附加数组的名次排序{ //计算名次 int order[size]; //保存名次的数组 for(int i=0;i&lt;size;i++) //初始化 order[i]=0; for(int i=1;i&lt;size;i++) for(int j=0;j&lt;i;j++) if(pArray[j]&lt;=pArray[i]) order[i]++; else order[j]++; T* temp=new T[size]; //附加数组 for(int i=0;i&lt;size;i++) //按照名次排序 temp[order[i]]=pArray[i]; for(int i=0;i&lt;size;i++) //复制 pArray[i]=temp[i]; delete []temp;}template &lt;class T&gt;void SORT&lt;T&gt;::selection_sort() //及时终止的选择排序{ bool sorted=false; //判断是否有序 for(int pos=size;!sorted &amp;&amp; (pos&gt;1);pos--) { int indexOfMax=0; sorted=true; //每次初始化为有序 //查找最大元素 for(int i=1;i&lt;pos;i++) { if(pArray[indexOfMax]&lt;=pArray[i]) indexOfMax=i; else sorted=false; //无序 } swap(pArray[indexOfMax],pArray[pos-1]); }}template &lt;class T&gt;void SORT&lt;T&gt;::bubble_sort() //及时终止的冒泡排序{ bool sorted=false; //判断是否有序 for(int i=0;i&lt;size-1&amp;&amp;!sorted;i++)//size个数最多进行(size-1)次冒泡 { sorted=true; //每次初始化为有序 for(int j=0;j&lt;size-1-i;j++) { if(pArray[j+1]&lt;pArray[j]) { swap(pArray[j],pArray[j+1]); sorted = false; //发生了交换,仍处于无序状态 } } }}template &lt;class T&gt;void SORT&lt;T&gt;::insert_sort() //插入排序{ for(int i=1;i&lt;size;i++) { T t=pArray[i]; //待插入的元素 int j; for(j=i-1;j&gt;=0 &amp;&amp; t&lt;pArray[j];j--) //寻找插入位置 pArray[j+1]=pArray[j]; pArray[j+1]=t; }}template &lt;class T&gt;void SORT&lt;T&gt;::input() //输入{ for(int i=0;i&lt;size;i++) cin&gt;&gt;pArray[i];}template &lt;class T&gt;void SORT&lt;T&gt;::output() //输出{ for(int i=0;i&lt;size;i++) cout&lt;&lt;pArray[i]&lt;&lt;&quot; &quot;;}int main(){ int n; cin&gt;&gt;n; SORT&lt;int&gt; s(n); //创建对象 s.input(); s.bubble_sort(); s.output(); return 0;} 结果分析 （1）名次排序、冒泡排序、插入排序是稳定的，选择排序是不稳定的。 e.g. 给序列3，1，1排序，首先找出最大元素3，和末端的1交换，序列变为1，1，3，满足及时终止的条件，排序结束，两个1的相对位置发生了变化。 （2）在使用for循环进行次数控制时，要注意边界，防止出现数组越界或者排序次数不够的情况。 （3）名次排序、冒泡排序、插入排序、选择排序的时间复杂度都是O(n^2)。 （4）对于名次排序，采用附加数组和原地重排两种方式进行比较，原地重排的最坏执行时间增加了，但是内存占用减少了，用时间换空间。 Postscript 1.排序的稳定性：假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的。 2.排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。例如若将上面的冒泡排序中相邻量元素交换的判定条件改为pArray[j+1]&lt;=pArray[j],则两个相等的元素就会交换位置，从而变成不稳定的排序算法。 3.上面的代码只给出了采用附加数组的名次排序，这里给出原地重排的代码实现。 123456789101112131415161718192021222324template &lt;class T&gt;void SORT&lt;T&gt;::rank_sort()//原地重排数组使之有序{ //计算名次 int order[size]; //保存名次的数组 for(int i=0;i&lt;size;i++) //初始化 order[i]=0; for(int i=1;i&lt;size;i++) for(int j=0;j&lt;i;j++) if(pArray[j]&lt;=pArray[i]) order[i]++; else order[j]++; //原地重排 for(int i=0;i&lt;size;i++) { //把正确的元素移到pArray[i] while(order[i]!=i) { int t=order[i]; swap(pArray[i],pArray[t]); swap(order[i],order[t]); } }}","link":"/2020/10/02/CS/DSA/DSA_2/"},{"title":"DSA：（三）数组描述线性表","text":"本文通过通讯录的实现来分析线性表的数组描述。 P1004:通讯录 要求 1.不要使用STL（可以使用string类）。 2.封装线性表类，提供插入，删除，查找等操作。 3.线性表实现使用数组描述方法（顺序存储结构）。 描述 设通讯录中每一个联系人的内容有：姓名、电话号码、班级宿舍。由标准输入读入联系人信息，使用线性表中操作实现通讯录管理功能，包括：插入、删除、编辑、查找（按姓名查找）；键盘输入一班级，输出通讯录中该班级中所有人的信息。 格式 每个操作的第一个数为操作数(插入：0，删除：1，编辑：2，查找：3，输出一个班所有人员信息：4)，具体格式如下： 123450 姓名 电话 班级 宿舍 //插入一条记录1 姓名 //根据姓名删除一条记录2 姓名 编辑项目 项目新值 //根据姓名编辑一条记录(编辑项目为1到3的整数，1代表编辑电话，2代表编辑班级，3代表编辑宿舍)3 姓名 //根据姓名查找，找到输出1，未找到输出04 班级 //输出该班级的所有成员的宿舍号的异或值 其中查找操作当找到相应的人时输出1，未找到输出0。输出一个班级的人员信息时输出所有成员的宿舍号的异或值。输入数据保证合法。 输入 第一行一个n(1&lt;=n&lt;=20000), 代表接下来操作的数目。接下来n行代表各项操作。 输出 当遇到查找和输出一个班所有人员信息操作时输出。 样例 输入 1234567891011121314151617181920212223242526272829280 Evan 57298577609 1 650 WINNIE 37367348390 4 13 Evan4 63 WINNIE1 Evan4 71 WINNIE3 MARYAM3 CAMERON3 TZIVIA0 OMAR 16447001130 6 554 84 23 JADEN3 ELIZABETH2 OMAR 1 794099055683 JOSHUA2 OMAR 1 89782148171 OMAR3 Azaan3 MARIA0 HANNAH 94060479192 5 983 HEIDY1 HANNAH0 Axel 92066832927 3 701 Axel3 TIFFANY 输出 123456789101112131415161010000000000000 限制 1s 算法描述 定义结构体contact，包含姓名、电话号码、班级、宿舍信息。线性表中的每一个元素都是一个结构体，通过结构体可以访问具体的个人信息。 使用顺序存储结构，封装线性表类AddressList，私有成员包括联系人个数contactSize，一维数组的容量listLength，存储联系人的一维数组element。公有成员包括构造函数，复制构造函数，析构函数，以及具体的方法，包括插入一条信息，根据姓名删除一条记录，根据姓名编辑电话，根据姓名编辑班级或宿舍（与根据姓名编辑电话函数形成重载），根据姓名查找，输出班级所有成员宿舍号的异或值。 读入数据时，按行读入，首先读入操作数instruction，根据操作数利用switch分支进行分类，再根据所属操作类别读入对应的数据，调用对应的成员函数，输出数据。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;stdexcept&gt;using namespace std;struct contact{ string name; //姓名 string telephoneNumber; //电话号码 int classNumber; //班级 int dormitoryNumber; //宿舍};class AddressList{private: int contactSize; //联系人的个数 int listLength; //一维数组的容量 contact* element; //存储联系人的一维数组public: AddressList(int initialCapacity=10); //构造函数 AddressList(const AddressList&amp; s); //复制构造函数 ~AddressList(); //析构函数 void insert(string name, string telephoneNumber, int classNumber, int dormitoryNumber); //插入一条记录 void eraser(string name); //根据姓名删除一条记录 void edit(string name, int num, string telephoneNumber); //根据姓名编辑电话 void edit(string name, int num, int Number); //根据姓名编辑班级或宿舍 int search(string name); //根据姓名查找 int outputClass(int classNumber); //输出班级所有成员宿舍号的异或值};AddressList::AddressList(int initialCapacity) //构造函数{ if(initialCapacity&lt;1) //初始容量小于1，抛出异常 { throw invalid_argument(&quot;InitialCapacity must be positive.&quot;); } listLength=initialCapacity; element=new contact[listLength]; contactSize=0;}AddressList::AddressList(const AddressList&amp; s) //复制构造函数{ listLength=s.listLength; contactSize=s.contactSize; element=new contact[listLength]; for(int i=0;i&lt;contactSize;i++) element[i]=s.element[i];}AddressList::~AddressList() //析构函数{ delete []element;}void AddressList::insert(string name, string telephoneNumber, int classNumber, int dormitoryNumber) //插入一条记录{ if(contactSize==listLength) //数组已满，容量扩大两倍 { contact* Nelement=new contact[listLength*2]; listLength=listLength*2; for(int i=0;i&lt;contactSize;i++) { Nelement[i]=element[i]; } delete []element; element=Nelement; } //在线性表末端(下标为contactSize处)插入一条记录 element[contactSize].name=name; element[contactSize].telephoneNumber=telephoneNumber; element[contactSize].classNumber=classNumber; element[contactSize].dormitoryNumber=dormitoryNumber; contactSize++;}void AddressList::eraser(string name) //根据姓名删除一条记录{ int index=0; //姓名对应的索引 for(int i=0;i&lt;contactSize;i++) { if(element[i].name==name) index=i; } for(int i=index+1;i&lt;contactSize;i++) //向左移动元素 { element[i-1]=element[i]; } element[--contactSize].~contact(); //联系人个数-1,析构无效元素}void AddressList::edit(string name, int num, string telephoneNumber) //根据姓名编辑电话{ for(int i=0;i&lt;contactSize;i++) { if(element[i].name==name) { element[i].telephoneNumber=telephoneNumber; } }}void AddressList::edit(string name, int num, int Number) //根据姓名编辑班级或宿舍{ if(num==2) //编辑班级 { for(int i=0;i&lt;contactSize;i++) { if(element[i].name==name) { element[i].classNumber=Number; } } } else //编辑宿舍 { for(int i=0;i&lt;contactSize;i++) { if(element[i].name==name) { element[i].dormitoryNumber=Number; } } }}int AddressList::search(string name) //根据姓名查找{ for(int i=0;i&lt;contactSize;i++) { if(element[i].name==name) return 1; } return 0;}int AddressList::outputClass(int classNumber) //输出班级所有成员宿舍号的异或值{ int res=0; for(int i=0;i&lt;contactSize;i++) { if(element[i].classNumber==classNumber) { res^=element[i].dormitoryNumber; } } return res;}int main(){ int n;//操作数目 cin&gt;&gt;n; AddressList Contact(10); //创建联系人对象 int instruction; //指令编号 string iName,iTelephone; //读入的姓名、电话信息 int iClass,iDormitory; //读入的班级、宿舍信息 for(int i=0;i&lt;n;i++) { cin&gt;&gt;instruction; switch(instruction) { case 0: //插入一条记录 cin&gt;&gt;iName&gt;&gt;iTelephone&gt;&gt;iClass&gt;&gt;iDormitory; Contact.insert(iName,iTelephone,iClass,iDormitory); break; case 1: //删除一条记录 cin&gt;&gt;iName; Contact.eraser(iName); break; case 2: //根据姓名编辑一条记录 int editNum; cin&gt;&gt;iName&gt;&gt;editNum; if(editNum==1) { cin&gt;&gt;iTelephone; Contact.edit(iName,editNum,iTelephone); } else if (editNum==2) { cin&gt;&gt;iClass; Contact.edit(iName,editNum,iClass); } else { cin&gt;&gt;iDormitory; Contact.edit(iName,editNum,iDormitory); } break; case 3: //根据姓名查找 cin&gt;&gt;iName; cout&lt;&lt;Contact.search(iName)&lt;&lt;endl; break; case 4: //输出班级所有成员宿舍号的异或 cin&gt;&gt;iClass; cout&lt;&lt;Contact.outputClass(iClass)&lt;&lt;endl; break; } } return 0;} 结果分析 第一次提交时7个节点通过，3个节点RE，一直找不到错误，然后仔细读代码(大概也就读了十几遍的样子)，发现在成员函数insert中，新数组动态申请时使用listLength*2表示新数组的元素个数，之后忘了对listLength扩大两倍（我真是个憨憨），修改后提交通过。","link":"/2020/10/04/CS/DSA/DSA_3/"},{"title":"DSA：（七）队列","text":"循环队列的数组描述有不同的实现策略，主要不同之处在于如何区分队列是空还是满。本文的实现策略是不将队列插满，队列元素个数最多是arrayLength-1，在向队列插入元素之前，先要判断本次操作是否会使队列变满。 P1011:卡片游戏 描述 假设桌上有一叠扑克牌，依次编号为1-n（从上至下）。当至少还有两张的时候，可以进行操作：把第一张牌扔掉，然后把新的第一张（原先扔掉的牌下方的那张牌,即第二张牌）放到整叠牌的最后。输入n，输出最后剩下的牌。 要求 1.创建队列类，使用数组描述的循环队列。 2.实现卡片游戏。 格式 输入 一个整数n，代表一开始卡片的总数。 输出 最后一张卡片的值。 样例 输入 1100 输出 172 限制 1s, 64MB for each test case. 算法描述 使用数组存储结构，封装循环队列类arrayQueue，私有成员包括队列首元素的下一个位置（逆时针）queueFront，队列尾元素的位置queueBack，数组大小arrayLength，存储队列的数组queue。公有成员包括构造函数，析构函数，ADT方法包括判断队列是否为空，返回队列中元素个数，返回队首元素，返回队尾元素，删除队首元素，将元素插入到队尾。 构造函数中，设置queueFront=queueBack=0。队空标志为queueFront=queueBack，队列元素个数为(arrayLength+queueBack-queueFront)%arrayLength。元素入队时，若插入一个元素后队列满，需要扩大容量，通过queueFront计算队列首元素的位置start，与2进行比较判断原队列中是否形成环，若没有形成环，对元素只需调用一次copy方法进行复制，若形成环，需要使用copy进行两次复制。 对扑克牌进行操作，把第一张牌扔掉，队列操作是删除队首元素；把新的一张牌放到整叠牌的最后，队列操作是获得队首元素，删除队首元素，将得到的队首元素插入到队尾。通过队列的元素个数进行循环控制。 C++实现代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class arrayQueue{private: int queueFront; //队列首元素的下一个位置（逆时针方向） int queueBack; //队列最后一个元素的位置 int arrayLength; //数组大小 T* queue; //存储队列的数组public: arrayQueue(int initialCapacity=10); ~arrayQueue() {delete []queue;} bool empty() const {return queueFront==queueBack;} int size() const {return (arrayLength+queueBack-queueFront)%arrayLength;} T&amp; front() const; //返回队首元素 T&amp; back() const; //返回队尾元素 void pop(); //删除队首元素 void push(const T&amp; theElement); //元素插入到队尾};template &lt;class T&gt;arrayQueue&lt;T&gt;::arrayQueue(int initialCapacity){ arrayLength=initialCapacity; queue=new T[arrayLength]; queueFront=queueBack=0;}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::front() const{//返回队首元素 return queue[(queueFront+1)%arrayLength];}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::back() const{//返回队尾元素 return queue[queueBack];}template &lt;class T&gt;void arrayQueue&lt;T&gt;::pop(){//删除队首元素 queueFront=(queueFront+1)%arrayLength; queue[queueFront].~T();}template &lt;class T&gt;void arrayQueue&lt;T&gt;::push(const T&amp; theElement){//元素插入到队尾 //如果插入一个元素后队列满，需要扩充容量 if((queueBack+1)%arrayLength==queueFront) { T* newQueue=new T[2*arrayLength]; int start=(queueFront+1)%arrayLength; //复制元素 if(start&lt;2) //原队列中没有形成环 copy(queue+start,queue+start+arrayLength-1,newQueue); else //原队列中形成环 { copy(queue+start,queue+arrayLength,newQueue); copy(queue,queue+queueBack+1,newQueue+arrayLength-start); } queueFront=2*arrayLength-1; queueBack=arrayLength-2; arrayLength*=2; delete []queue; queue=newQueue; } queueBack=(queueBack+1)%arrayLength; queue[queueBack]=theElement;}int main(){ int n; cin&gt;&gt;n; arrayQueue&lt;int&gt; card; for(int i=1;i&lt;=n;i++) card.push(i); while(card.size()&gt;=2) { card.pop(); int t=card.front(); card.pop(); card.push(t); } cout&lt;&lt;card.front()&lt;&lt;endl; return 0;} 结果分析 1.构造函数设置queueFront=queueBack=0，保证符合队列为空的标志，并且将0号位置空出来，从1号位置开始插入。队列的最大元素个数为arrayLength-1，若插入一个元素后队列满，可以根据队列首元素的位置与2的大小关系判断队列中是否形成了环，然后进行元素的复制。 2.通过queueFront和queueBack计算队列元素个数，若队列中没有形成环，queueBack-queueFront得到队列元素个数，若队列中形成了环，queueFront-queueBack为空白位置的个数，arrayLength-(queueFront-queueBack)得到队列元素个数。将两种情况合并，(arrayLength+queueBack-queueFront)%arrayLength表示队列元素个数。","link":"/2020/11/12/CS/DSA/DSA_7/"},{"title":"DSA：（十）堆及其应用","text":"优先级队列中，每个元素都有一个优先级。在最小优先级队列中，查找和删除的元素都是优先级最小的元素。在最大优先级队列中，查找和删除的元素都是优先级最大的元素。优先级队列性能较好的是堆结构，一个大根堆（小根堆）既是大根树（小根树），也是完全二叉树。删除和插入的时间复杂度均为O(logn)，初始化的时间复杂度为O(n)。利用堆结构实现堆排序，时间复杂度为O(nlogn)。利用堆和二叉树，实现Huffman编码，保证没有一个编码是另一个编码的前缀，并且WEP最小。 P1016:堆的操作 内容 创建最小堆类，最小堆的存储结构使用数组。提供操作:插入、删除、初始化。题目第一个操作是建堆操作，接下来是对堆的插入和删除操作，插入和删除都在建好的堆上操作。 格式 输入 第一行一个数n（n&lt;=5000)，代表堆的大小。第二行n个数，代表堆的各个元素。 第三行一个数m (m&lt;=1000)，代表接下来共m个操作。接下来m行，分别代表各个操作。下面是各个操作的格式： 插入操作：1 num 删除操作：2 排序操作：第一行两个数3和n，3代表是排序操作，n代表待排序的数的数目，接下来一行n个数是待排序数。 保证排序操作只出现一次且一定是最后一个操作。 输出 第一行建堆操作输出建好堆后堆顶的元素。 接下来m个操作，若是插入和删除操作，每行输出执行操作后堆顶的元素的值；若是排序操作，输出一行按升序排序好的结果，每个元素间用空格分隔。 样例 输入 123456789101112131410-225580 113195 -257251 384948 -83524 331745 179545 293165 125998 376875101 -2325021 -3598331 951232221 2239711 -1187351 -2788433 10-96567 37188 -142422 166589 -169599 245575 -369710 423015 -243107 -108789 输出 1234567891011-257251-257251-359833-359833-257251-232502-225580-225580-225580-278843-369710 -243107 -169599 -142422 -108789 -96567 37188 166589 245575 423015 Limitation 1s, 64MB for each test case. 算法描述 使用数组存储结构，封装小根堆类minHeap，私有成员包括存储堆的数组heap，数组大小arrayLength，小根堆的大小heapSize，公有成员包括构造函数，析构函数，empty方法，size方法，返回堆顶元素的top方法，向堆中插入一个元素的push方法，删除堆顶元素的pop方法，初始化一个小根堆的initialize方法，从堆的析构函数中保存数组的deactiveArray方法。定义模板函数heapSort，利用堆排序对数组进行排序。 top：返回堆顶元素。直接返回heap[1]即可。 pop：删除堆顶元素。首先将堆顶元素heap[1]删除，然后将堆的最后一个元素放在根的位置，依次和左右孩子中较小的进行比较，寻找合适的位置放入。 push：向堆中插入一个元素。首先判断数组容量是否足够，若数组已满，需要进行扩容。为插入的元素寻找插入位置，判断条件是是否到达根节点和theElement值是否小于当前位置的元素值（保证小根堆的结构）。 initialize：初始化一个小根堆。令heap指向数组theHeap，heapSize=theSize。然后从最后一个具有孩子的节点开始扫描，用root表示正在处理的节点，对于每一个root值，利用while循环将以root为根的子树调整为小根堆。 deactiveArray：从堆的析构函数中保存数组。将类的heap指针置空。 heapSort：利用堆排序对数组a[1:n]排序。首先声明一个minHeap类的对象heap，调用initialize方法初始化小根堆，然后每次删除堆顶元素，将其放在数组的最后，最后调用deactivateArray方法，将heap的指针置空，保存数组a。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class minHeap //小根堆{private: T *heap; //保存堆的数组 int arrayLength; //数组大小 int heapSize; //堆的大小public: minHeap(int initialCapacity=10); ~minHeap() {delete []heap;} bool empty() const {return heapSize==0;} int size() const {return heapSize;} T&amp; top() const {return heap[1];} //返回堆顶元素 void pop(); //删除堆顶元素 void push(const T&amp; theElement); //向堆中插入一个元素 void initialize(T* theHeap,int theSize);//初始化一个小根堆 void deactivateArray() {heap=NULL;} //从堆的析构函数中保存数组a};template &lt;class T&gt;minHeap&lt;T&gt;::minHeap(int initialCapacity){ heap=new T[initialCapacity+1]; arrayLength=initialCapacity+1; heapSize=0;}template &lt;class T&gt;void minHeap&lt;T&gt;::pop(){//删除堆顶元素 heap[1].~T(); //删除最小元素 //重新构造堆 T lastElement=heap[heapSize--]; //从根开始，为lastElement寻找合适的位置 int currentNode=1,child=2; while(child&lt;=heapSize) { if(child&lt;heapSize &amp;&amp; heap[child]&gt;heap[child+1]) child++; if(lastElement&lt;=heap[child]) break; heap[currentNode]=heap[child]; currentNode=child; child*=2; } heap[currentNode]=lastElement;}template &lt;class T&gt;void minHeap&lt;T&gt;::push(const T &amp;theElement){//向堆中插入一个元素 if(heapSize==arrayLength-1) //数组已满 { T* newHeap=new T[arrayLength*2]; arrayLength*=2; copy(heap+1,heap+arrayLength,newHeap+1); delete []heap; heap=newHeap; } //为theElement寻找插入位置 int currentNode=++heapSize; while(currentNode!=1 &amp;&amp; theElement&lt;heap[currentNode/2]) {//不能把theElement放入heap[currentNode] heap[currentNode]=heap[currentNode/2]; currentNode/=2; } heap[currentNode]=theElement;}template &lt;class T&gt;void minHeap&lt;T&gt;::initialize(T *theHeap, int theSize){//初始化一个小根堆 delete []heap; heap=theHeap; heapSize=theSize; arrayLength=theSize+1; //堆化 for(int root=heapSize/2;root&gt;=1;root--) { T rootElement=heap[root]; //子树的根 //寻找放置rootElement的位置 int child=2*root; while(child&lt;=heapSize) { if(child&lt;heapSize &amp;&amp; heap[child]&gt;heap[child+1]) child++; if(rootElement&lt;=heap[child]) break; heap[child/2]=heap[child]; child*=2; } heap[child/2]=rootElement; }}template &lt;class T&gt;void heapSort(T *a, int n){//利用堆排序对数组a[1:n]进行排序 minHeap&lt;T&gt; heap(1); heap.initialize(a,n); for(int i=n-1;i&gt;=1;i--) { T x=heap.top(); heap.pop(); a[i+1]=x; } heap.deactivateArray(); //从堆的析构函数中保存数组a}int main(){ int n;//堆的大小 cin&gt;&gt;n; int *heapElement=new int[n+1]; for(int i=1;i&lt;=n;i++)//第二行n个数，代表堆的各个元素 cin&gt;&gt;heapElement[i]; minHeap&lt;int&gt; H(1); H.initialize(heapElement,n); cout&lt;&lt;H.top()&lt;&lt;endl; int m,instruction,num; //m个操作和当前的操作 cin&gt;&gt;m; for(int i=0;i&lt;m;i++) { cin&gt;&gt;instruction; switch(instruction) { case 1: cin&gt;&gt;num; H.push(num); cout&lt;&lt;H.top()&lt;&lt;endl; break; case 2: H.pop(); cout&lt;&lt;H.top()&lt;&lt;endl; break; case 3: cin&gt;&gt;num; int *unsorted=new int[num+1]; for(int k=1;k&lt;=num;k++) cin&gt;&gt;unsorted[k]; heapSort(unsorted,num); for(int k=num;k&gt;=1;k--) cout&lt;&lt;unsorted[k]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; delete []unsorted; break; } } return 0;} P1017:霍夫曼编码 格式 输入 一串小写字母组成的字符串（不超过1000000)。 输出 输出这个字符串通过Huffman编码后的长度。 样例 输入 1abcdabcaba 输出 119 限制 1s, 1024KiB for each test case. 提示 样例中，‘a’ 出现了4次，‘b’ 出现了3次，‘c’ 出现了2次，‘d’ 出现了1次 编码为: ‘a’ : 0 ‘b’ : 10 ‘c’ : 110 ‘d’ : 111 算法描述 扩充链表存储的二叉树类，增加私有成员WEP，表示Huffman树的WEP值，增加方法computeWEP，计算Huffman树的WEP值，增加方法makeTree，将left，right，element合并成一颗新树。 定义huffmanNode类，表示Huffman树的每个节点。私有成员包括linkedBinaryTree类的指针tree和权值weight。公有成员是对括号的运算符重载，返回weight值。声明类的友元函数HuffmanTree。 HuffmanTree：用权值weight[1:n]构造Huffman树。首先创建一组hNode数组，对于每个hNode[i]，weight值由参数可以得到，tree通过new得到，调用makTree构造出一颗树。创建小根堆heap，heap的每一个元素都是huffmanNode类型，通过小根堆的initialize方法将一组单节点树hNode变成一个小根堆。然后不断从小根堆中取出两棵权值最小的树，将其合并成一个后放入小根堆。函数返回heap.top().tree。 computeWEP：计算Huffman树的WEP值。利用层次遍历，对于遍历到的每个节点，如果其标识为0，则其为内部节点，如果标识不为0，则其为外部节点，根据weight值和当前节点到根节点的路径长度（即层数-1）计算WEP。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;//----------------------小根堆----------------------template &lt;class T&gt;class minHeap //小根堆{private: T *heap; //保存堆的数组 int arrayLength; //数组长度 int heapSize; //堆的大小public: minHeap(int initialCapacity=10); ~minHeap() {delete []heap;} bool empty() const {return heapSize==0;} int size() const {return heapSize;} T&amp; top() const {return heap[1];} //返回堆顶元素 void pop(); //删除堆顶元素 void push(const T&amp; theElement); //向堆中插入一个元素 void initialize(T* theHeap,int theSize);//初始化一个小根堆 void heapSort(T* a,int n); //利用堆排序对数组a[1:n]进行排序 void deactivateArray() {heap=NULL;} //从堆的析构函数中保存数组a};template &lt;class T&gt;minHeap&lt;T&gt;::minHeap(int initialCapacity){ heap=new T[initialCapacity+1]; arrayLength=initialCapacity+1; heapSize=0;}template &lt;class T&gt;void minHeap&lt;T&gt;::pop(){//删除堆顶元素 heap[1].~T(); //删除最大元素 //重新构造堆 T lastElement=heap[heapSize--]; //从根开始，为lastElement寻找合适的位置 int currentNode=1,child=2; while(child&lt;=heapSize) { if(child&lt;heapSize &amp;&amp; heap[child]&gt;heap[child+1]) child++; if(lastElement&lt;=heap[child]) break; heap[currentNode]=heap[child]; currentNode=child; child*=2; } heap[currentNode]=lastElement;}template &lt;class T&gt;void minHeap&lt;T&gt;::push(const T &amp;theElement){//向堆中插入一个元素 if(heapSize==arrayLength-1) //数组已满 { T* newHeap=new T[arrayLength*2]; arrayLength*=2; copy(heap+1,heap+arrayLength,newHeap+1); delete []heap; heap=newHeap; } //为theElement寻找插入位置 int currentNode=++heapSize; while(currentNode!=1 &amp;&amp; theElement&lt;heap[currentNode/2]) {//不能把theElement放入heap[currentNode] heap[currentNode]=heap[currentNode/2]; currentNode/=2; } heap[currentNode]=theElement;}template &lt;class T&gt;void minHeap&lt;T&gt;::initialize(T *theHeap, int theSize){//初始化一个小根堆 delete []heap; heap=theHeap; heapSize=theSize; arrayLength=theSize+1; //堆化 for(int root=heapSize/2;root&gt;=1;root--) { T rootElement=heap[root]; //子树的根 //寻找放置rootElement的位置 int child=2*root; while(child&lt;=heapSize) { if(child&lt;heapSize &amp;&amp; heap[child]&gt;heap[child+1]) child++; if(rootElement&lt;=heap[child]) break; heap[child/2]=heap[child]; child*=2; } heap[child/2]=rootElement; }}//----------------------队列----------------------template &lt;class T&gt;class arrayQueue{private: int queueFront; //队列首元素的下一个位置（逆时针方向） int queueBack; //队列最后一个元素的位置 int arrayLength; //数组大小 T* queue; //存储队列的数组public: arrayQueue(int initialCapacity=10); ~arrayQueue() {delete []queue;} bool empty() const {return queueFront==queueBack;} int size() const {return (arrayLength+queueBack-queueFront)%arrayLength;} T&amp; front() const; //返回队首元素 T&amp; back() const; //返回队尾元素 void pop(); //删除队首元素 void push(const T&amp; theElement); //元素插入到队尾};template &lt;class T&gt;arrayQueue&lt;T&gt;::arrayQueue(int initialCapacity){ arrayLength=initialCapacity; queue=new T[arrayLength]; queueFront=queueBack=0;}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::front() const{//返回队首元素 return queue[(queueFront+1)%arrayLength];}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::back() const{//返回队尾元素 return queue[queueBack];}template &lt;class T&gt;void arrayQueue&lt;T&gt;::pop(){//删除队首元素 queueFront=(queueFront+1)%arrayLength; queue[queueFront].~T();}template &lt;class T&gt;void arrayQueue&lt;T&gt;::push(const T&amp; theElement){//元素插入到队尾 //如果插入一个元素后队列满，需要扩充容量 if((queueBack+1)%arrayLength==queueFront) { T* newQueue=new T[2*arrayLength]; int start=(queueFront+1)%arrayLength; //复制元素 if(start&lt;2) //原队列中没有形成环 copy(queue+start,queue+start+arrayLength-1,newQueue); else //原队列中形成环 { copy(queue+start,queue+arrayLength,newQueue); copy(queue,queue+queueBack+1,newQueue+arrayLength-start); } queueFront=2*arrayLength-1; queueBack=arrayLength-2; arrayLength*=2; delete []queue; queue=newQueue; } queueBack=(queueBack+1)%arrayLength; queue[queueBack]=theElement;}//----------------------二叉树----------------------template &lt;class T&gt;struct binaryTreeNode //二叉树节点类{ T element; binaryTreeNode&lt;T&gt; *leftChild, *rightChild; //三个构造函数 binaryTreeNode() {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement):element(theElement) {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement,binaryTreeNode&lt;T&gt;* theLeftChild,binaryTreeNode&lt;T&gt;* theRightChild):element(theElement) { leftChild=theLeftChild; rightChild=theRightChild; }};template &lt;class T&gt;class linkedBinaryTree{private: binaryTreeNode&lt;T&gt; *root; //根节点指针 int treeSize; //树的节点个数 int WEP; //Huffman树的WEP值 static void (*visit)(binaryTreeNode&lt;T&gt; *); //访问函数 static void preOrder(binaryTreeNode&lt;T&gt; *t); //前序遍历 static void inOrder(binaryTreeNode&lt;T&gt; *t); //中序遍历 static void postOrder(binaryTreeNode&lt;T&gt; *t); //后序遍历 static void dispose(binaryTreeNode&lt;T&gt; *t) {delete t;} //删除t指向的节点 static void output(binaryTreeNode&lt;T&gt; *t) {cout&lt;&lt;t-&gt;element&lt;&lt;&quot; &quot;;} //输出节点t的element值 int height(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的高度 int nodeNumber(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的节点个数public: linkedBinaryTree() {root=NULL; treeSize=0; WEP=0;} ~linkedBinaryTree() {erase();} bool empty() const {return treeSize==0;} int size() const {return treeSize;} void preOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; preOrder(root); } void inOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; inOrder(root); } void postOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; postOrder(root); } void postOrderOutput() //后序输出序列 {postOrder(output);cout&lt;&lt;endl;} void levelOrder(void(*)(binaryTreeNode&lt;T&gt;*)); //层次遍历 void erase() //删除二叉树 { postOrder(dispose); root=NULL; treeSize=0; } int Height() const {return height(root);} //计算二叉树的高度 int NodeNumber() const {return nodeNumber(root);} //计算二叉树的节点个数 void initialize(int num); //二叉树的初始化 void subtreeNodeNumber() const; //输出二叉树中所有节点为根的子树的节点个数 void subtreeHeight() const; //输出二叉树中所有节点为根的子树的高度 binaryTreeNode&lt;T&gt;* buildTree(T* pre,T* in,int len); //通过前序序列pre和中序序列in构造一颗二叉树,len表示序列长度 void update(T* pre,T* in,int len); //将构造的二叉树放到对象中，即更新root和treeSize void makeTree(const T&amp; element,linkedBinaryTree&lt;T&gt;&amp; left,linkedBinaryTree&lt;T&gt;&amp; right); //创建一个二叉树，element为根节点元素，left左子树，right为右子树 int computeWEP(int weight[]); //计算Huffman树的WEP值};template &lt;class T&gt;void (*linkedBinaryTree&lt;T&gt;::visit)(binaryTreeNode&lt;T&gt; *)=NULL; //类的静态成员的初始化template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::preOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { linkedBinaryTree&lt;T&gt;::visit(t); preOrder(t-&gt;leftChild); preOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::inOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { inOrder(t-&gt;leftChild); linkedBinaryTree&lt;T&gt;::visit(t); inOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::postOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { postOrder(t-&gt;leftChild); postOrder(t-&gt;rightChild); linkedBinaryTree&lt;T&gt;::visit(t); }}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::height(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int hl=height(t-&gt;leftChild); int hr=height(t-&gt;rightChild); if(hl&gt;hr) return ++hl; else return ++hr;}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::nodeNumber(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int nl=nodeNumber(t-&gt;leftChild); int nr=nodeNumber(t-&gt;rightChild); return nl+nr+1;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::levelOrder(void (*theVisit)(binaryTreeNode&lt;T&gt; *)){ binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; while (t!=NULL) { theVisit(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else return ; q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::initialize(int num){//二叉树的初始化 //这棵树有num个节点，编号为1~num，根节点为1 //读入编号为i的节点的左孩子a，右孩子b，-1表示该位置没有节点 root=new binaryTreeNode&lt;T&gt;(1); treeSize=num; int *left=new int[num+1]; //左孩子 int *right=new int[num+1]; //右孩子 binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; for(int i=1;i&lt;=num;i++) cin&gt;&gt;left[i]&gt;&gt;right[i]; int cur=t-&gt;element; //当前节点的element值 //利用层次遍历进行初始化 while (t!=NULL) { if(left[cur]!=-1) t-&gt;leftChild=new binaryTreeNode&lt;T&gt;(left[cur]); if(right[cur]!=-1) t-&gt;rightChild=new binaryTreeNode&lt;T&gt;(right[cur]); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //初始化完成 { delete []left; delete []right; return ; } q.pop(); cur=t-&gt;element; }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeNodeNumber() const{//输出二叉树中所有节点为根的子树的节点个数 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的节点个数 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=nodeNumber(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeHeight() const{//输出二叉树中所有节点为根的子树的高度 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的高度 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=height(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;binaryTreeNode&lt;T&gt;* linkedBinaryTree&lt;T&gt;::buildTree(T *pre, T *in, int len){//根据前序序列pre和中序序列in构建二叉树 //len表示序列长度 //返回二叉树的根节点 //序列长度小于等于0，不需要继续构造 if(len&lt;=0) return NULL; binaryTreeNode&lt;T&gt;* subRoot=new binaryTreeNode&lt;T&gt;(pre[0]); //pre[0]为根节点 int index=0; //在中序序列中查找pre[0] for(int i=0;i&lt;len;i++) if(in[i]==pre[0]) { index=i; break; } //递归构造左子树和右子树 subRoot-&gt;leftChild=buildTree(pre+1,in,index); subRoot-&gt;rightChild=buildTree(pre+index+1,in+index+1,len-index-1); return subRoot;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::update(T* pre,T* in,int len){//将构造的二叉树放到对象中，即更新root和treeSize root=buildTree(pre, in, len); treeSize=len;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::makeTree(const T &amp;element, linkedBinaryTree&lt;T&gt; &amp;left, linkedBinaryTree&lt;T&gt; &amp;right){//将left,right和element合并成一颗新树 root=new binaryTreeNode&lt;T&gt;(element,left.root,right.root); treeSize=left.treeSize+right.treeSize+1; left.root=right.root=NULL; left.treeSize=right.treeSize=0;}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::computeWEP(int weight[]){//计算Huffman树的WEP值 int road=0; //当前节点到根节点的路径长度 arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; q.push(root); while(1) { int length=q.size(); if(length==0) break; while(length&gt;0) { binaryTreeNode&lt;T&gt;* cur; cur=q.front(); q.pop(); length--; if(cur-&gt;element!=0) WEP+=weight[cur-&gt;element]*road; if(cur-&gt;leftChild!=NULL) q.push(cur-&gt;leftChild); if(cur-&gt;rightChild!=NULL) q.push(cur-&gt;rightChild); } road++; } if(WEP==0) //Huffman树只有根节点 return weight[1]; return WEP;}template &lt;class T&gt;linkedBinaryTree&lt;int&gt;* HuffmanTree(T weight[],int n); //用权值weight[1:n]构造霍夫曼树,n&gt;=1template &lt;class T&gt;class huffmanNode{ friend linkedBinaryTree&lt;int&gt;* HuffmanTree&lt;T&gt;(T weight[],int n); //友元函数的声明public: operator T() const {return weight;}private: linkedBinaryTree&lt;int&gt; *tree; T weight;};template &lt;class T&gt;linkedBinaryTree&lt;int&gt;* HuffmanTree(T weight[],int n){//用权值weight[1:n]构造霍夫曼树,n&gt;=1 //创建一组单节点树hNode数组 huffmanNode&lt;T&gt;* hNode=new huffmanNode&lt;T&gt;[n+1]; linkedBinaryTree&lt;int&gt; emptyTree; for(int i=1;i&lt;=n;i++) { hNode[i].weight=weight[i]; hNode[i].tree=new linkedBinaryTree&lt;int&gt;; hNode[i].tree-&gt;makeTree(i,emptyTree,emptyTree); } //将一组单节点树hNode[1:n]变成一个小根堆 minHeap&lt;huffmanNode&lt;T&gt;&gt; heap(1); heap.initialize(hNode,n); //不断从最小堆中取出两颗树合并成一个放入，直到剩下一颗 huffmanNode&lt;T&gt; w,x,y; linkedBinaryTree&lt;int&gt; *z; for(int i=1;i&lt;n;i++) { //从最小堆中选出两颗权值最小的树 x=heap.top(); heap.pop(); y=heap.top(); heap.pop(); //合并成一颗树w，放入堆 z=new linkedBinaryTree&lt;int&gt;; z-&gt;makeTree(0,*x.tree,*y.tree); w.weight=x.weight+y.weight; w.tree=z; heap.push(w); delete x.tree; delete y.tree; } return heap.top().tree;}int main(){ string str; cin&gt;&gt;str; int t[26]={0}; int weight[27]={0}; int size=0; for(int i=0;i&lt;str.size();i++) t[str.at(i)-'a']++; for(int i=0;i&lt;26;i++) if(t[i]!=0) weight[++size]=t[i]; linkedBinaryTree&lt;int&gt;* p=HuffmanTree(weight,size); cout&lt;&lt;p-&gt;computeWEP(weight)&lt;&lt;endl; return 0;} 结果分析 1.模板类声明友元的函数如果是模板函数，声明时需要在友元函数的函数名之后参数之前加上。 2.堆排序是不稳定的。 3.根据Huffman树求Huffman编码，可以对Huffman树进行后序遍历，利用栈记录走过的分支，如果是左分支，栈内进0，如果是右分支，栈内进1，直到到达一个外部节点，此时栈内记录的就是该节点对应的Huffman编码，然后继续后序遍历，直到遍历结束。","link":"/2020/12/23/CS/DSA/DSA_10/"},{"title":"Lunch Meeting（一）","text":"1a1d9abe5672c7bc37baaec17a6e5159515451f0571d00edcbb5bd7cff710270a8fba6795f0fa45552155e3314c529b9430dd98844ed59e1d3849ba2f9801aa179a362a6c66bc4e171789d8f46e5ed6e05586456ad0fa87bd468ffe3c71d7082d2c9955a2a23b038d97fa88891783f442bcfeae19275dc45ea2232ee5e593c91caf567e6f43ade044b037fa83b422a20f5f6609b53b606527aeed509f182500daea841a9f24032752a62684e443dcb6bd522d0cd938cb09c27ee7033e4f27cac7c861568705640a74e1bcd866bc2151c7fa330ef34599cb47c1010dd8d8c573a85a7eaca354b345790f1dba17507774346f6e47cabd85c6c8fc429865de1acd549a5ef39955b2ffbbc30e2840cc769b23c1dbefb4a33c65f12229d537aa7e265780959db24510e3483ea4781a99a6bd7d094afea90cf4a4727919a701e0287037b618cf82506ad4fe6942961a35a6e3c4c5eaaa9a76a6c523e4d9c216274795421b7e5b40b3dbc84b05b0225cc04125808ebf50bb877c79d17cd7f623e017e47ba60655af40e53ab6b5319f1712aa08a6a9e3925e9074863c5a1f7c151f31cba28aca970e2eaef9b9f713ec31140d2402b39ff2cec97a1bbb11c4a396d2a0d91119718aeaeb9a9d7ba3697a6efe85482fe17a3aebb2e3099b04e3e318fb68e55644806b61d10ce05af275f7da2ed84948c3985eace3009e07c25bd272234f86e2fcc437ade5e8090a004df40f23de06554bbc3c702a3f9a57973bc593a27a54543096745d65ca77dbabf921debfbc744b1924d25997c77816e75ec0da49d172a00aca2264f690f477b00af8fa0ba27660864027e267434a84a2ed620e573a194867532861498b322fc7643f5b886959874a1196820a2a6d6259bdf092ce104e5ba8c47745e91e8b940ee8ec3fdb93d504303f33a8e4f3bacf8ee51aec12e8cc96b1bdca949e7633ff268f04dc7f0fd4f 输入密码，查看文章","link":"/2021/04/20/Secret/JingYing/lunch-meeting-1st/"},{"title":"DSA：（十二）图","text":"图的表示可以通过邻接矩阵，邻接链表和邻接数组。本文通过邻接链表实现无向无权图的表示，成员方法包括插入一条边，删除一条边，广度优先搜索，深度优先搜索，求连通分量个数，求两点之间的最短路径（BFS）。linkedGraph类中含有迭代器类myIterator，通过顶点创建迭代器，依次返回该顶点的所有邻接点。 P1019:图论基础 描述 创建无向图类，存储结构使用邻接链表，提供操作：插入一条边，删除一条边，BFS，DFS。 格式 输入 第一行四个整数n，m，s，t。n (10≤n≤100000) 代表图中点的个数，m (10≤m≤200000) 代表接下来共有m个操作，s代表起始点，t代表终点。 接下来m行，每行代表一次插入或删除边的操作，操作格式为： 0 u v 在点u和v之间增加一条边 1 u v 删除点u和v之间的边 输出 第一行输出图中有多少个连通分量。 第二行输出所有连通子图中最小点的编号（升序），编号间用空格分隔。 第三行输出从s点开始的dfs序列长度。 第四行输出从s点开始的字典序最小的dfs序列。 第五行输出从t点开始的bfs序列的长度。 第六行输出从t点开始字典序最小的bfs序列。 第七行输出从s点到t点的最短路径，若是不存在路径则输出-1。 样例 输入 12345678910111213141516171819202110 20 4 50 6 40 10 30 4 80 4 101 4 100 2 10 5 80 5 20 10 70 9 60 9 10 7 10 8 100 7 50 8 30 6 71 6 41 8 30 7 80 9 2 输出 123456711 104 8 5 2 1 7 6 9 10 3 105 2 7 8 1 9 6 10 4 3 2 限制 1s, 10240KiB for each test case. 算法描述 使用邻接链表存储结构，封装无向图类linkedGraph。protected成员包括图的顶点数n，边数e，邻接表aList，深度优先搜索递归方法rDfs，静态成员标记数组reach，标记label，路径数组path，路径长度length。public成员包括构造函数，析构函数，返回顶点个数，返回边数，插入一条边，删除一条边，广度优先搜索，深度优先搜索，返回无向图的构件个数，通过BFS求两点之间的最短路径，对aList链表数组的每个元素进行排序。定义迭代器myIterator，提供next方法依次返回当前顶点的邻接顶点，若不存在返回0。方法iterator返回myIterator类的指针。 对chain类进行扩展，增加方法eraseElement(theVertex)删除顶点为theVertex的元素和冒泡排序方法bubbleSort。 insertEdge：插入一条边i, j。首先通过aList[i].indexOf(j)判断图中是否已经存在这条边，若已经存在则不需要再次插入，若不存在，调用aList[i]和aList[j]的insert方法，将邻接顶点插入到链表头，图的边数e加一。 eraseEdge：删除一条边i, j。首先通过aList[i].eraseElement (j)判断图中是否存在这条边，若不存在则不需要进行删除，若存在，调用aList[i]和aList[j]的eraseElement方法删除邻接点，图的边数e减一。 labelComponents：返回无向图的构件个数。首先将标记构件号的数组c和标记label初始化，然后遍历每个顶点，如果顶点i未到达，对其实施BFS，进行标记。 findPath：寻找一条从顶点theSource到顶点theDestination的最短路径，返回一个数组path，从索引1开始表示路径，path[0]表示路径长度。如果路径不存在，返回NULL。首先对path，length，reach等进行初始化，定义bool型变量exists表示路径是否存在，用parent数组存储每个节点的前驱节点。利用BFS搜索路径，每次从队列中删除一个有标记的顶点，判断是否到达theDestination，若未到达，则标记所有邻接于顶点w的还未到达的顶点，使用parent数组存储前驱节点。如果到达theDestination，exists赋值为true，跳出while循环。如果找到了最短路径，根据parent逆向寻找路径中的各个顶点，通过栈结构将其放入path数组中，path[0]记录路径长度。如果不存在路径，输出-1然后返回。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839#include &lt;iostream&gt;using namespace std;//---------------------graphChain类---------------------template &lt;class T&gt;struct chainNode //节点类{ //数据成员 T element; chainNode&lt;T&gt;* next; //方法 chainNode() {} chainNode(const T&amp; element) { this-&gt;element=element; } chainNode(const T&amp; element,chainNode&lt;T&gt;* next) { this-&gt;element=element; this-&gt;next=next; }};class linkedGraph;template &lt;class T&gt;class graphChain{ friend class linkedGraph;protected: chainNode&lt;T&gt;* firstNode; //指向链表第一个节点的指针 int listSize; //线性表的元素个数public: graphChain(); //构造函数 graphChain(const graphChain&lt;T&gt;&amp; theList); //复制构造函数 ~graphChain(); //析构函数 //方法 bool empty() const {return listSize==0;} int size() const {return listSize;} T&amp; get(int theIndex) const; int indexOf(const T&amp; theElement); //返回元素theElement首次出现时的索引，若不存在返回-1 void insert(int theIndex,const T&amp; theElement); //在索引为theIndex的位置插入元素theElement void erase(int theIndex); //删除链表中索引为theIndex的元素 T* eraseElement(T&amp; theVertex); //删除顶点为theVertex的元素 void bubbleSort(); //冒泡排序 //迭代器 class iterator { protected: chainNode&lt;T&gt;* node; public: //用C++的typedef语句实现前向迭代器 typedef bidirectional_iterator_tag __iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference; iterator(chainNode&lt;T&gt;* theNode=NULL) //构造函数 { node=theNode; } //解引用操作符 T&amp; operator* () const {return node-&gt;element;} T* operator-&gt; () const {return &amp;node-&gt;element;} //迭代器加法操作 iterator&amp; operator++ ()//前++ { node=node-&gt;next; return *this; } iterator operator++ (int)//后++ { iterator old=*this; node=node-&gt;next; return old; } //相等检验 bool operator!= (const iterator&amp; right) const { return node!=right.node; } bool operator== (const iterator&amp; right) const { return node==right.node; } }; iterator begin() const { return iterator(firstNode); } iterator end() const { return iterator(NULL); }};template &lt;class T&gt;graphChain&lt;T&gt;::graphChain() //构造函数{ firstNode=NULL; listSize=0;}template &lt;class T&gt;graphChain&lt;T&gt;::graphChain(const graphChain&lt;T&gt;&amp; theList) //复制构造函数{ listSize=theList.listSize; //链表为空 if(listSize==0) { firstNode=NULL; return ; } //链表不为空 chainNode&lt;T&gt;* sourceNode=theList.firstNode; firstNode=new chainNode&lt;T&gt;(sourceNode-&gt;element);//复制theList的首元素 sourceNode=sourceNode-&gt;next; chainNode&lt;T&gt;* targetNode=firstNode; while(sourceNode!=NULL) //复制剩余元素 { targetNode-&gt;next=new chainNode&lt;T&gt;(sourceNode-&gt;element); targetNode=targetNode-&gt;next; sourceNode=sourceNode-&gt;next; } targetNode-&gt;next=NULL; //尾结点}template &lt;class T&gt;graphChain&lt;T&gt;::~graphChain() //析构函数{ while(firstNode!=NULL) { chainNode&lt;T&gt;* nextNode=firstNode-&gt;next; delete firstNode; firstNode=nextNode; }}template &lt;class T&gt;T&amp; graphChain&lt;T&gt;::get(int theIndex) const{//返回索引为theIndex的元素 //移向需要的节点 chainNode&lt;T&gt;* currentNode=firstNode; for(int i=0;i&lt;theIndex;i++) currentNode=currentNode-&gt;next; return currentNode-&gt;element;}template &lt;class T&gt;int graphChain&lt;T&gt;::indexOf(const T&amp; theElement){//返回元素theElement首次出现时的索引，若不存在返回-1 //搜索链表寻找theElement chainNode&lt;T&gt;* currentNode=firstNode; int index=0; while (currentNode!=NULL &amp;&amp; currentNode-&gt;element!=theElement) { currentNode=currentNode-&gt;next; index++; } if(currentNode==NULL) return -1; else return index;}template &lt;class T&gt;void graphChain&lt;T&gt;::insert(int theIndex,const T&amp; theElement) //插入操作{//在索引为theIndex的位置插入元素theElement if(theIndex==0)//在链表头插入 firstNode=new chainNode&lt;T&gt;(theElement,firstNode); else { //寻找前驱 chainNode&lt;T&gt;* p=firstNode; for(int i=0;i&lt;theIndex-1;i++) p=p-&gt;next; //在p之后插入 p-&gt;next=new chainNode&lt;T&gt;(theElement,p-&gt;next); } listSize++;}template &lt;class T&gt;void graphChain&lt;T&gt;::erase(int theIndex){//删除链表中索引为theIndex的元素 chainNode&lt;T&gt;* deleteNode; if(theIndex==0) {//删除链表的首节点 deleteNode=firstNode; firstNode=firstNode-&gt;next; } else { chainNode&lt;T&gt;* p=firstNode; for(int i=0;i&lt;theIndex-1;i++) p=p-&gt;next; deleteNode=p-&gt;next; p-&gt;next=p-&gt;next-&gt;next; } listSize--; delete deleteNode;}template &lt;class T&gt;T* graphChain&lt;T&gt;::eraseElement(T &amp;theVertex){//删除顶点为theVertex的元素 chainNode&lt;T&gt;* deleteNode; //要删除的节点 if(firstNode-&gt;element==theVertex) //删除的是链表的首节点 { deleteNode=firstNode; firstNode=firstNode-&gt;next; } else //删除的不是链表的首节点 { chainNode&lt;T&gt;* previousNode=firstNode; chainNode&lt;T&gt;* currentNode=firstNode-&gt;next; while(currentNode!=NULL &amp;&amp; currentNode-&gt;element!=theVertex) { currentNode=currentNode-&gt;next; previousNode=previousNode-&gt;next; } if(currentNode==NULL) //链表中不存在要删除的元素 return NULL; else //链表中存在要删除的元素 { deleteNode=currentNode; previousNode-&gt;next=currentNode-&gt;next; } } T* pElement=&amp;deleteNode-&gt;element; listSize--; delete deleteNode; return pElement;}template &lt;class T&gt;void graphChain&lt;T&gt;::bubbleSort(){//冒泡排序 for(chainNode&lt;T&gt;* p=firstNode;p!=NULL;p=p-&gt;next) for(chainNode&lt;T&gt;* q=p-&gt;next;q!= NULL;q=q-&gt;next) if(p-&gt;element &gt; q-&gt;element) swap(p-&gt;element,q-&gt;element);}//---------------------arrayQueue类---------------------template &lt;class T&gt;class arrayQueue{private: int queueFront; //队列首元素的下一个位置（逆时针方向） int queueBack; //队列最后一个元素的位置 int arrayLength; //数组大小 T* queue; //存储队列的数组public: arrayQueue(int initialCapacity=10); ~arrayQueue() {delete []queue;} bool empty() const {return queueFront==queueBack;} int size() const {return (arrayLength+queueBack-queueFront)%arrayLength;} T&amp; front() const; //返回队首元素 T&amp; back() const; //返回队尾元素 void pop(); //删除队首元素 void push(const T&amp; theElement); //元素插入到队尾};template &lt;class T&gt;arrayQueue&lt;T&gt;::arrayQueue(int initialCapacity){ arrayLength=initialCapacity; queue=new T[arrayLength]; queueFront=queueBack=0;}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::front() const{//返回队首元素 return queue[(queueFront+1)%arrayLength];}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::back() const{//返回队尾元素 return queue[queueBack];}template &lt;class T&gt;void arrayQueue&lt;T&gt;::pop(){//删除队首元素 queueFront=(queueFront+1)%arrayLength; queue[queueFront].~T();}template &lt;class T&gt;void arrayQueue&lt;T&gt;::push(const T&amp; theElement){//元素插入到队尾 //如果插入一个元素后队列满，需要扩充容量 if((queueBack+1)%arrayLength==queueFront) { T* newQueue=new T[2*arrayLength]; int start=(queueFront+1)%arrayLength; //复制元素 if(start&lt;2) //原队列中没有形成环 copy(queue+start,queue+start+arrayLength-1,newQueue); else //原队列中形成环 { copy(queue+start,queue+arrayLength,newQueue); copy(queue,queue+queueBack+1,newQueue+arrayLength-start); } queueFront=2*arrayLength-1; queueBack=arrayLength-2; arrayLength*=2; delete []queue; queue=newQueue; } queueBack=(queueBack+1)%arrayLength; queue[queueBack]=theElement;}//---------------------arrayStack类---------------------template &lt;class T&gt;class arrayStack{private: int stackTop; //栈顶 int arrayLength; //栈容量 T* stack; //元素数组public: //构造函数、析构函数 arrayStack(int initialCapacity=10); ~arrayStack() {delete []stack;} //ADT方法 bool empty() const {return stackTop==-1;} int size() const {return stackTop+1;} T&amp; top(); void pop(); void push(const T&amp; theElement);};template &lt;class T&gt;arrayStack&lt;T&gt;::arrayStack(int initialCapacity){ arrayLength=initialCapacity; stack=new T[arrayLength]; stackTop=-1;}template &lt;class T&gt;T&amp; arrayStack&lt;T&gt;::top(){ return stack[stackTop];}template &lt;class T&gt;void arrayStack&lt;T&gt;::pop(){ stack[stackTop--].~T();}template &lt;class T&gt;void arrayStack&lt;T&gt;::push(const T&amp; theElement){ if(stackTop==arrayLength-1) {//空间已满，容量加倍 T* newStack=new T[arrayLength*2]; arrayLength*=2; for(int i=0;i&lt;=stackTop;i++) newStack[i]=stack[i]; delete []stack; stack=newStack; } //在栈顶插入 stack[++stackTop]=theElement;}//---------------------linkedGraph类---------------------class linkedGraph{protected: int n; //顶点数 int e; //边数 graphChain&lt;int&gt; *aList; //邻接表 void rDfs(int v); //深度优先搜索递归方法 void rDfs_output(int v); //深度优先搜索递归方法（输出DFS序列） static int *reach; //标记数组 static int label; //标记 static int *path; //路径 static int length; //路径长度public: linkedGraph(int numberOfVertices=0) {//构造函数 n=numberOfVertices; e=0; aList=new graphChain&lt;int&gt;[n+1]; } ~linkedGraph() {delete []aList;} int numberOfVertices() const {return n;} //返回顶点数 int numberOfEdges() const {return e;} //返回边数 void insertEdge(int i,int j); //插入一条边 void eraseEdge(int i,int j); //删除一条边 void bfs(int v,int reach[],int label); //广度优先搜索 void bfs_output(int v,int reach[],int label); //广度优先搜索（输出BFS序列） void dfs(int v,int reach[],int label); //深度优先搜索 void dfs_output(int v,int reach[],int label); //深度优先搜索（输出DFS序列） int labelComponents(int c[]); //返回无向图的构件个数 int* findPath(int theSource,int theDestination);//通过BFS求两点之间的最短路径 void sortedAList() //对aList[i]进行排序 { for(int i=1;i&lt;=n;i++) aList[i].bubbleSort(); } //迭代器 class myIterator { protected: graphChain&lt;int&gt; chain; chainNode&lt;int&gt;* currentVertexNode; public: myIterator(graphChain&lt;int&gt;&amp; theGraphChain) { chain=theGraphChain; currentVertexNode=chain.firstNode; } ~myIterator() {chain.firstNode=NULL;} int next() {//返回下一个顶点。若不存在则返回0 //寻找下一个邻接的顶点 while(currentVertexNode!=NULL) { chainNode&lt;int&gt;* p=currentVertexNode; currentVertexNode=currentVertexNode-&gt;next; return p-&gt;element; } //不存在下一个邻接的顶点 return 0; } }; myIterator* iterator(int theVertex) //访问指定顶点的相邻顶点 {//返回顶点theVertex的迭代器 return new myIterator(aList[theVertex]); }};int* linkedGraph::reach=NULL; //标记数组int linkedGraph::label=0; //标记int* linkedGraph::path=NULL; //路径int linkedGraph::length=0; //路径长度void linkedGraph::insertEdge(int i,int j){//插入一条边i,j //判断是否是新边 if(aList[i].indexOf(j)==-1) { aList[i].insert(0,j); aList[j].insert(0,i); e++; }}void linkedGraph::eraseEdge(int i,int j){//删除一条边i,j //判断边i,j是否存在 int *v=aList[i].eraseElement(j); if(v!=NULL) { aList[j].eraseElement(i); e--; }}int linkedGraph::labelComponents(int *c){//返回无向图的构件个数 //令所有顶点是非构件 for(int i=0;i&lt;=n;i++) c[i]=0; label=0; //确定构件 for(int i=1;i&lt;=n;i++) { if(c[i]==0) //顶点i未到达 { label++; bfs(i,c,label); //给新构件做标记 } } return label;}void linkedGraph::bfs(int v,int reach[],int label){ arrayQueue&lt;int&gt; q(10); reach[v]=label; q.push(v); while (!q.empty()) { //从队列中删除一个有标记的顶点 int w=q.front(); q.pop(); //标记所有邻接于顶点w的还没有到达的顶点 for(chainNode&lt;int&gt;* u=aList[w].firstNode;u!=NULL;u=u-&gt;next) { //访问顶点w的一个关联的顶点 if(reach[u-&gt;element]==0) {//u-&gt;element是一个没有到达的顶点 q.push(u-&gt;element); reach[u-&gt;element]=label; //到达标记 } } }}void linkedGraph::bfs_output(int v,int reach[],int label){ arrayQueue&lt;int&gt; q(10); reach[v]=label; cout&lt;&lt;v&lt;&lt;&quot; &quot;; q.push(v); while (!q.empty()) { //从队列中删除一个有标记的顶点 int w=q.front(); q.pop(); //标记所有邻接于顶点w的还没有到达的顶点 for(chainNode&lt;int&gt;* u=aList[w].firstNode;u!=NULL;u=u-&gt;next) { //访问顶点w的一个关联的顶点 if(reach[u-&gt;element]==0) {//u-&gt;element是一个没有到达的顶点 q.push(u-&gt;element); reach[u-&gt;element]=label; //到达标记 cout&lt;&lt;u-&gt;element&lt;&lt;&quot; &quot;; } } } cout&lt;&lt;endl;}void linkedGraph::dfs(int v,int reach[],int label){ linkedGraph::reach=reach; linkedGraph::label=label; rDfs(v);}void linkedGraph::rDfs(int v){//深度优先搜索递归方法 reach[v]=label; myIterator* iv=iterator(v); int u; while((u=iv-&gt;next())!=0) //访问与v相邻的顶点 if(reach[u]==0) rDfs(u); //u是一个没有到达的顶点 delete iv;}void linkedGraph::dfs_output(int v,int reach[],int label){ linkedGraph::reach=reach; linkedGraph::label=label; rDfs_output(v);}void linkedGraph::rDfs_output(int v){//深度优先搜索递归方法 reach[v]=label; cout&lt;&lt;v&lt;&lt;&quot; &quot;; myIterator* iv=iterator(v); int u; while((u=iv-&gt;next())!=0) //访问与v相邻的顶点 if(reach[u]==0) rDfs_output(u); //u是一个没有到达的顶点 delete iv;}int* linkedGraph::findPath(int theSource, int theDestination){//寻找一条从顶点theSource到顶点theDestination的最短路径 //返回一个数组path，从索引1开始表示路径，path[0]表示路径长度 //如果路径不存在，返回NULL //为寻找路径的算法初始化 bool exists=false; path=new int[n+1]; path[1]=theSource; length=0; int *parent=new int[n+1]; //节点的父节点 reach=new int[n+1]; for(int i=1;i&lt;=n;i++) reach[i]=0; //搜索路径 arrayQueue&lt;int&gt; q(10); reach[theSource]=1; q.push(theSource); while (!q.empty()) { //从队列中删除一个有标记的顶点 int w=q.front(); q.pop(); if(w==theDestination) //到达theDestination { exists=true; break; } //标记所有邻接于顶点w的还没有到达的顶点 for(chainNode&lt;int&gt;* u=aList[w].firstNode;u!=NULL;u=u-&gt;next) { //访问顶点w的一个关联的顶点 if(reach[u-&gt;element]==0) {//u-&gt;element是一个没有到达的顶点 q.push(u-&gt;element); reach[u-&gt;element]=label; //到达标记 parent[u-&gt;element]=w; //存储父节点 } } } if(theSource==theDestination || exists) //找到一条最短路径 { //根据parent逆向寻找路径 int i=theDestination; arrayStack&lt;int&gt; stack; stack.push(theDestination); //入栈 while (parent[i]!=theSource) { stack.push(parent[i]); i=parent[i]; } length=stack.size(); path[0]=length; //出栈 for(int k=2;k&lt;=length+1;k++) { path[k]=stack.top(); stack.pop(); } cout&lt;&lt;path[0]&lt;&lt;endl; } else //不存在路径 { delete []path; path=NULL; cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; } delete []reach; delete []parent; return path;}template &lt;class T&gt;void bubble_sort(T* array,int size) //及时终止的冒泡排序{ bool sorted=false; //判断是否有序 for(int i=0;i&lt;size-1&amp;&amp;!sorted;i++)//size个数最多进行(size-1)次冒泡 { sorted=true; //每次初始化为有序 for(int j=0;j&lt;size-1-i;j++) { if(array[j+1]&lt;array[j]) { swap(array[j],array[j+1]); sorted = false; //发生了交换,仍处于无序状态 } } }}int main(){ int n,m,s,t; //n个顶点，m个操作，s代表起始点，t代表终点 cin&gt;&gt;n&gt;&gt;m&gt;&gt;s&gt;&gt;t; int instruction,u,v; linkedGraph LG(n); //构建图 for(int i=0;i&lt;m;i++) { cin&gt;&gt;instruction&gt;&gt;u&gt;&gt;v; if(instruction==0) LG.insertEdge(u,v); else LG.eraseEdge(u,v); } int *c=new int[n+1]; //c[i]是顶点i的构件号 int *reachDFS=new int[n+1]; //DFS搜索时的标记数组 int *reachBFS=new int[n+1]; //BFS搜索时的标记数组 int cntDFS=0,cntBFS=0; //DFS和BFS序列长度 for(int i=1;i&lt;=n;i++) //初始化 reachDFS[i]=reachBFS[i]=0; //第一行输出图中有多少个连通分量 int components=LG.labelComponents(c); cout&lt;&lt;components&lt;&lt;endl; //第二行输出所有连通子图中最小点的编号（升序），编号间用空格分隔 int *min=new int[components]; //每个连通子图中的最小点的编号 for(int i=0;i&lt;components;i++) //初始化 min[i]=0; for(int i=1;i&lt;=n;i++) { if(min[c[i]-1]==0) min[c[i]-1]=i; else { if(i&lt;min[c[i]-1]) min[c[i]-1]=i; } } //对min[i]排序后输出 bubble_sort(min,components); for(int i=0;i&lt;components;i++) cout&lt;&lt;min[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; //第三行输出从s点开始的dfs序列长度 LG.dfs(s,reachDFS,1); for(int i=1;i&lt;=n;i++) if(reachDFS[i]==1) cntDFS++; cout&lt;&lt;cntDFS&lt;&lt;endl; //第四行输出从s点开始的字典序最小的dfs序列 LG.sortedAList(); for(int i=1;i&lt;=n;i++) reachDFS[i]=0; LG.dfs_output(s,reachDFS,1); cout&lt;&lt;endl; //第五行输出从t点开始的bfs序列的长度 LG.bfs(t,reachBFS,1); for(int i=1;i&lt;=n;i++) if(reachBFS[i]==1) cntBFS++; cout&lt;&lt;cntBFS&lt;&lt;endl; //第六行输出从t点开始字典序最小的bfs序列 LG.sortedAList(); for(int i=1;i&lt;=n;i++) reachBFS[i]=0; LG.bfs_output(t,reachBFS,1); //第七行输出从s点到t点的最短路径，若是不存在路径则输出-1 int *path=LG.findPath(s,t); //释放内存 delete []c; delete []reachDFS; delete []reachBFS; delete []path; delete []min; return 0;} 结果分析 1.求字典序最小的BFS和DFS序列，一种办法是在求之前对邻接表的每个链表排序，另一种办法是在插入边的时候，按照有序链表进行插入。 2.求所有连通子图最小点的编号，需要先求出连通子图个数，然后根据连通子图个数声明一个数组，用来保存每个连通子图的最小点编号。遍历所有顶点，根据该顶点的label值和数组中已经存储的编号，最终得到所有连通子图最小点的编号。进行排序后，即可按照升序输出。 3.求无权图中两个点之间的最短路径，使用BFS搜索即可，在搜索过程中保存当前节点的前驱节点，搜索结束后逆向寻找这条路径中的各个顶点。","link":"/2020/12/23/CS/DSA/DSA_12/"},{"title":"DSA：（四）链式描述线性表","text":"本文通过两个具体的题目实现线性表的链式描述，并为链表类封装了前向迭代器，链表类的方法包括插入、删除、原地逆置、查询、输出异或和、箱子排序、二路归并。 P1005:链表实现 要求 1.封装链表类，链表迭代器类。 2.链表类需提供操作：在指定位置插入元素，删除指定元素，搜索链表中是否有指定元素，原地逆置链表，输出链表。 3.不得使用与链表实现相关的STL。 描述 第一行两个整数N和Q。 第二行N个整数，作为节点的元素值，创建链表。 接下来Q行，执行各个操作，具体格式如下： 12345插入操作: 1 idx val //在链表的idx位置插入元素val删除操作: 2 val //删除链表中的val元素。若链表中存在多个该元素，仅删除第一个。若该元素不存在，输出-1逆置操作: 3 //原地逆置链表查询操作: 4 val //查询链表中的 val 元素，并输出其索引。若链表中存在多个该元素，仅输出第一个的索引。若不存在该元素，输出-1输出操作: 5 //使用链表迭代器，输出当前链表索引与元素的异或和 样例 输入 12345678910111210 106863 35084 11427 53377 34937 14116 5000 49692 70281 73704 4 68631 2 4419954 214661 6 1148354 3493754 68631 10 18635 输出 12345670398665-141014154101410 限制 1s 算法描述 定义结构体chainNode，数据成员包含element和next，element为数据域，next为指针域。方法包括三个重载的构造函数，默认构造函数，通过元素element创建节点，通过元素element和指针next创建节点。 使用链式存储结构，封装链表类chain，保护成员包括指向链表首节点的指针firstNode和链表长度listSize。公有成员包括构造函数，复制构造函数，析构函数，以及具体的方法，包括插入操作，删除操作，原地逆置操作，查询操作，输出操作。 定义链表类的迭代器iterator，保护成员为节点类的指针node，公有成员包括构造函数，操作符重载函数（解引用操作符 * 和-&gt;，前++，后++，相等检验中的!=和==），在chain类中增加方法begin和end，返回指向链表首元素的指针和尾元素的指针。 读入数据时，按行读入，首先读入操作数instruction，根据操作数利用switch分支进行分类，再根据所属操作类别读入对应的数据，调用对应的成员函数，输出数据。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;struct chainNode //节点类{ //数据成员 T element; chainNode&lt;T&gt;* next; //方法 chainNode() {} chainNode(const T&amp; element) { this-&gt;element=element; } chainNode(const T&amp; element,chainNode&lt;T&gt;* next) { this-&gt;element=element; this-&gt;next=next; }};template &lt;class T&gt;class chain //链表类{protected: chainNode&lt;T&gt;* firstNode; //指向链表第一个节点的指针 int listSize; //线性表的元素个数public: chain(); //构造函数 chain(const chain&lt;T&gt;&amp; theList); //复制构造函数 ~chain(); //析构函数 //方法 void insert(int idx,const T&amp; val); //在链表的idx位置插入元素val void erase(const T&amp; val); //删除链表中的val元素。若链表中存在多个该元素，仅删除第一个；若该元素不存在，输出-1。 void reverse(); //原地逆置链表 int search(const T&amp; val) const; //查询链表中的val元素，并输出其索引。若链表中存在多个该元素，仅输出第一个的索引；若不存在该元素，输出-1。 int output() const; //输出当前链表索引与元素的异或和 //迭代器 class iterator { protected: chainNode&lt;T&gt;* node; public: //用C++的typedef语句实现前向迭代器 typedef bidirectional_iterator_tag __iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference; iterator(chainNode&lt;T&gt;* theNode=NULL) //构造函数 { node=theNode; } //解引用操作符 T&amp; operator* () const {return node-&gt;element;} T* operator-&gt; () const {return &amp;node-&gt;element;} //迭代器加法操作 iterator&amp; operator++ ()//前++ { node=node-&gt;next; return *this; } iterator operator++ (int)//后++ { iterator old=*this; node=node-&gt;next; return old; } //相等检验 bool operator!= (const iterator&amp; right) const { return node!=right.node; } bool operator== (const iterator&amp; right) const { return node==right.node; } }; iterator begin() const { return iterator(firstNode); } iterator end() const { return iterator(NULL); }};template &lt;class T&gt;chain&lt;T&gt;::chain() //构造函数{ firstNode=NULL; listSize=0;}template &lt;class T&gt;chain&lt;T&gt;::chain(const chain&lt;T&gt;&amp; theList) //复制构造函数{ listSize=theList.listSize; //链表为空 if(listSize==0) { firstNode=NULL; return ; } //链表不为空 chainNode&lt;T&gt;* sourceNode=theList.firstNode; firstNode=new chainNode&lt;T&gt;(sourceNode-&gt;element);//复制theList的首元素 sourceNode=sourceNode-&gt;next; chainNode&lt;T&gt;* targetNode=firstNode; while(sourceNode!=NULL) //复制剩余元素 { targetNode-&gt;next=new chainNode&lt;T&gt;(sourceNode-&gt;element); targetNode=targetNode-&gt;next; sourceNode=sourceNode-&gt;next; } targetNode-&gt;next=NULL; //尾结点}template &lt;class T&gt;chain&lt;T&gt;::~chain() //析构函数{ while(firstNode!=NULL) { chainNode&lt;T&gt;* nextNode=firstNode-&gt;next; delete firstNode; firstNode=nextNode; }}template &lt;class T&gt;void chain&lt;T&gt;::insert(int idx,const T&amp; val) //插入操作{//在链表的idx位置插入元素val if(idx==0)//在链表头插入 { firstNode=new chainNode&lt;T&gt;(val,firstNode); } else { //寻找前驱 chainNode&lt;T&gt;* p=firstNode; for(int i=0;i&lt;idx-1;i++) p=p-&gt;next; //在p之后插入 p-&gt;next=new chainNode&lt;T&gt;(val,p-&gt;next); } listSize++;}template &lt;class T&gt;void chain&lt;T&gt;::erase(const T&amp; val) //删除操作{//删除链表中的val元素。若链表中存在多个该元素，仅删除第一个；若该元素不存在，输出-1。 chainNode&lt;T&gt;* deleteNode; //要删除的节点 if(firstNode-&gt;element==val) //删除的是链表的首节点 { deleteNode=firstNode; firstNode=firstNode-&gt;next; } else //删除的不是链表的首节点 { chainNode&lt;T&gt;* previousNode=firstNode; chainNode&lt;T&gt;* currentNode=firstNode-&gt;next; while(currentNode!=NULL &amp;&amp; currentNode-&gt;element!=val) { currentNode=currentNode-&gt;next; previousNode=previousNode-&gt;next; } if(currentNode==NULL) //链表中不存在要删除的元素 { cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; return ; } else //链表中存在要删除的元素 { deleteNode=currentNode; previousNode-&gt;next=currentNode-&gt;next; } } listSize--; delete deleteNode;}template &lt;class T&gt;void chain&lt;T&gt;::reverse() //原地逆置{ if(listSize==0) //链表为空 return ; else { chainNode&lt;T&gt;* currentNode=firstNode; //当前节点 while(currentNode-&gt;next) //当前节点还有后继元素 { chainNode&lt;T&gt;* p=currentNode-&gt;next; //储存当前节点的后继元素 currentNode-&gt;next=p-&gt;next; //将p断开 p-&gt;next=firstNode; //将p连在首节点的前面 firstNode=p; //设置p为首节点 } }}template &lt;class T&gt;int chain&lt;T&gt;::search(const T&amp; val) const //查询操作{//查询链表中的val元素，并输出其索引。若链表中存在多个该元素，仅输出第一个的索引；若不存在该元素，输出-1。 chainNode&lt;T&gt;* currentNode=firstNode; int index=0; //当前节点的索引 while(currentNode!=NULL &amp;&amp; currentNode-&gt;element!=val) { currentNode=currentNode-&gt;next; //移向下一个节点 index++; } //确定是否找到元素 if(currentNode!=NULL) return index; else { return -1; }}template &lt;class T&gt;int chain&lt;T&gt;::output() const //输出输出当前链表索引与元素的异或和{ int res=0,index=0; for(iterator i=this-&gt;begin();i!=this-&gt;end();i++) //通过迭代器遍历链表 { res+=index^*i; index++; } return res;}int main(){ int n,q; //n个整数 q行操作 int value; //读取初始链表的各个元素值 int instruction; //指令编号 int idx,val; //读入的索引、元素信息 cin&gt;&gt;n&gt;&gt;q; chain&lt;int&gt; A; //创建对象 for(int i=0;i&lt;n;i++) //将数据插入链表 { cin&gt;&gt;value; A.insert(i,value); } //执行各项操作 for(int i=0;i&lt;q;i++) { cin&gt;&gt;instruction; switch(instruction) { case 1: //插入操作 cin&gt;&gt;idx&gt;&gt;val; A.insert(idx,val); break; case 2: //删除操作 cin&gt;&gt;val; A.erase(val); break; case 3: //原地逆置 A.reverse(); break; case 4: //查询操作 cin&gt;&gt;val; cout&lt;&lt;A.search(val)&lt;&lt;endl; break; case 5: //输出操作 cout&lt;&lt;A.output()&lt;&lt;endl; break; } } return 0;} 结果分析 1.迭代器可以理解为广义的指针，在链表的一些操作中，使用迭代器会减少一些操作的时间复杂度。例如，在链表chain中，从左至右访问线性表的元素时，使用get方法和使用迭代器方法，在运行时间上的差别是很大的。如果一次考察一个元素，get方法的时间复杂度为O(n^2)，迭代器方法的时间复杂度为O(n)。 2.对chain类可以扩展一些ADT方法，比如clear（清除表中所有元素）和push_back(theElement)（将元素theElement插入表尾）。以chain类为基类，派生出extendedChain类，在extendedChain类中增加protected成员lastNode，实现方法clear和push_back，改进erase和insert方法。 P1006:链表合并 要求 1.使用题目“链表实现”中实现的链表类、迭代器类完成本题。 2.不得使用与题目实现相关的STL。 描述 给定两组整数序列，你需要分别创建两个有序链表，使用链表迭代器实现链表的合并，并分别输出这三个有序链表的索引与元素的异或和。 Note:给定序列是无序的，你需要首先得到一个有序的链表。 格式 输入 第一行两个整数N和M。 第二行N个整数，代表第一组整数序列。 第三行M个整数，代表第二组整数序列。 输出 三行整数。分别代表第一组数、第二组数对应的有序链表与合并后有序链表的索引与元素的异或和。 样例 输入 123 03 1 2 输出 123505 限制 1s 算法描述 使用已经封装的链表类和迭代器，增加方法getMax求链表元素的最大值，getMin求链表元素的最小值，binSort进行箱子排序，merge实现两个链表的归并。 binSort的两个参数为链表元素的最大值和最小值，首先判断是否是空表，若是空表直接返回。若不是空表，根据min和max的值判断链表中元素的正负，分为三种情况，均&gt;=0，均&lt;=0，有正有负，对应相应的range（范围）和offset（偏移量），再进行箱子排序。在分配箱子时，将对应元素分配到theBin+offset的箱子中，收集箱子时，按照theBin从0到range进行收集。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;struct chainNode //节点类{ //数据成员 T element; chainNode&lt;T&gt;* next; //方法 chainNode() {} chainNode(const T&amp; element) { this-&gt;element=element; } chainNode(const T&amp; element,chainNode&lt;T&gt;* next) { this-&gt;element=element; this-&gt;next=next; }};template &lt;class T&gt;class chain //链表类{protected: chainNode&lt;T&gt;* firstNode; //指向链表第一个节点的指针 int listSize; //线性表的元素个数public: chain(); //构造函数 chain(const chain&lt;T&gt;&amp; theList); //复制构造函数 ~chain(); //析构函数 //方法 void insert(int idx,const T&amp; val); //在链表的idx位置插入元素val void erase(const T&amp; val); //删除链表中的val元素。若链表中存在多个该元素，仅删除第一个；若该元素不存在，输出-1。 void reverse(); //原地逆置链表 int search(const T&amp; val) const; //查询链表中的val元素，并输出其索引。若链表中存在多个该元素，仅输出第一个的索引；若不存在该元素，输出-1。 int output() const; //输出当前链表索引与元素的异或和 int size() const {return listSize;} //返回链表的元素个数 int getMax() const; //求链表中元素的最大值 int getMin() const; //求链表中元素的最小值 void binSort(int max,int min); //箱子排序 void merge(const chain&lt;T&gt;&amp; a,const chain&lt;T&gt;&amp; b);//将链表a,b归并到当前链表中 //迭代器 class iterator { protected: chainNode&lt;T&gt;* node; public: //用C++的typedef语句实现前向迭代器 typedef bidirectional_iterator_tag __iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference; iterator(chainNode&lt;T&gt;* theNode=NULL) //构造函数 { node=theNode; } //解引用操作符 T&amp; operator* () const {return node-&gt;element;} T* operator-&gt; () const {return &amp;node-&gt;element;} //迭代器加法操作 iterator&amp; operator++ ()//前++ { node=node-&gt;next; return *this; } iterator operator++ (int)//后++ { iterator old=*this; node=node-&gt;next; return old; } //相等检验 bool operator!= (const iterator&amp; right) const { return node!=right.node; } bool operator== (const iterator&amp; right) const { return node==right.node; } }; iterator begin() const { return iterator(firstNode); } iterator end() const { return iterator(NULL); }};template &lt;class T&gt;chain&lt;T&gt;::chain() //构造函数{ firstNode=NULL; listSize=0;}template &lt;class T&gt;chain&lt;T&gt;::chain(const chain&lt;T&gt;&amp; theList) //复制构造函数{ listSize=theList.listSize; //链表为空 if(listSize==0) { firstNode=NULL; return ; } //链表不为空 chainNode&lt;T&gt;* sourceNode=theList.firstNode; firstNode=new chainNode&lt;T&gt;(sourceNode-&gt;element);//复制theList的首元素 sourceNode=sourceNode-&gt;next; chainNode&lt;T&gt;* targetNode=firstNode; while(sourceNode!=NULL) //复制剩余元素 { targetNode-&gt;next=new chainNode&lt;T&gt;(sourceNode-&gt;element); targetNode=targetNode-&gt;next; sourceNode=sourceNode-&gt;next; } targetNode-&gt;next=NULL; //尾结点}template &lt;class T&gt;chain&lt;T&gt;::~chain() //析构函数{ while(firstNode!=NULL) { chainNode&lt;T&gt;* nextNode=firstNode-&gt;next; delete firstNode; firstNode=nextNode; }}template &lt;class T&gt;void chain&lt;T&gt;::insert(int idx,const T&amp; val) //插入操作{//在链表的idx位置插入元素val if(idx==0)//在链表头插入 { firstNode=new chainNode&lt;T&gt;(val,firstNode); } else { //寻找前驱 chainNode&lt;T&gt;* p=firstNode; for(int i=0;i&lt;idx-1;i++) p=p-&gt;next; //在p之后插入 p-&gt;next=new chainNode&lt;T&gt;(val,p-&gt;next); } listSize++;}template &lt;class T&gt;void chain&lt;T&gt;::erase(const T&amp; val) //删除操作{//删除链表中的val元素。若链表中存在多个该元素，仅删除第一个；若该元素不存在，输出-1。 chainNode&lt;T&gt;* deleteNode; //要删除的节点 if(firstNode-&gt;element==val) //删除的是链表的首节点 { deleteNode=firstNode; firstNode=firstNode-&gt;next; } else //删除的不是链表的首节点 { chainNode&lt;T&gt;* previousNode=firstNode; chainNode&lt;T&gt;* currentNode=firstNode-&gt;next; while(currentNode!=NULL &amp;&amp; currentNode-&gt;element!=val) { currentNode=currentNode-&gt;next; previousNode=previousNode-&gt;next; } if(currentNode==NULL) //链表中不存在要删除的元素 { cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; return ; } else //链表中存在要删除的元素 { deleteNode=currentNode; previousNode-&gt;next=currentNode-&gt;next; } } listSize--; delete deleteNode;}template &lt;class T&gt;void chain&lt;T&gt;::reverse() //原地逆置{ if(listSize==1) //链表只有一个元素 return ; else { chainNode&lt;T&gt;* currentNode=firstNode; //当前节点 while(currentNode-&gt;next) //当前节点还有后继元素 { chainNode&lt;T&gt;* p=currentNode-&gt;next; //储存当前节点的后继元素 currentNode-&gt;next=p-&gt;next; //将p断开 p-&gt;next=firstNode; //将第一个节点连在p的后面 firstNode=p; //设置p为第一个节点 } }}template &lt;class T&gt;int chain&lt;T&gt;::search(const T&amp; val) const //查询操作{//查询链表中的val元素，并输出其索引。若链表中存在多个该元素，仅输出第一个的索引；若不存在该元素，输出-1。 chainNode&lt;T&gt;* currentNode=firstNode; int index=0; //当前节点的索引 while(currentNode!=NULL &amp;&amp; currentNode-&gt;element!=val) { currentNode=currentNode-&gt;next; //移向下一个节点 index++; } //确定是否找到元素 if(currentNode!=NULL) return index; else { return -1; }}template &lt;class T&gt;int chain&lt;T&gt;::output() const //输出当前链表索引与元素的异或和{ int res=0,index=0; for(iterator i=this-&gt;begin();i!=this-&gt;end();i++) //通过迭代器遍历链表 { res+=index^*i; index++; } return res;}template &lt;class T&gt;int chain&lt;T&gt;::getMax() const //求当前链表中元素的最大值{ if(listSize==0) //空表 return 0; int max=firstNode-&gt;element; chainNode&lt;T&gt;* currentNode=firstNode-&gt;next; while(currentNode!=NULL) { if(currentNode-&gt;element&gt;max) max=currentNode-&gt;element; currentNode=currentNode-&gt;next; } return max;}template &lt;class T&gt;int chain&lt;T&gt;::getMin() const //求当前链表中元素的最小值{ if(listSize==0) //空表 return 0; int min=firstNode-&gt;element; chainNode&lt;T&gt;* currentNode=firstNode-&gt;next; while(currentNode!=NULL) { if(currentNode-&gt;element&lt;min) min=currentNode-&gt;element; currentNode=currentNode-&gt;next; } return min;}template &lt;class T&gt;void chain&lt;T&gt;::binSort(int max,int min) //箱子排序{ //空表 if(listSize==0) return ; //不是空表 int range=0,offset=0; //范围和偏移量 if(min&gt;=0) //链表所有元素均为非负整数 { range=max; offset=0; } else if(max&lt;=0) //链表所有元素均为非正整数 { range=-min; offset=-min; } else //链表元素有正有负 { range=max-min; offset=-min; } //创建并初始化箱子 chainNode&lt;T&gt; **bottom,**top; bottom=new chainNode&lt;T&gt;* [range+1]; top=new chainNode&lt;T&gt;* [range+1]; for(int i=0;i&lt;=range;i++) //初始化为空 bottom[i]=NULL; //把链表的节点分配到箱子 for(;firstNode!=NULL;firstNode=firstNode-&gt;next) {//把首节点firstNode加到箱子中 int theBin=firstNode-&gt;element; if(bottom[theBin+offset]==NULL) //箱子为空 bottom[theBin+offset]=top[theBin+offset]=firstNode; else //箱子不为空 { top[theBin+offset]-&gt;next=firstNode; top[theBin+offset]=firstNode; } } //把箱子中的节点收集到有序链表 chainNode&lt;T&gt; *y=NULL; for(int theBin=0;theBin&lt;=range;theBin++) { if(bottom[theBin]!=NULL) //箱子不空 { if(y==NULL) //收集的是第一个非空箱子 firstNode=bottom[theBin]; else //收集的不是第一个非空箱子 y-&gt;next=bottom[theBin]; y=top[theBin]; } } if(y!=NULL) //处理尾结点 y-&gt;next=NULL; delete [] bottom; delete [] top;}template &lt;class T&gt;void chain&lt;T&gt;::merge(const chain&lt;T&gt; &amp;a, const chain&lt;T&gt; &amp;b) //将链表a,b归并到当前链表中{ int index=0; iterator ia=a.begin(),ib=b.begin(); while(ia!=a.end() &amp;&amp; ib!=b.end()) { if(*ia&lt;*ib) //将*ia并入 { insert(index++,*ia); ia++; } else //将*ib并入 { insert(index++,*ib); ib++; } } //对a或b中剩余元素进行归并 while(ia!=a.end()) { insert(index++,*ia); ia++; } while(ib!=b.end()) { insert(index++,*ib); ib++; } listSize=a.size()+b.size();}int main(){ int n,m; //两个整数 int value; //读取初始链表的各个元素值 cin&gt;&gt;n&gt;&gt;m; chain&lt;int&gt; A,B,C; //创建对象 for(int i=0;i&lt;n;i++) //将数据插入链表A { cin&gt;&gt;value; A.insert(i,value); } for(int i=0;i&lt;m;i++) //将数据插入链表B { cin&gt;&gt;value; B.insert(i,value); } A.binSort(A.getMax(),A.getMin()); B.binSort(B.getMax(),B.getMin()); C.merge(A,B); cout&lt;&lt;A.output()&lt;&lt;endl; cout&lt;&lt;B.output()&lt;&lt;endl; cout&lt;&lt;C.output()&lt;&lt;endl; return 0;} 结果分析 1.一般情况的箱子排序只需要参数range，条件是链表中的元素值均为非负整数，而题目中链表元素值包括负数，因此需要根据链表中的最大值和最小值确定range和offset。 2.由箱子排序衍生出基数排序，所谓基数排序，是把数按照某种基数r分解为数字，然后对数字排序。例如，用基数10把十进制数928分解为9、2、8。利用箱子排序方法，从最低位开始依次到最高位，根据当前位的数字对数据进行排序。基数排序和箱子排序时间复杂度虽然相同，但使用基数排序极大地减少了程序的执行步数。单个的箱子排序实际上相当于r=1000的基数排序。基数排序的基数不同，总的执行步数也不同，根据实际数据确定基数减少执行步数。 3.箱子排序和基数排序都是稳定的。 4.箱子排序还有类外函数的实现方法，但执行了很多new和delete操作将节点从一个位置移动到另一个位置，虽然时间复杂度与成员函数相同，但效率比较低。","link":"/2020/10/14/CS/DSA/DSA_4/"},{"title":"DSA：（十一）搜索树","text":"二叉搜索树查找、删除、插入操作的平均性能为O(logn)，最坏情况下的性能为O(n)。索引二叉搜索树为每个节点增加了leftSize域，记录该节点左子树的元素个数，可以按名次进行查找和删除操作，在插入和删除后需要对一些节点的leftSize值进行更新。 P1018:二叉搜索树 描述 创建带索引的二叉搜索树类。存储结构使用链表，提供操作:插入、删除、按名次删除、查找、按名次查找、升序输出所有元素。 格式 输入 输入第一行一个数字m (m&lt;=1000000)，表示有m个操作。 接下来m行，每一行有两个数字a，b： 当输入的第一个数字a为0时，输入的第二个数字b表示向搜索树中插入b。 当输入的第一个数字a为1时，输入的第二个数字b表示向搜索树中查找b。 当输入的第一个数字a为2时，输入的第二个数字b表示向搜索树中删除b。 当输入的第一个数字a为3时，输入的第二个数字b表示查找搜索树中名次为b的元素。 当输入的第一个数字a为4时，输入的第二个数字b表示删除搜索树中名次为b的元素。 输出 对于输入中的每一种操作，输出执行操作的过程中依次比较的元素值的异或值。 注意 查询与删除操作中，待查询的元素也需要异或入答案中。 查找（删除）操作中，如果未找到，或者插入操作，已存在，输出0（不插入），不需要输出异或和。 查找（删除）第b大，如果不存在，输出0。 删除操作中，如果当前元素有两个孩子，替换的为右子树中最小的，如果只有一个孩子，直接用该孩子替换当前元素，如果没有孩子，直接删除。 删除操作的替换过程中所有比较操作不计入答案。 样例 样例1 输入 1234567891011121314130 60 70 40 50 11 50 73 32 41 53 44 30 4 输出 123456789101112130662270723163 样例2 输入 123456789101112131415140 430 170 550 620 570 660 674 50 670 703 64 70 202 43 输出 123456789101112131404343283434963402929915843 限制 1s, 10240KiB for each test case. 提示 查找和删除第k大的元素时，可以先把第k的元素找到，再按照该元素查找和删除。 算法描述 封装索引二叉搜索树类indexedBinarySearchTree，二叉树的存储结构使用链表，每个节点包括关键字key，左子树的元素个数leftSize，左孩子leftChild，右孩子rightChild。节点类的构造函数有四个，默认构造函数，通过theKey构造，通过theKey，theLeftChild，theRightChild构造（构造函数中计算leftSize值），通过theKey，theLeftSize，theLeftChild，theRightChild构造。索引二叉搜索树类中，非静态的私有成员包括根节点root，树的节点个数treeSize，静态的私有成员包括访问函数visit，前序遍历preOrder，中序遍历inOrder，后序遍历postOrder，删除t指向的节点dispose方法，输出该节点的关键字的output方法。公有成员包括构造函数，析构函数，empty方法，size方法，前序遍历，中序遍历，后序遍历，层次遍历，删除二叉树的erase方法，查找关键字的find方法，插入关键字的insert方法，删除关键字的erase方法，获取名次为b的节点的关键字的get方法，插入操作后更新leftSize域的updateLeftSizeAfterInsert方法，删除操作后更新leftSize域的updateLeftSizeAfterErase_1，updateLeftSizeAfterErase_2方法，两种方法针对删除操作中的两种情况进行相应更新。 find：查找关键字为theKey的节点，如果找到输出查找过程中依次比较的元素值的异或和，如果未找到输出0，不需要输出异或和。指针p从根节点开始搜索，寻找关键字等于theKey的节点，直到p为空为止。循环体首先进行异或操作，然后根据theKey和p-&gt;key的大小关系判断是否找到以及进左子树还是右子树。 insert：插入关键字为theKey的节点，如果不存在关键字为theKey的节点，输出插入过程中依次比较的元素值的异或和，如果已存在关键字为theKey的节点，输出0，不需要输出异或和。指针p从根节点开始搜索，寻找插入的位置，用指针pp保存p的父节点，根据theKey和p-&gt;key的大小关系判断是否已经存在关键字为theKey的节点以及进左子树还是右子树。根据theKey建立一个新节点，根据root是否为空判断是否是插入到一颗空树中，然后通过pp将其连在搜索树上。插入后，treeSize加一，调用updateLeftSizeAfterInsert方法对从根节点到插入点的路径上的节点的leftSize值进行更新。指针x从根节点开始，如果theKey小于x-&gt;key，当前节点的leftSize需要加一，如果theKey大于x-&gt;key，当前节点的leftSize不需要更新。最后输出异或值。 erase：删除关键字为theKey的节点，输出删除过程中依次比较的元素值的异或和，替换过程中的所有比较操作不计入答案。如果当前节点有两个孩子，用右子树中关键字最小的节点进行替换。如果只有一个孩子，直接用该节点的孩子进行替换。如果没有孩子，直接删除。如果不存在，输出0。指针p从根节点开始搜索，pp为p的父节点。搜索完毕后根据p是否为空判断是否存在关键字为theKey的节点。若不存在，输出0然后返回。若存在，根据p的孩子个数分两种情况进行考虑。 （1）p有两个孩子：转化为第（2）中情况。在p的右子树中沿着leftChild寻找最小元素s替代被删除的节点。替代过程是根据s-&gt;key，p-&gt;leftSize，p-&gt;leftChild，p-&gt;rightChild新建一个节点，将其连在pp上，更新指针pp，删除p节点，然后让p指向s（这是为了保证（2）中对节点s的删除）。 （2）p至多有一个孩子：将孩子指针存在c中，将pp和c连起来，删除p，treeSize减一。最后输出异或值。 对leftSize的更新在（1）过程之后（如果有的话），（2）过程之前进行。使用flag标记（1）过程是否进行，如果（1）过程执行，即要删除的节点有两个孩子，调用updateLeftSizeAfterErase_2，否则调用updateLeftSizeAfterErase_1。 updateLeftSizeAfterErase_2：要删除的节点有两个孩子，对从root到p的路径上的节点的leftSize进行更新。参数为节点类的指针s。指针x从根节点开始，当x不等于s时，执行while循环，通过x-&gt;key和s-&gt;key的大小关系进行相应节点的leftSize的更新。注意等于的特殊情况，第一次遇到相等的情况，表示x为替换后的节点，因为是用右子树的最小元素进行替换，所以直接进入右子树即可，第二次遇到表示路径寻找完毕。 updateLeftSizeAfterErase_1：要删除的节点至多有一个孩子，对从root到p的路径上的节点的leftSize进行更新。参数为关键字值theKey。指针x从根节点开始，当x不为空时，执行while循环，通过theKey和x-&gt;key的大小关系进行相应节点的leftSize的更新，若相等则路径寻找完毕。 get：返回第index个元素的关键字的值（index从0开始）。指针x从根节点开始搜索，如果index等于x-&gt;leftSize，则找到该元素，如果index小于x-&gt;leftSize，则第index个元素是左子树的第index个元素，如果index大于x-&gt;leftSize，则第index个元素是右子树的第(index-(x-&gt;leftSize+1))个元素。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;struct indexedBinarySearchTreeNode{ T key; //关键字 int leftSize; //左子树的元素个数 indexedBinarySearchTreeNode&lt;T&gt; *leftChild,*rightChild; //左孩子和右孩子 indexedBinarySearchTreeNode() { leftChild=rightChild=NULL; leftSize=0; } indexedBinarySearchTreeNode(const T&amp; theKey) { key=theKey; leftChild=rightChild=NULL; leftSize=0; } indexedBinarySearchTreeNode(const T&amp; theKey,indexedBinarySearchTreeNode&lt;T&gt; *theLeftChild,indexedBinarySearchTreeNode&lt;T&gt; *theRightChild) { key=theKey; leftChild=theLeftChild; rightChild=theRightChild; leftSize=0; //计算leftSize的值 indexedBinarySearchTreeNode&lt;T&gt; *p=theLeftChild; while(p!=NULL) //从根沿着右子树的路径计算节点个数 { leftSize+=p-&gt;leftSize+1; p=p-&gt;rightChild; } } indexedBinarySearchTreeNode(const T&amp; theKey,int theLeftSize,indexedBinarySearchTreeNode&lt;T&gt; *theLeftChild,indexedBinarySearchTreeNode&lt;T&gt; *theRightChild) { key=theKey; leftSize=theLeftSize; leftChild=theLeftChild; rightChild=theRightChild; }};template &lt;class T&gt;class indexedBinarySearchTree{private: indexedBinarySearchTreeNode&lt;T&gt; *root; //根节点 int treeSize; //树的节点数量 static void (*visit)(indexedBinarySearchTreeNode&lt;T&gt; *); //访问函数 static void preOrder(indexedBinarySearchTreeNode&lt;T&gt; *t); //前序遍历 static void inOrder(indexedBinarySearchTreeNode&lt;T&gt; *t); //中序遍历 static void postOrder(indexedBinarySearchTreeNode&lt;T&gt; *t); //后序遍历 static void dispose(indexedBinarySearchTreeNode&lt;T&gt; *t) {delete t;} //删除t指向的节点 static void output(indexedBinarySearchTreeNode&lt;T&gt; *t) {cout&lt;&lt;t-&gt;key&lt;&lt;&quot; &quot;;} //输出节点的关键字public: indexedBinarySearchTree() {root=NULL; treeSize=0;} ~indexedBinarySearchTree() {erase();} bool empty() const {return treeSize==0;} int size() const {return treeSize;} void preOrder(void(*theVisit)(indexedBinarySearchTreeNode&lt;T&gt;*)) { visit=theVisit; preOrder(root); } void inOrder(void(*theVisit)(indexedBinarySearchTreeNode&lt;T&gt;*)) { visit=theVisit; inOrder(root); } void postOrder(void(*theVisit)(indexedBinarySearchTreeNode&lt;T&gt;*)) { visit=theVisit; postOrder(root); } void inOrderOutput() {inOrder(output); cout&lt;&lt;endl;} //输出中序序列 void erase() //删除二叉树 { postOrder(dispose); root=NULL; treeSize=0; } T* find(const T&amp; theKey) const; //查找关键字为theKey的节点 void insert(const T&amp; theKey); //插入关键字为theKey的节点 void erase(const T&amp; theKey); //删除关键字为theKey的节点 T get(int index); //获得名次为b的节点的关键字 void updateLeftSizeAfterInsert(const T&amp; theKey); //插入操作后对leftSize域的更新 void updateLeftSizeAfterErase_1(const T&amp; theKey); //要删除的节点p最多有一个孩子，删除操作后对root到p的路径上节点的leftSize域进行更新 void updateLeftSizeAfterErase_2(indexedBinarySearchTreeNode&lt;T&gt; *s); //要删除的节点p有两个孩子，删除操作后对root到p的路径上节点的leftSize域进行更新};template &lt;class T&gt;void (*indexedBinarySearchTree&lt;T&gt;::visit)(indexedBinarySearchTreeNode&lt;T&gt;*)=NULL; //类的静态成员的初始化template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::preOrder(indexedBinarySearchTreeNode&lt;T&gt; *t){ if(t!=NULL) { indexedBinarySearchTree&lt;T&gt;::visit(t); preOrder(t-&gt;leftChild); preOrder(t-&gt;rightChild); }}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::inOrder(indexedBinarySearchTreeNode&lt;T&gt; *t){ if(t!=NULL) { inOrder(t-&gt;leftChild); indexedBinarySearchTree&lt;T&gt;::visit(t); inOrder(t-&gt;rightChild); }}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::postOrder(indexedBinarySearchTreeNode&lt;T&gt; *t){ if(t!=NULL) { postOrder(t-&gt;leftChild); postOrder(t-&gt;rightChild); indexedBinarySearchTree&lt;T&gt;::visit(t); }}template &lt;class T&gt;T* indexedBinarySearchTree&lt;T&gt;::find(const T &amp;theKey) const{//查找关键字为theKey的节点 //如果找到输出查找过程中依次比较的元素值的异或和 //如果未找到输出0，不需要输出异或和 int value=0; //异或和 //指针p从根开始搜索，寻找关键字等于theKey的节点 indexedBinarySearchTreeNode&lt;T&gt; *p=root; while(p!=NULL) { value^=p-&gt;key; //异或 if(theKey&lt;p-&gt;key) p=p-&gt;leftChild; else if(theKey&gt;p-&gt;key) p=p-&gt;rightChild; else { cout&lt;&lt;value&lt;&lt;endl; return &amp;p-&gt;key; } } //未找到关键字为theKey的节点 cout&lt;&lt;&quot;0&quot;&lt;&lt;endl; return NULL;}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::insert(const T &amp;theKey){//插入关键字为theKey的节点 //如果不存在关键字为theKey的节点，输出插入过程中依次比较的元素值的异或和 //如果已存在关键字为theKey的节点，输出0，不需要输出异或和 int value=0; //异或和 indexedBinarySearchTreeNode&lt;T&gt; *p=root,*pp=NULL; //p从根节点开始，pp为p的父节点 //寻找插入点 while(p!=NULL) { value^=p-&gt;key; //异或 pp=p; //将p移向孩子节点 if(theKey&lt;p-&gt;key) p=p-&gt;leftChild; else if(theKey&gt;p-&gt;key) p=p-&gt;rightChild; else //已存在关键字为theKey的节点 { cout&lt;&lt;&quot;0&quot;&lt;&lt;endl; return ; } } //为theKey建立一个新节点，并将该节点连接到pp indexedBinarySearchTreeNode&lt;T&gt; *newNode=new indexedBinarySearchTreeNode&lt;T&gt;(theKey); if(root!=NULL) //树非空 { if(theKey&lt;pp-&gt;key) pp-&gt;leftChild=newNode; else pp-&gt;rightChild=newNode; } else //插入到空树中 root=newNode; //更新treeSize和路径上节点的leftSize treeSize++; updateLeftSizeAfterInsert(theKey); cout&lt;&lt;value&lt;&lt;endl;}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::erase(const T&amp; theKey){//删除关键字为theKey的节点，输出删除过程中依次比较的元素值的异或和，替换过程中的所有比较操作不计入答案 //如果当前节点有两个孩子，用右子树中关键字最小的节点进行替换 //如果只有一个孩子，直接用该节点的孩子进行替换 //如果没有孩子，直接删除 //如果不存在，输出0 int value=0,flag=0; //异或值和标记 indexedBinarySearchTreeNode&lt;T&gt; *p=root,*pp=NULL; while (p!=NULL &amp;&amp; p-&gt;key!=theKey) {//p移动到它的孩子节点 value^=p-&gt;key; pp=p; if(theKey&lt;p-&gt;key) p=p-&gt;leftChild; else p=p-&gt;rightChild; } if(p==NULL) //不存在关键字theKey的节点 { cout&lt;&lt;&quot;0&quot;&lt;&lt;endl; return ; } //重新组织树结构 //当p有两个孩子时的处理 if(p-&gt;leftChild!=NULL &amp;&amp; p-&gt;rightChild!=NULL) {//两个孩子 flag=1; //转化为空或只有一个孩子 //在p的右子树中寻找最小元素 indexedBinarySearchTreeNode&lt;T&gt; *s=p-&gt;rightChild,*ps=p; while(s-&gt;leftChild!=NULL) {//移动到最小元素 ps=s; s=s-&gt;leftChild; } //将最小元素s移动到p indexedBinarySearchTreeNode&lt;T&gt; *q=new indexedBinarySearchTreeNode&lt;T&gt;(s-&gt;key,p-&gt;leftSize,p-&gt;leftChild,p-&gt;rightChild); if(pp==NULL) //p为根节点 root=q; else if(p==pp-&gt;leftChild) pp-&gt;leftChild=q; else pp-&gt;rightChild=q; //更新p和p的父节点 if(ps==p) pp=q; else pp=ps; delete p; p=s; } //在进行删除前更新leftSize if(flag==1) //删除的节点有两个孩子 updateLeftSizeAfterErase_2(p); else //删除的节点最多有一个孩子 updateLeftSizeAfterErase_1(theKey); //p最多有一个孩子 //把孩子指针存放在c indexedBinarySearchTreeNode&lt;T&gt; *c; if(p-&gt;leftChild!=NULL) c=p-&gt;leftChild; else c=p-&gt;rightChild; //删除p if(p==root) root=c; else //p是pp的左孩子还是右孩子 { if(p==pp-&gt;leftChild) pp-&gt;leftChild=c; else pp-&gt;rightChild=c; } treeSize--; delete p; value^=theKey; cout&lt;&lt;value&lt;&lt;endl;}template &lt;class T&gt;T indexedBinarySearchTree&lt;T&gt;::get(int index){//返回第index个元素的关键字的值 //index从0开始 indexedBinarySearchTreeNode&lt;T&gt; *x=root; while(x!=NULL) { if(index==x-&gt;leftSize) //第index个元素是x-&gt;key break; else if(index&lt;x-&gt;leftSize) //第index个元素是左子树的第index个元素 x=x-&gt;leftChild; else //第index个元素是右子树的第(index-(x-&gt;leftSize+1))个元素 { index=index-(x-&gt;leftSize+1); x=x-&gt;rightChild; } } return x-&gt;key;}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::updateLeftSizeAfterInsert(const T &amp;theKey){//插入操作后对leftSize域的更新 indexedBinarySearchTreeNode&lt;T&gt; *x=root; //寻找从根开始到关键字为theKey的节点的路径 while(x!=NULL) { if(theKey&lt;x-&gt;key) //插入节点在x的左子树中，leftSize++ { x-&gt;leftSize++; x=x-&gt;leftChild; } else if(theKey&gt;x-&gt;key) //插入节点在x的右子树中 x=x-&gt;rightChild; else //路径寻找完毕 break; }}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::updateLeftSizeAfterErase_1(const T &amp;theKey){//要删除的节点p最多有一个孩子，删除操作后对root到p的路径上节点的leftSize域 indexedBinarySearchTreeNode&lt;T&gt; *x=root; //寻找从根开始到关键字为theKey的节点的路径 while(x!=NULL) { if(theKey&lt;x-&gt;key) //删除节点在x的左子树中，leftSize-- { x-&gt;leftSize--; x=x-&gt;leftChild; } else if(theKey&gt;x-&gt;key) //删除节点在x的右子树中 x=x-&gt;rightChild; else //路径寻找完毕 break; }}template &lt;class T&gt;void indexedBinarySearchTree&lt;T&gt;::updateLeftSizeAfterErase_2(indexedBinarySearchTreeNode&lt;T&gt; *s){//要删除的节点p有两个孩子，删除操作后对root到p的路径上节点的leftSize域进行更新 indexedBinarySearchTreeNode&lt;T&gt; *x=root; bool meet=false; //标记是否是第一次遇到关键字为s-&gt;key的节点 //寻找从根开始到s的路径 while(x!=s) { if(s-&gt;key&lt;x-&gt;key) //删除节点在x的左子树中，leftSize-- { x-&gt;leftSize--; x=x-&gt;leftChild; } else if(s-&gt;key&gt;x-&gt;key) //删除节点在x的右子树中 x=x-&gt;rightChild; else { if(!meet) //第一次遇到相同关键字的节点 { meet=true; //这个节点的关键字已经被右子树的最小元素替换 x=x-&gt;rightChild; //要删除的节点位于右子树，所以将指针指向右孩子 } else //第二次遇到，路径寻找完毕 break; } }}int main(){ indexedBinarySearchTree&lt;int&gt; IBST; int m,instruction,b; cin&gt;&gt;m; for(int i=0;i&lt;m;i++) { cin&gt;&gt;instruction; switch (instruction) { case 0: cin&gt;&gt;b; IBST.insert(b); break; case 1: cin&gt;&gt;b; IBST.find(b); break; case 2: cin&gt;&gt;b; IBST.erase(b); break; case 3: cin&gt;&gt;b; IBST.find(IBST.get(b-1)); break; default: cin&gt;&gt;b; IBST.erase(IBST.get(b-1)); } } return 0;} 结果分析 1.updateLeftSizeAfterErase_1和updateLeftSizeAfterErase_2可以合并成updateLeftSize AfterErase，参数为索引二叉搜索树节点类的指针。while循环条件是x!=s，如果s-&gt;key小于x-&gt;key，x-&gt;leftSize减一，x=x-&gt;leftChild，否则x=x-&gt;rightChild。 2.插入节点时，对leftSize更新不能边寻找边更新，因为有可能该节点已经存在，不需要再插入，所以需要在插入操作完成后再根据theKey更新。","link":"/2020/12/23/CS/DSA/DSA_11/"},{"title":"DSA：（六）栈","text":"数学表达式根据运算符和数字的相对位置可以分为前缀、中缀、后缀三种，前缀表达式又叫波兰表达式，后缀表达式又叫逆波兰表达式，这两种表达式都不含括号。中缀表达式可以转换为前缀表达式和后缀表达式，转换过程以及计算过程都需要用到栈结构。本文通过两种方法实现数学表达式的计算，方法一将中缀表达式转换为后缀表达式，然后进行计算，方法二直接对中缀表达式进行计算。 P1010:计算表达式 题目描述 创建栈类，采用数组描述。 计算数学表达式的值。 输入数学表达式，输出表达式的计算结果。数学表达式由单个数字和运算符 + 、 - 、 * 、 / 、 ( 、 ) 构成，例如 2 + 3 * ( 4 + 5 )- 6 / 4。假定表达式输入格式合法。 格式 输入 第一行一个整数n(1&lt;=n&lt;=100)，代表表达式的个数。 接下来n行，每行一个表达式，保证表达式内的数字为单个整数，表达式内各运算符和数字间没有空格，且表达式的长度不超过2000。 输出 每行表达式输出一个浮点数，要求保留两位小数，保证输入表达式合法。 注意 因为精度问题，请使用double存数据。 样例 输入 123431+6/1*7+2*1*4+9/1+2*0*9+9+7/(9*5)-1*6-0*8-7-9*2+6-(0-5-2*8-7-9*5*(6-5*5*2*6-2-7-5+6*7+6*9-1*0*0+3*0+2/1-6/6+5))0-4-1/6*(1-(6/7)-4+6+2+6*1)-1*7+2-8*2+0-(4+6-6*1+(3-8*6/4-6-5)*6/4/8+7-1*4/9*5)-0/6+1-0-2+7-2+6*4-3*6+2/8+6+1*6*25-3*9+5/1*5-9+1*8-6-8-4*1+5-2+9/3*2-2/5/(2-6)*2/7-9*0-2+4/6*6*7*8-8-8*6+8*9*(3+0*1/5/2*7*8+0-8*8-5+8/5*2-0) 输出 123-9197.84-3.47-4362.57 限制 1s, 65536KiB for each test case. 算法描述和实现 方法一 使用数组存储结构，封装栈类arrayStack，私有成员包括栈顶stackTop，栈容量arrayLength，元素数组stack。公有成员包括构造函数，析构函数，ADT方法包括判断栈是否为空，返回栈中元素个数，返回栈顶元素，删除栈顶元素，将元素压入栈顶。 封装calculator类，私有成员包括一个double类型的栈，字符串s。公有成员包括输入，将中缀表达式转换为后缀表达式，处理后缀表达式，取2个操作数，对2个操作数进行运算，返回运算符优先级，输出结果，将char类型的数字转换为double类型，每个方法的具体思想如下： input：读入表达式（中缀）到私有成员s中。 change：将中缀表达式转换为后缀表达式。使用char类型的栈临时存储运算符。声明string类型的变量_s，用来临时存储后缀表达式。引入标记字符’#’，将其插入到运算符栈中，并规定其优先级为最低，这样做可以不用对栈空的情况进行特殊考虑。遍历表达式中每个字符，根据字符类型进行对应操作。字符串s遍历完毕后，如果栈顶元素不为标记字符（即栈非空），按顺序依次弹出栈中的元素，插入到_s的末端。 运算数：直接插入到_s的末端。 四则运算符：将该运算符与栈顶运算符优先级进行比较，如果优先级高于栈顶运算符，表示该部分运算还不能进行，将其压入栈；如果优先级低于或等于（优先级相同从左到右运算）栈顶运算符，表示前面部分的运算可以进行，将栈顶运算符弹出并插入到_s的末端，然后继续与新的栈顶运算符进行比较，直到优先级大于栈顶运算符（栈空的情况已经包含，因为设置标记字符的优先级为最低）,再将该运算符入栈。 左括号：直接压入栈，入栈后优先级降到最低，保证其它运算符正常入栈。 右括号：依次弹出栈顶运算符，并插入到_s的末端，直到遇到左括号。最后将左括号从栈顶删除。 operate：处理后缀表达式。遍历后缀表达式中的每个字符，如果是数字则入操作数栈，如果是操作符则取数进行运算。 getTwoNumbers：获取两个操作数。 calculate：对两个操作数进行运算。先使用getTwoNumbers方法获取两个操作数，然后根据运算符的类型进行对应的运算，将结果压入numberStack栈中。 order：返回运算符优先级。加减为1，乘除为2，左括号为0，右括号为3，标记符号为0。 output：输出最终结果。按照2位小数输出操作数栈的栈顶元素。 charToDouble：将char类型的数字字符转换为double类型。返回数字字符与’0’的差。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;string&gt;using namespace std;template &lt;class T&gt;class arrayStack{private: int stackTop; //栈顶 int arrayLength; //栈容量 T* stack; //元素数组public: //构造函数、析构函数 arrayStack(int initialCapacity=10); ~arrayStack() {delete []stack;} //ADT方法 bool empty() const {return stackTop==-1;} int size() const {return stackTop+1;} T&amp; top(); void pop(); void push(const T&amp; theElement);};template &lt;class T&gt;arrayStack&lt;T&gt;::arrayStack(int initialCapacity){ arrayLength=initialCapacity; stack=new T[arrayLength]; stackTop=-1;}template &lt;class T&gt;T&amp; arrayStack&lt;T&gt;::top(){ return stack[stackTop];}template &lt;class T&gt;void arrayStack&lt;T&gt;::pop(){ stack[stackTop--].~T();}template &lt;class T&gt;void arrayStack&lt;T&gt;::push(const T&amp; theElement){ if(stackTop==arrayLength-1) {//空间已满，容量加倍 T* newStack=new T[arrayLength*2]; arrayLength*=2; for(int i=0;i&lt;=stackTop;i++) newStack[i]=stack[i]; delete []stack; stack=newStack; } //在栈顶插入 stack[++stackTop]=theElement;}class calculator{private: arrayStack&lt;double&gt; numberStack; //操作数栈 string s; //存储中缀表达式和后缀表达式public: void input(); //读入中缀表达式 void change(); //将中缀表达式转换为后缀表达式 void operate(); //遍历后缀表达式中的每个字符，如果是数字则入栈，如果是操作符则取数进行运算 void getTwoNumbers(double &amp;num1,double &amp;num2); //获取两个操作数 void calculate(char op); //对两个操作数进行op运算 int order(char op); //运算符优先级 void output(); //输出最终结果 double charToDouble(char ch); //将char类型的数字字符转换为double类型};void calculator::input(){//读入中缀表达式 cin&gt;&gt;s;}void calculator::change(){//将中缀表达式转换为后缀表达式 arrayStack&lt;char&gt; operatorStack; //暂存运算符的栈 string _s; //暂存转换后的字符串 char ch; //当前的字符 operatorStack.push('#'); for(int i=0;i&lt;(int)s.size();i++) { ch=s.at(i); if(ch=='(') //左括号 { operatorStack.push(ch); } else if(ch==')') //右括号 { while(operatorStack.top()!='(') { _s.push_back(operatorStack.top()); operatorStack.pop(); } operatorStack.pop(); } else if(ch=='+'||ch=='-'||ch=='*'||ch=='/') //四则运算符 { char w=operatorStack.top(); if(order(w)&lt;order(ch)) { operatorStack.push(ch); } else { while(order(w)&gt;=order(ch)) { _s.push_back(w); operatorStack.pop(); w=operatorStack.top(); } operatorStack.push(ch); } } else//数字 { _s.push_back(ch); } } while(operatorStack.top()!='#') { _s.push_back(operatorStack.top()); operatorStack.pop(); } s=_s;}void calculator::getTwoNumbers(double &amp;num1,double &amp;num2){//获取两个操作数 num1=numberStack.top(); numberStack.pop(); num2=numberStack.top(); numberStack.pop();}void calculator::operate(){//遍历后缀表达式中的每个字符，如果是数字则入栈，如果是操作符则取数进行运算 for(int i=0;i&lt;(int)s.size();i++) { switch (s.at(i)) { case '-': case '+': case '*': case '/': calculate(s.at(i)); break; default: numberStack.push(charToDouble(s.at(i))); break; } }}void calculator::calculate(char op){//对两个操作数进行op运算 double number1,number2; getTwoNumbers(number1,number2); switch (op) { case '+':numberStack.push(number2+number1); break; case '-':numberStack.push(number2-number1); break; case '*':numberStack.push(number2*number1); break; case '/':numberStack.push(number2/number1); break; default: break; }}int calculator::order(char op){//运算符优先级 int val; if(op=='+'||op=='-') val=1; else if(op=='*'||op=='/') val=2; else if(op==')') val=3; else val=0; return val;}void calculator::output(){//输出最终结果 printf(&quot;%.2f\\n&quot;,numberStack.top());}double calculator::charToDouble(char ch){//将char类型的数字字符转换为double类型 double result=ch-'0'; return result;}int main(){ int n; //表达式个数 cin&gt;&gt;n; calculator c; for(int i=0;i&lt;n;i++) { c.input(); c.change(); c.operate(); c.output(); } return 0;} 方法二 使用数组存储结构，封装栈类arrayStack，私有成员包括栈顶stackTop，栈容量arrayLength，元素数组stack。公有成员包括构造函数，析构函数，ADT方法包括判断栈是否为空，返回栈中元素个数，返回栈顶元素，删除栈顶元素，将元素压入栈顶。 封装calculator类，私有成员包括一个double类型的操作数栈，一个char类型的运算符栈，字符串s。公有成员包括输入，遍历表达式进行相应处理，取2个操作数，对2个操作数进行运算，返回运算符优先级，输出结果，将char类型的数字转换为double类型，每个方法的具体思想如下： input：读入表达式到私有成员s中。 operate：遍历表达式中的每个字符，进行对应操作。operateStack栈存储运算符，首先将栈空的标记字符压入栈中，并规定其优先级为最低，这样做可以不用对栈空的情况进行特殊考虑。遍历表达式中每个字符，根据字符类型进行对应操作。 运算数：压入numberStack栈中。 四则运算符：将该运算符与操作符栈顶运算符优先级进行比较，如果优先级高于栈顶运算符，表示该部分运算还不能进行，将其压入栈；如果优先级低于或等于（优先级相同从左到右运算）栈顶运算符，表示前面部分的运算可以进行，取出栈顶运算符进行计算，完成计算后将栈顶运算符弹出，然后继续与新的栈顶运算符进行比较，直到优先级大于栈顶运算符（栈空的情况已经包含，因为设置标记字符的优先级为最低）,再将该运算符压入操作符栈。 左括号：直接压入栈，入栈后优先级降到最低，保证其它运算符正常入栈。 右括号：依次取栈顶运算符进行运算，直到遇到左括号为止。最后将左括号从栈顶删除。 字符串s遍历完毕后，如果栈顶元素不为标记字符（即栈非空），依次取出栈顶运算符进行计算，计算结果压入numberStack中。 getTwoNumbers：获取两个操作数。 calculate：对两个操作数进行运算。先使用getTwoNumbers方法获取两个操作数，然后根据运算符的类型进行对应的运算，将结果压入numberStack栈中。 order：返回运算符优先级。加减为1，乘除为2，左括号为0，右括号为3，标记符号为0。 output：输出最终结果。按照2位小数输出操作数栈的栈顶元素。 charToDouble：将char类型的数字字符转换为double类型。返回数字字符与’0’的差。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;string&gt;using namespace std;template &lt;class T&gt;class arrayStack{private: int stackTop; //栈顶 int arrayLength; //栈容量 T* stack; //元素数组public: //构造函数、析构函数 arrayStack(int initialCapacity=10); ~arrayStack() {delete []stack;} //ADT方法 bool empty() const {return stackTop==-1;} int size() const {return stackTop+1;} T&amp; top(); void pop(); void push(const T&amp; theElement);};template &lt;class T&gt;arrayStack&lt;T&gt;::arrayStack(int initialCapacity){ arrayLength=initialCapacity; stack=new T[arrayLength]; stackTop=-1;}template &lt;class T&gt;T&amp; arrayStack&lt;T&gt;::top(){ return stack[stackTop];}template &lt;class T&gt;void arrayStack&lt;T&gt;::pop(){ stack[stackTop--].~T();}template &lt;class T&gt;void arrayStack&lt;T&gt;::push(const T&amp; theElement){ if(stackTop==arrayLength-1) {//空间已满，容量加倍 T* newStack=new T[arrayLength*2]; arrayLength*=2; for(int i=0;i&lt;=stackTop;i++) newStack[i]=stack[i]; delete []stack; stack=newStack; } //在栈顶插入 stack[++stackTop]=theElement;}class calculator{private: arrayStack&lt;double&gt; numberStack; //操作数栈 arrayStack&lt;char&gt; operatorStack; //操作符栈 string s; //存储表达式public: void input(); //读入表达式 void operate(); //遍历表达式中的每个字符，进行相应处理 void getTwoNumbers(double &amp;num1,double &amp;num2); //获取两个操作数 void calculate(char op); //对两个操作数进行op运算 int order(char op); //运算符优先级 void output(); //输出最终结果 double charToDouble(char ch); //将char类型的数字字符转换为double类型};void calculator::input(){//读入表达式 cin&gt;&gt;s;}void calculator::getTwoNumbers(double &amp;num1,double &amp;num2){//获取两个操作数 num1=numberStack.top(); numberStack.pop(); num2=numberStack.top(); numberStack.pop();}void calculator::operate(){//遍历表达式中的每个字符，进行对应操作 operatorStack.push('#'); //设置栈空的标记字符，优先级设为最低 for(int i=0;i&lt;(int)s.size();i++) //遍历每个字符 { char ch=s.at(i); //当前字符 if(ch&gt;='0' &amp;&amp; ch&lt;='9') //数字 numberStack.push(charToDouble(ch)); //转换类型后入操作数栈 else //运算符 { if(ch=='(') //左括号 operatorStack.push(ch); //压入操作符栈 else if(ch==')') //右括号 { while(operatorStack.top()!='(') //进行计算直到遇到左括号 { calculate(operatorStack.top()); operatorStack.pop(); } operatorStack.pop(); //删除左括号 } else //四则运算符 { if(order(ch)&gt;order(operatorStack.top())) //当前运算符优先级高于栈顶运算符优先级 operatorStack.push(ch); else //当前运算符优先级低于或等于栈顶运算符优先级 { while(order(ch)&lt;=order(operatorStack.top())) {//进行计算 calculate(operatorStack.top()); operatorStack.pop(); } operatorStack.push(ch); //当前运算符压入操作符栈 } } } } //栈不为空 while(operatorStack.top()!='#') { char op=operatorStack.top(); operatorStack.pop(); calculate(op); }}void calculator::calculate(char op){//对两个操作数进行op运算 double number1,number2; getTwoNumbers(number1,number2); switch (op) { case '+':numberStack.push(number2+number1); break; case '-':numberStack.push(number2-number1); break; case '*':numberStack.push(number2*number1); break; case '/':numberStack.push(number2/number1); break; default: break; }}int calculator::order(char op){//运算符优先级 int val; if(op=='+'||op=='-') val=1; else if(op=='*'||op=='/') val=2; else if(op==')') val=3; else val=0; return val;}void calculator::output(){//输出最终结果 printf(&quot;%.2f\\n&quot;,numberStack.top());}double calculator::charToDouble(char ch){//将char类型的数字字符转换为double类型 double result=ch-'0'; return result;}int main(){ int n; //表达式个数 cin&gt;&gt;n; calculator c; for(int i=0;i&lt;n;i++) { c.input(); c.operate(); c.output(); } return 0;} 结果分析 1.在操作符栈中压入标记字符，并将其优先级设置为最低，在后续的判断中不用考虑栈空的情况，减少比较次数，提高程序性能。 2.逆波兰表达式求值是递归的一道经典问题，也可采用递归进行求解。","link":"/2020/11/04/CS/DSA/DSA_6/"},{"title":"DSA：（八）散列表","text":"散列表（哈希表）有两种实现方法，一种是线性探查，一种是链表散列。散列常作为字典的表示方法，通过哈希函数把字典的数对映射到散列表的具体位置，散列表的每一个位置叫做一个桶。散列表的最坏性能与线性表相同，因此性能很好，但是缺点是溢出后无法对散列表进行扩容（只能重新建立一个新的散列表）。所以在实际应用过程中散列表一般会开的比较大，保证不会溢出，同时需要选择一个好的除数减少冲突。本文的两个问题在实现过程中通过关键字模拟散列表的操作，即散列表每个位置的元素是关键字而不是数对。 P1012:线性开型寻址 描述 给定散列函数的除数D和操作数m，输出每次操作后的状态。 有以下三种操作： 1.插入x，若散列表已存在x，输出“Existed”，否则插入x到散列表中，输出所在的下标。 2.查询x，若散列表不含有x，输出“-1”，否则输出x对应下标。 3.删除x，若散列表不含有x，输出“Not Found”，否则输出删除x过程中移动元素的个数。 要求 使用线性开型寻址实现 格式 输入 第一行两个整数D，m。分别代表散列函数的除数D和操作数m。 接下来m行，每行两个整数opt和x，分别代表操作类型和操作数。 若opt为0，代表插入x。 若opt为1，代表查询x。 若opt为2，代表删除x。 输出 按要求输出。 样例 样例1 输入 123456789101112137 121 210 10 130 50 230 260 331 331 331 131 51 1 输出 123456789101112-116520333651 样例2 输入 1234567891011121314151617181920212223242526272829303120 300 840 150 542 152 841 542 540 891 890 130 482 890 600 241 130 61 240 312 602 480 490 91 61 130 332 490 601 62 91 60 输出 123456789101112131415161718192021222324252627282930415140014099138004136411009106131410600 限制 1s, 64MB for each test case. 算法描述 使用数组存储结构，封装散列表类hashTable，protected成员包括存储散列表的数组table，除数divisor，散列表的大小dSize，查询关键字的search方法，public成员包括构造函数，析构函数，empty方法，size方法，寻找关键字的find方法，插入关键字的insert方法，删除关键字的erase方法。 search：搜索散列表，查询关键字theKey，如果存在关键字返回其位置，否则返回该关键字可以插入的位置。从起始桶开始，判断table[i]是否为空或者指向的元素是否为theKey。 find：调用search方法搜索散列表得到位置b，通过table[b]是否为空或者指向的元素是否为theKey判断是否匹配，若不匹配输出-1，返回NULL，若匹配输出关键字在散列表的位置b，返回table[b]。 insert：调用search方法搜索散列表得到位置b，如果table[b]为NULL，插入该关键字，输出插入位置b，否则存在匹配的关键字（因为题目保证散列表不会溢出），输出“Existed”。 erase：调用search方法搜索散列表得到位置b，起始桶homeBucket保存b的位置，如果table[b]=NULL，则不存在该关键字，输出“Not Found”然后返回。否则存在该关键字，首先释放内存，将散列表的长度-1，moveTimes记录元素移动次数，然后进入外层循环，将位置b置空，使用gap记录删除的关键字的位置。进入内层循环，b移向下一个位置，如果table[b]为空或者b=homeBucket(即已经遍历散列表)，则不需要再判断元素是否需要移动，输出移动次数然后返回。否则需要判断元素是否需要移动，通过pos记录散列表当前位置的关键字的起始桶位置，不需要移动的条件是pos在gap和b之间，考虑有环和没有环的情况，通过三个条件给出限制，否则需要进行移动，跳出内层循环，用b填充gap，移动次数+1，然后继续进行下去，直到满足返回的条件。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class hashTable{protected: int search(const T&amp; theKey) const; //搜索散列表，查询关键字theKey，如果有存在该关键字，返回其位置，否则返回该关键字可以插入的位置 T** table; //散列表 int divisor; //散列函数的除数 int dSize; //散列表的大小public: hashTable(int theDivisor=11); //构造函数 ~hashTable() {delete []table;} //析构函数 bool empty() const {return dSize==0;} int size() const {return dSize;} T* find(const T&amp; theKey) const; //返回关键字theKey的指针，若不存在该关键字，则返回NULL void insert(const T&amp; theKey); //在散列表中插入关键字theKey，若存在相同的关键字则覆盖 void erase(const T&amp; theKey); //在散列表中删除关键字theKey，若不存在输出错误信息};template &lt;class T&gt;hashTable&lt;T&gt;::hashTable(int theDivisor){ divisor=theDivisor; dSize=0; //分配和初始化散列表数组 table=new T*[divisor]; for(int i=0;i&lt;divisor;i++) //将所有桶置空 table[i]=NULL;}template &lt;class T&gt;int hashTable&lt;T&gt;::search(const T&amp; theKey) const{//搜索散列表，查询关键字theKey //如果有存在该关键字，返回其位置，否则返回该关键字可以插入的位置 int i=theKey % divisor; //起始桶 int j=i; //从起始桶开始 do{ if(table[j]==NULL || *table[j]==theKey) return j; j=(j+1)%divisor; //下一个桶 }while(j!=i); return j;//表已经满}template &lt;class T&gt;T* hashTable&lt;T&gt;::find(const T&amp; theKey) const{//返回关键字theKey的指针，若不存在该关键字，则返回NULL //搜索散列表 int b=search(theKey); //判断table[b]是否匹配 if(table[b]==NULL || *table[b]!=theKey) //不匹配 { cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; return NULL; } //匹配 cout&lt;&lt;b&lt;&lt;endl; return table[b];}template &lt;class T&gt;void hashTable&lt;T&gt;::insert(const T&amp; theKey){//在散列表中插入关键字theKey，若存在相同的关键字则覆盖 int b=search(theKey); //检查匹配的关键字是否存在 //没有匹配的关键字，且表不满，则插入该关键字 if(table[b]==NULL) { table[b]=new T(theKey); dSize++; cout&lt;&lt;b&lt;&lt;endl; } else //存在匹配的关键字 cout&lt;&lt;&quot;Existed&quot;&lt;&lt;endl;}template &lt;class T&gt;void hashTable&lt;T&gt;::erase(const T&amp; theKey){//在散列表中删除关键字theKey //若不存在输出错误信息 int b=search(theKey); int homeBucket=b; if(table[b]==NULL) //不存在该关键字 { cout&lt;&lt;&quot;Not Found&quot;&lt;&lt;endl; return ; } //存在该关键字 delete table[b]; //释放内存 dSize--; //散列表长度-1 int moveTimes=0; //元素移动次数 for(;;) { table[b]=NULL; //将散列表的位置b置空 int gap=b; //记录删除的关键字的位置 for(;;) { b=(b+1)%divisor; //b的下一个位置 if(table[b]==NULL||b==homeBucket) //不需要再进行移动，直接返回 { cout&lt;&lt;moveTimes&lt;&lt;endl; return ; } int pos=*table[b]%divisor; //当前关键字在散列表中的原始映射位置 //不受散列表中删除关键字的影响 //三个条件都限制了pos要在gap和b之间 if(gap&lt;pos &amp;&amp; pos&lt;=b) continue; if(gap&gt;b &amp;&amp; gap&lt;pos) continue; if(gap&gt;b &amp;&amp; pos&lt;=b) continue; //受到影响，跳出循环 break; } table[gap]=table[b]; //用b填充gap moveTimes++; }}int main(){ int D,m,instruction,x; cin&gt;&gt;D&gt;&gt;m; hashTable&lt;int&gt; H(D); for(int i=0;i&lt;m;i++) { cin&gt;&gt;instruction; switch(instruction) { case 0: cin&gt;&gt;x; H.insert(x); break; case 1: cin&gt;&gt;x; H.find(x); break; case 2: cin&gt;&gt;x; H.erase(x); break; } } return 0;} P1013:链表散列 描述 给定散列函数的除数D和操作数m，输出每次操作后的状态。 有以下三种操作： 1.插入x，若散列表已存在x，输出&quot;Existed&quot;。 2.查询x，若散列表不含有x，输出&quot;Not Found&quot;，否则输出x所在的链表长度。 3.删除x，若散列表不含有x，输出&quot;Delete Failed&quot;，否则输出x所在链表删除x后的长度。 要求 使用链表散列方式 格式 输入 第一行两个整数D(1&lt;=D&lt;=3000)和m(1&lt;=m&lt;=3000)，其中D为散列函数的除数，m为操作数。 接下来的m行，每行两个整数opt和x，分别代表操作类型和操作数。 若opt为0，则代表向散列表中插入x； 若opt为1，代表查询散列表中x是否存在； 若opt为2，(如果散列表中含有x)，删除x。 数据保证散列表不会溢出。 输出 按要求输出。 样例 样例1 输入 123456789101112137 121 210 10 130 50 230 260 331 331 331 131 51 1 输出 123456Not Found33131 样例2 输入 123456789101112131415167 152 100 100 102 101 100 101 100 170 20 160 112 22 101 111 17 输出 123456789Delete FailedExisted0Not Found11111 限制 1s, 64MB for each test case. 数据范围 对于前60%的数据，只包含插入和查询操作。 对于后40%的数据，包含插入、查询与删除操作。 算法描述 使用链式存储结构，封装散列表类hashChains，protected成员包括有序链表数组table，散列函数的除数divisor，散列表的大小dSize，public成员包括构造函数，析构函数，empty方法，size方法，查询关键字的find方法，插入关键字的insert方法，删除关键字的erase方法。操作主要通过sortedChain类的方法来实现。 find：首先通过关键字确定起始桶的位置homeBucket，然后在起始桶中调用sortedChain类的find方法，根据返回值是否为空判断是否存在匹配的关键字，若不存在，输出“Not Found”，若存在，通过调用table[homeBucket]的size方法输出关键字所在链表的长度。 insert：首先通过关键字确定起始桶的位置homeBucket，homeSize表示homeBucket桶在插入前的链表长度，调用table[homeBucket]的insert方法，进行插入操作，若已经存在相同的关键字，输出“Existed”，否则进行关键字的插入，根据homeSize和插入后table[homeBucket]长度的比较，判断是否进行了插入（排除相同关键字的情况），对散列表的大小进行相应增加。 erase：首先通过关键字确定起始桶的位置homeBucket，然后调用table[homeBucket]的erase方法，若不存在关键字，输出“Delete Failed”，若存在进行相应删除操作，输出删除该关键字后的链表长度。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;struct node{ T element; node&lt;T&gt;* next; node() {} node(const T&amp; element) { this-&gt;element=element; } node(const T&amp; element,node&lt;T&gt;* next) { this-&gt;element=element; this-&gt;next=next; }};template &lt;class T&gt;class sortedChain{protected: node&lt;T&gt;* firstNode; //指向有序链表第一个节点的指针 int dSize; //有序链表的长度public: sortedChain(int initialCapacity=10); ~sortedChain(); bool empty() const {return dSize==0;} int size() const {return dSize;} T* find(const T&amp; theKey) const; //查询关键字theKey void insert(const T&amp; theKey); //插入关键字theKey，若已经存在关键字，输出Existed void erase(const T&amp; theKey); //删除关键字theKey，若不存在该关键字输出Delete Failed};template &lt;class T&gt;sortedChain&lt;T&gt;::sortedChain(int initialCapacity){ firstNode=NULL; dSize=0;}template &lt;class T&gt;sortedChain&lt;T&gt;::~sortedChain&lt;T&gt;(){ while (firstNode!=NULL) { node&lt;T&gt;* nextNode=firstNode-&gt;next; delete firstNode; firstNode=nextNode; }}template &lt;class T&gt;T* sortedChain&lt;T&gt;::find(const T &amp;theKey) const {//查询关键字theKey，若不存在返回NULL，若存在返回节点数据域的地址 node&lt;T&gt;* currentNode=firstNode; while(currentNode!=NULL &amp;&amp; currentNode-&gt;element&lt;theKey) currentNode=currentNode-&gt;next; if(currentNode!=NULL &amp;&amp; currentNode-&gt;element==theKey) return &amp;currentNode-&gt;element; return NULL;}template &lt;class T&gt;void sortedChain&lt;T&gt;::insert(const T &amp;theKey){//插入关键字theKey，若已经存在关键字，输出Existed node&lt;T&gt;* p=firstNode; node&lt;T&gt;* tp=NULL; while(p!=NULL &amp;&amp; p-&gt;element&lt;theKey) { tp=p; p=p-&gt;next; } if(p!=NULL &amp;&amp; p-&gt;element==theKey) { cout&lt;&lt;&quot;Existed&quot;&lt;&lt;endl; return ; } node&lt;T&gt;* newNode=new node&lt;T&gt;(theKey,p); if(tp==NULL) //插在首节点 firstNode=newNode; else tp-&gt;next=newNode; dSize++;}template &lt;class T&gt;void sortedChain&lt;T&gt;::erase(const T &amp;theKey){//删除关键字theKey，若不存在该关键字输出Delete Failed node&lt;T&gt;* p=firstNode; node&lt;T&gt;* tp=NULL; while(p!=NULL &amp;&amp; p-&gt;element&lt;theKey) { tp=p; p=p-&gt;next; } if((p!=NULL &amp;&amp; p-&gt;element&gt;theKey) || p==NULL) { cout&lt;&lt;&quot;Delete Failed&quot;&lt;&lt;endl; return ; } if(p!=NULL &amp;&amp; p-&gt;element==theKey) { if(tp==NULL) firstNode=p-&gt;next; else tp-&gt;next=p-&gt;next; delete p; dSize--; cout&lt;&lt;dSize&lt;&lt;endl; }}template &lt;class T&gt;class hashChains{protected: sortedChain&lt;T&gt;* table; //链表数组 int divisor; //散列函数的除数 int dSize; //散列表的大小public: hashChains(int theDivisor=11); ~hashChains() {delete []table;} bool empty() const {return dSize==0;} int size() const {return dSize;} void find(const T&amp; theKey) const; //查询关键字theKey，若不存在该关键字，输出Not Found，若存在输出所在链表的长度 void insert(const T&amp; theKey); //在散列表中插入关键字theKey，若存在相同的关键字则覆盖 void erase(const T&amp; theKey); //在散列表中删除关键字theKey，若不存在输出错误信息};template &lt;class T&gt;hashChains&lt;T&gt;::hashChains(int theDivisor){ divisor=theDivisor; dSize=0; table=new sortedChain&lt;T&gt;[divisor];}template &lt;class T&gt;void hashChains&lt;T&gt;::find(const T&amp; theKey) const{//返回关键字theKey匹配的数对的指针 int homeBucket=theKey % divisor; T* temp=table[homeBucket].find(theKey); if(temp==NULL) cout&lt;&lt;&quot;Not Found&quot;&lt;&lt;endl; else cout&lt;&lt;table[homeBucket].size()&lt;&lt;endl;}template &lt;class T&gt;void hashChains&lt;T&gt;::insert(const T&amp; theKey){//在字典中插入一个数对thePair，若存在关键字相同的数对，则覆盖 int homeBucket=theKey % divisor; int homeSize=table[homeBucket].size(); table[homeBucket].insert(theKey); if(table[homeBucket].size()&gt;homeSize) dSize++;}template &lt;class T&gt;void hashChains&lt;T&gt;::erase(const T&amp; theKey){//删除关键字为theKey的数对 int homeBucket=theKey % divisor; table[homeBucket].erase(theKey);}int main(){ int D,m,instruction,x; cin&gt;&gt;D&gt;&gt;m; hashChains&lt;int&gt; H(D); for(int i=0;i&lt;m;i++) { cin&gt;&gt;instruction; switch(instruction) { case 0: cin&gt;&gt;x; H.insert(x); break; case 1: cin&gt;&gt;x; H.find(x); break; case 2: cin&gt;&gt;x; H.erase(x); break; } } return 0;} 结果分析 1.线性探查的删除操作的核心是在删除一个元素后，判断散列剩余的元素要不要进行移动，如果需要移动，移动到哪个位置。在实现中，gap表示需要进行填充的位置，如果不进行填充，会破坏散列表的组织，影响后序的搜索等操作，不需要进行移动的元素应该满足其起始桶位置在gap和b之间，这样在线性探查的过程中，不会遇到gap，不影响该元素的搜索，所以这样的元素不需要进行移动。 2.线性探查的删除操作也可以为每个桶增加一个neverUsed域，用来标识这个桶是否曾经存有元素然后该元素被删除，保证在探查过程中不会受到删除的影响。 3.散列在最坏情况下的复杂度与线性表在最坏情况下的复杂度相同，使用链表时的平均性能优于线性探查。 4.数对的表示可以通过pair&lt;const K,E&gt;，pair.first为关键字，pair.second为元素值。","link":"/2020/11/22/CS/DSA/DSA_8/"},{"title":"DSA：（九）二叉树操作","text":"树型结构适合表示层次关系。本文通过链表实现二叉树的操作，包括前序遍历、中序遍历、后序遍历、层次遍历、计算节点数目和高度，以及通过前序序列和中序序列构造出二叉树。 P1014:二叉树基础 描述 创建二叉树类。二叉树的存储结构使用链表。提供操作:前序遍历、中序遍历、后序遍历、层次遍历、计算二叉树结点数目、计算二叉树高度。 格式 输入 第一行为一个数字n(10&lt;=n&lt;=100000)，表示这棵树有n个节点，编号为1 ~ n。 之后n行每行两个数字，第i行的两个数字a、b表示编号为i的节点的左孩子节点为a，右孩子节点为b，-1表示该位置没有节点。 保证数据有效，根节点为1。 输出 第一行，n个数字，表示该树的层次遍历。 第二行，n个数字，第i个数字表示以i节点为根的子树的节点数目。 第三行，n个数字，第i个数字表示以i节点为根的子树的高度。 样例 样例1 输入 12345652 34 5-1 -1-1 -1-1 -1 输出 1231 2 3 4 55 3 1 1 13 2 1 1 1 样例2 输入 12345653 2-1 -14 5-1 -1-1 -1 输出 1231 3 2 4 55 1 3 1 13 1 2 1 1 样例3 输入 1234567891011102 -14 36 -15 89 7-1 -1-1 -1-1 -110 -1-1 -1 输出 1231 2 4 3 5 8 6 9 7 10 10 9 2 6 4 1 1 1 2 1 6 5 2 4 3 1 1 1 2 1 Hint 请仔细读题，注意建树过程。 算法描述 封装二叉树类linkedBinaryTree，二叉树的存储结构使用链表，每个节点包括元素值element，左孩子leftChild，右孩子rightChild。节点类的构造函数有三个，默认构造函数，通过theElement构造，通过theElement，theLeftChild，theRightChild构造。二叉树类中，非静态的私有成员包括根节点root，树的节点个数treeSize，求以t为根节点的子树的高度height方法，求以t为根节点的子树的节点个数nodeNumber方法，静态的私有成员包括访问函数visit，前序遍历preOrder，中序遍历inOrder，后序遍历postOrder，删除t指向的节点dispose方法。公有成员包括构造函数，析构函数，empty方法，size方法，前序遍历，中序遍历，后序遍历，层次遍历，删除二叉树的erase方法，求二叉树的节点个数和高度，初始化二叉树initialize方法，输出以二叉树所有节点为根节点的子树的高度和节点个数。 前序遍历按照根、左、右的顺序访问二叉树的节点，中序遍历按照左、根、右的顺序访问二叉树的节点，后序遍历按照左、右、跟的顺序访问二叉树的节点。三种遍历方法都用递归实现。层次遍历利用队列的“先进先出”实现。 erase：删除整颗二叉树。通过后序遍历，对访问到的每一个节点调用dispose方法执行删除操作，最后将root置空，treeSize置零。 已知根节点求树的节点个数和高度，都用递归实现。求节点个数时，先求出左右子树的节点个数，相加再加一得到树的节点个数。求高度时，先求出左右子树的高度，二者的较大值加一得到树的高度。 初始化二叉树，首先将每个节点的左孩子和右孩子分别存入两个数组，然后利用层次遍历，对遍历到的当前的元素，根据左孩子和右孩子，构造相应的节点。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class arrayQueue{private: int queueFront; //队列首元素的下一个位置（逆时针方向） int queueBack; //队列最后一个元素的位置 int arrayLength; //数组大小 T* queue; //存储队列的数组public: arrayQueue(int initialCapacity=10); ~arrayQueue() {delete []queue;} bool empty() const {return queueFront==queueBack;} int size() const {return (arrayLength+queueBack-queueFront)%arrayLength;} T&amp; front() const; //返回队首元素 T&amp; back() const; //返回队尾元素 void pop(); //删除队首元素 void push(const T&amp; theElement); //元素插入到队尾};template &lt;class T&gt;arrayQueue&lt;T&gt;::arrayQueue(int initialCapacity){ arrayLength=initialCapacity; queue=new T[arrayLength]; queueFront=queueBack=0;}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::front() const{//返回队首元素 return queue[(queueFront+1)%arrayLength];}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::back() const{//返回队尾元素 return queue[queueBack];}template &lt;class T&gt;void arrayQueue&lt;T&gt;::pop(){//删除队首元素 queueFront=(queueFront+1)%arrayLength; queue[queueFront].~T();}template &lt;class T&gt;void arrayQueue&lt;T&gt;::push(const T&amp; theElement){//元素插入到队尾 //如果插入一个元素后队列满，需要扩充容量 if((queueBack+1)%arrayLength==queueFront) { T* newQueue=new T[2*arrayLength]; int start=(queueFront+1)%arrayLength; //复制元素 if(start&lt;2) //原队列中没有形成环 copy(queue+start,queue+start+arrayLength-1,newQueue); else //原队列中形成环 { copy(queue+start,queue+arrayLength,newQueue); copy(queue,queue+queueBack+1,newQueue+arrayLength-start); } queueFront=2*arrayLength-1; queueBack=arrayLength-2; arrayLength*=2; delete []queue; queue=newQueue; } queueBack=(queueBack+1)%arrayLength; queue[queueBack]=theElement;}template &lt;class T&gt;struct binaryTreeNode //二叉树节点类{ T element; binaryTreeNode&lt;T&gt; *leftChild, *rightChild; //三个构造函数 binaryTreeNode() {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement):element(theElement) {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement,binaryTreeNode&lt;T&gt;* theLeftChild,binaryTreeNode&lt;T&gt;* theRightChild):element(theElement) { leftChild=theLeftChild; rightChild=theRightChild; }};template &lt;class T&gt;class linkedBinaryTree{private: binaryTreeNode&lt;T&gt; *root; //根节点指针 int treeSize; //树的节点个数 static void (*visit)(binaryTreeNode&lt;T&gt; *); //访问函数 static void preOrder(binaryTreeNode&lt;T&gt; *t); //前序遍历 static void inOrder(binaryTreeNode&lt;T&gt; *t); //中序遍历 static void postOrder(binaryTreeNode&lt;T&gt; *t); //后序遍历 static void dispose(binaryTreeNode&lt;T&gt; *t) {delete t;} //删除t指向的节点 int height(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的高度 int nodeNumber(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的节点个数public: linkedBinaryTree() {root=NULL; treeSize=0;} ~linkedBinaryTree() {erase();} bool empty() const {return treeSize==0;} int size() const {return treeSize;} void preOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; preOrder(root); } void inOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; inOrder(root); } void postOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; postOrder(root); } void levelOrder(void(*)(binaryTreeNode&lt;T&gt;*)); //层次遍历 void erase() //删除二叉树 { postOrder(dispose); root=NULL; treeSize=0; } int Height() const {return height(root);} //计算二叉树的高度 int NodeNumber() const {return nodeNumber(root);} //计算二叉树的节点个数 void initialize(int num); //二叉树的初始化 void subtreeNodeNumber() const; //输出二叉树中所有节点为根的子树的节点个数 void subtreeHeight() const; //输出二叉树中所有节点为根的子树的高度};template &lt;class T&gt;void (*linkedBinaryTree&lt;T&gt;::visit)(binaryTreeNode&lt;T&gt;*)=NULL; //类的静态成员的初始化template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::preOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { linkedBinaryTree&lt;T&gt;::visit(t); preOrder(t-&gt;leftChild); preOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::inOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { inOrder(t-&gt;leftChild); linkedBinaryTree&lt;T&gt;::visit(t); inOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::postOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { postOrder(t-&gt;leftChild); postOrder(t-&gt;rightChild); linkedBinaryTree&lt;T&gt;::visit(t); }}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::height(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int hl=height(t-&gt;leftChild); int hr=height(t-&gt;rightChild); if(hl&gt;hr) return ++hl; else return ++hr;}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::nodeNumber(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int nl=nodeNumber(t-&gt;leftChild); int nr=nodeNumber(t-&gt;rightChild); return nl+nr+1;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::levelOrder(void (*theVisit)(binaryTreeNode&lt;T&gt; *)){ binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; while (t!=NULL) { theVisit(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else return ; q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::initialize(int num){//二叉树的初始化 //这棵树有num个节点，编号为1~num，根节点为1 //读入编号为i的节点的左孩子a，右孩子b，-1表示该位置没有节点 root=new binaryTreeNode&lt;T&gt;(1); treeSize=num; int *left=new int[num+1]; //左孩子 int *right=new int[num+1]; //右孩子 binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; for(int i=1;i&lt;=num;i++) cin&gt;&gt;left[i]&gt;&gt;right[i]; int cur=t-&gt;element; //当前节点的element值 //利用层次遍历进行初始化 while (t!=NULL) { if(left[cur]!=-1) t-&gt;leftChild=new binaryTreeNode&lt;T&gt;(left[cur]); if(right[cur]!=-1) t-&gt;rightChild=new binaryTreeNode&lt;T&gt;(right[cur]); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //初始化完成 { delete []left; delete []right; return ; } q.pop(); cur=t-&gt;element; }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeNodeNumber() const{//输出二叉树中所有节点为根的子树的节点个数 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的节点个数 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=nodeNumber(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeHeight() const{//输出二叉树中所有节点为根的子树的高度 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的高度 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=height(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;void output(binaryTreeNode&lt;T&gt;* t){//输出节点的element值 cout&lt;&lt;t-&gt;element&lt;&lt;&quot; &quot;;}int main(){ int n; linkedBinaryTree&lt;int&gt; BT; cin&gt;&gt;n; BT.initialize(n); BT.levelOrder(output); cout&lt;&lt;endl; BT.subtreeNodeNumber(); cout&lt;&lt;endl; BT.subtreeHeight(); cout&lt;&lt;endl; return 0;} P1015:二叉树遍历 描述 接收二叉树前序序列和中序序列(各元素各不相同)，输出该二叉树的后序序列。 格式 输入 输入有三行： 第一行为数字n。 第二行有n个数字，表示二叉树的前序遍历。 第三行有n个数字，表示二叉树的中序遍历。 输出 输出一行，表示该二叉树的后序遍历序列。 样例 输入 12351 2 4 5 34 2 5 1 3 输出 14 5 2 3 1 算法描述 在二叉树类linkedBinaryTree的基础上增加方法buildTree和update。buildTree的参数为前序序列pre，中序序列in，序列长度len，返回构造出的二叉树的根节点。buildTree通过递归实现，根据前序序列中的pre[0]，在中序序列中查找pre[0]的位置，根据pre[0]将中序序列分为左、根、右三部分，对于每一个部分，按照相同的方法进行构造，根据递归调用即可。update根据buildTree的返回值和序列长度，更新私有成员root和treeSize。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class arrayQueue{private: int queueFront; //队列首元素的下一个位置（逆时针方向） int queueBack; //队列最后一个元素的位置 int arrayLength; //数组大小 T* queue; //存储队列的数组public: arrayQueue(int initialCapacity=10); ~arrayQueue() {delete []queue;} bool empty() const {return queueFront==queueBack;} int size() const {return (arrayLength+queueBack-queueFront)%arrayLength;} T&amp; front() const; //返回队首元素 T&amp; back() const; //返回队尾元素 void pop(); //删除队首元素 void push(const T&amp; theElement); //元素插入到队尾};template &lt;class T&gt;arrayQueue&lt;T&gt;::arrayQueue(int initialCapacity){ arrayLength=initialCapacity; queue=new T[arrayLength]; queueFront=queueBack=0;}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::front() const{//返回队首元素 return queue[(queueFront+1)%arrayLength];}template &lt;class T&gt;T&amp; arrayQueue&lt;T&gt;::back() const{//返回队尾元素 return queue[queueBack];}template &lt;class T&gt;void arrayQueue&lt;T&gt;::pop(){//删除队首元素 queueFront=(queueFront+1)%arrayLength; queue[queueFront].~T();}template &lt;class T&gt;void arrayQueue&lt;T&gt;::push(const T&amp; theElement){//元素插入到队尾 //如果插入一个元素后队列满，需要扩充容量 if((queueBack+1)%arrayLength==queueFront) { T* newQueue=new T[2*arrayLength]; int start=(queueFront+1)%arrayLength; //复制元素 if(start&lt;2) //原队列中没有形成环 copy(queue+start,queue+start+arrayLength-1,newQueue); else //原队列中形成环 { copy(queue+start,queue+arrayLength,newQueue); copy(queue,queue+queueBack+1,newQueue+arrayLength-start); } queueFront=2*arrayLength-1; queueBack=arrayLength-2; arrayLength*=2; delete []queue; queue=newQueue; } queueBack=(queueBack+1)%arrayLength; queue[queueBack]=theElement;}template &lt;class T&gt;struct binaryTreeNode //二叉树节点类{ T element; binaryTreeNode&lt;T&gt; *leftChild, *rightChild; //三个构造函数 binaryTreeNode() {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement):element(theElement) {leftChild=rightChild=NULL;} binaryTreeNode(const T&amp; theElement,binaryTreeNode&lt;T&gt;* theLeftChild,binaryTreeNode&lt;T&gt;* theRightChild):element(theElement) { leftChild=theLeftChild; rightChild=theRightChild; }};template &lt;class T&gt;class linkedBinaryTree{private: binaryTreeNode&lt;T&gt; *root; //根节点指针 int treeSize; //树的节点个数 static void (*visit)(binaryTreeNode&lt;T&gt; *); //访问函数 static void preOrder(binaryTreeNode&lt;T&gt; *t); //前序遍历 static void inOrder(binaryTreeNode&lt;T&gt; *t); //中序遍历 static void postOrder(binaryTreeNode&lt;T&gt; *t); //后序遍历 static void dispose(binaryTreeNode&lt;T&gt; *t) {delete t;} //删除t指向的节点 static void output(binaryTreeNode&lt;T&gt; *t) {cout&lt;&lt;t-&gt;element&lt;&lt;&quot; &quot;;} //输出节点t的element值 int height(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的高度 int nodeNumber(binaryTreeNode&lt;T&gt; *t) const; //计算以t为根节点的子树的节点个数public: linkedBinaryTree() {root=NULL; treeSize=0;} ~linkedBinaryTree() {erase();} bool empty() const {return treeSize==0;} int size() const {return treeSize;} void preOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; preOrder(root); } void inOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; inOrder(root); } void postOrder(void(*theVisit)(binaryTreeNode&lt;T&gt;*)) { visit=theVisit; postOrder(root); } void postOrderOutput() //后序输出序列 {postOrder(output);cout&lt;&lt;endl;} void levelOrder(void(*)(binaryTreeNode&lt;T&gt;*)); //层次遍历 void erase() //删除二叉树 { postOrder(dispose); root=NULL; treeSize=0; } int Height() const {return height(root);} //计算二叉树的高度 int NodeNumber() const {return nodeNumber(root);} //计算二叉树的节点个数 void initialize(int num); //二叉树的初始化 void subtreeNodeNumber() const; //输出二叉树中所有节点为根的子树的节点个数 void subtreeHeight() const; //输出二叉树中所有节点为根的子树的高度 binaryTreeNode&lt;T&gt;* buildTree(T* pre,T* in,int len); //通过前序序列pre和中序序列in构造一颗二叉树,len表示序列长度 void update(T* pre,T* in,int len); //将构造的二叉树放到对象中，即更新root和treeSize};template &lt;class T&gt;void (*linkedBinaryTree&lt;T&gt;::visit)(binaryTreeNode&lt;T&gt; *)=NULL; //类的静态成员的初始化template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::preOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { linkedBinaryTree&lt;T&gt;::visit(t); preOrder(t-&gt;leftChild); preOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::inOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { inOrder(t-&gt;leftChild); linkedBinaryTree&lt;T&gt;::visit(t); inOrder(t-&gt;rightChild); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::postOrder(binaryTreeNode&lt;T&gt; *t){ if(t!=NULL) { postOrder(t-&gt;leftChild); postOrder(t-&gt;rightChild); linkedBinaryTree&lt;T&gt;::visit(t); }}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::height(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int hl=height(t-&gt;leftChild); int hr=height(t-&gt;rightChild); if(hl&gt;hr) return ++hl; else return ++hr;}template &lt;class T&gt;int linkedBinaryTree&lt;T&gt;::nodeNumber(binaryTreeNode&lt;T&gt; *t) const{ if(t==NULL) return 0; int nl=nodeNumber(t-&gt;leftChild); int nr=nodeNumber(t-&gt;rightChild); return nl+nr+1;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::levelOrder(void (*theVisit)(binaryTreeNode&lt;T&gt; *)){ binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; while (t!=NULL) { theVisit(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else return ; q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::initialize(int num){//二叉树的初始化 //这棵树有num个节点，编号为1~num，根节点为1 //读入编号为i的节点的左孩子a，右孩子b，-1表示该位置没有节点 root=new binaryTreeNode&lt;T&gt;(1); treeSize=num; int *left=new int[num+1]; //左孩子 int *right=new int[num+1]; //右孩子 binaryTreeNode&lt;T&gt; *t=root; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; for(int i=1;i&lt;=num;i++) cin&gt;&gt;left[i]&gt;&gt;right[i]; int cur=t-&gt;element; //当前节点的element值 //利用层次遍历进行初始化 while (t!=NULL) { if(left[cur]!=-1) t-&gt;leftChild=new binaryTreeNode&lt;T&gt;(left[cur]); if(right[cur]!=-1) t-&gt;rightChild=new binaryTreeNode&lt;T&gt;(right[cur]); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //初始化完成 { delete []left; delete []right; return ; } q.pop(); cur=t-&gt;element; }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeNodeNumber() const{//输出二叉树中所有节点为根的子树的节点个数 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的节点个数 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=nodeNumber(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::subtreeHeight() const{//输出二叉树中所有节点为根的子树的高度 int *result=new int[treeSize+1]; //result[i]表示以节点i为根的子树的高度 binaryTreeNode&lt;T&gt; *t=root; int cur; arrayQueue&lt;binaryTreeNode&lt;T&gt;*&gt; q; //层次遍历 while (t!=NULL) { cur=t-&gt;element; result[cur]=height(t); if(t-&gt;leftChild) q.push(t-&gt;leftChild); if(t-&gt;rightChild) q.push(t-&gt;rightChild); if(!q.empty()) t=q.front(); else //遍历结束 { for(int i=1;i&lt;=treeSize;i++) cout&lt;&lt;result[i]&lt;&lt;&quot; &quot;; delete []result; return ; } q.pop(); }}template &lt;class T&gt;binaryTreeNode&lt;T&gt;* linkedBinaryTree&lt;T&gt;::buildTree(T *pre, T *in, int len){//根据前序序列pre和中序序列in构建二叉树 //len表示序列长度 //返回二叉树的根节点 //序列长度小于等于0，不需要继续构造 if(len&lt;=0) return NULL; binaryTreeNode&lt;T&gt;* subRoot=new binaryTreeNode&lt;T&gt;(pre[0]); //pre[0]为根节点 int index=0; //在中序序列中查找pre[0] for(int i=0;i&lt;len;i++) if(in[i]==pre[0]) { index=i; break; } //递归构造左子树和右子树 subRoot-&gt;leftChild=buildTree(pre+1,in,index); subRoot-&gt;rightChild=buildTree(pre+index+1,in+index+1,len-index-1); return subRoot;}template &lt;class T&gt;void linkedBinaryTree&lt;T&gt;::update(T* pre,T* in,int len){//将构造的二叉树放到对象中，即更新root和treeSize root=buildTree(pre, in, len); treeSize=len;}int main(){ linkedBinaryTree&lt;int&gt; BT; int n; cin&gt;&gt;n; int *pre=new int[n],*in=new int[n]; for(int i=0;i&lt;n;i++) cin&gt;&gt;pre[i]; for(int i=0;i&lt;n;i++) cin&gt;&gt;in[i]; BT.update(pre,in,n); BT.postOrderOutput(); delete []pre; delete []in; return 0;} 结果分析 1.初始化时需要注意第i行的两个数字a、b表示的是编号为i的节点的左孩子和右孩子，不是位置为i的节点，因此在利用层次遍历进行初始化时，首先将每个节点的左孩子和右孩子分别存入两个数组，然后根据当前节点的element值在数组中找到左孩子和右孩子。 2.类的静态数据成员需要在类内定义，在类外进行初始化，如果没有初始化，也就意味着没有对其分配内存，在连接时会因为找不到对应的内存单元导致连接报错。 函数指针的初始化的语法格式： 12template &lt;class T&gt;void (*linkedBinaryTree&lt;T&gt;::visit)(binaryTreeNode&lt;T&gt; *)=NULL;","link":"/2020/12/23/CS/DSA/DSA_9/"},{"title":"Lunch Meeting（二）","text":"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 输入密码，查看文章","link":"/2021/04/20/Secret/JingYing/lunch-meeting-2nd/"},{"title":"Snappy Algorithm","text":"How to analyse the source codes of snappy ? Introduction Snappy is a compression/decompression library. It does not aim for maximum compression, or compatibility with any other compression library; instead, it aims for very high speeds and reasonable compression. For instance, compared to the fastest mode of zlib, Snappy is an order of magnitude faster for most inputs, but the resulting compressed files are anywhere from 20% to 100% bigger. (For more information, see “Performance”, below.) Snappy has the following properties: Fast: Compression speeds at 250 MB/sec and beyond, with no assembler code. See “Performance” below. Stable: Over the last few years, Snappy has compressed and decompressed petabytes of data in Google’s production environment. The Snappy bitstream format is stable and will not change between versions. Robust: The Snappy decompressor is designed not to crash in the face of corrupted or malicious input. Free and open source software: Snappy is licensed under a BSD-type license. For more information, see the included COPYING file. Snappy has previously been called “Zippy” in some Google presentations and the like. Snappy in RocksDB How to link: https://github.com/facebook/rocksdb/blob/main/build_tools/build_detect_platform 123456if ! test $ROCKSDB_DISABLE_SNAPPY; then # Test whether Snappy library is installed # http://code.google.com/p/snappy/ $CXX $PLATFORM_CXXFLAGS -x c++ - -o /dev/null 2&gt;/dev/null &lt;&lt;EOF #include &lt;snappy.h&gt; int main() {} Where to use: https://github.com/facebook/rocksdb/blob/main/util/compression.h 123456789101112131415161718192021222324252627282930313233343536373839404142inline bool Snappy_Compress(const CompressionInfo&amp; /*info*/, const char* input, size_t length, ::std::string* output) {#ifdef SNAPPY output-&gt;resize(snappy::MaxCompressedLength(length)); size_t outlen; snappy::RawCompress(input, length, &amp;(*output)[0], &amp;outlen); output-&gt;resize(outlen); return true;#else (void)input; (void)length; (void)output; return false;#endif}inline CacheAllocationPtr Snappy_Uncompress( const char* input, size_t length, size_t* uncompressed_size, MemoryAllocator* allocator = nullptr) {#ifdef SNAPPY size_t uncompressed_length = 0; if (!snappy::GetUncompressedLength(input, length, &amp;uncompressed_length)) { return nullptr; } CacheAllocationPtr output = AllocateBlock(uncompressed_length, allocator); if (!snappy::RawUncompress(input, length, output.get())) { return nullptr; } *uncompressed_size = uncompressed_length; return output;#else (void)input; (void)length; (void)uncompressed_size; (void)allocator; return nullptr;#endif} RocksDB主要调用了两个接口RawCompress和RawUncompress。 Snappy Source: https://github.com/google/snappy/ 首先看一下Format，然后分别从RawCompress和RawUncompress入手分析Snappy的压缩和解压过程。 Format format_description.txt说明了一些编码格式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110Snappy compressed format descriptionLast revised: 2011-10-05This is not a formal specification, but should suffice to explain mostrelevant parts of how the Snappy format works. It is originally based ontext by Zeev Tarantov.Snappy is a LZ77-type compressor with a fixed, byte-oriented encoding.There is no entropy encoder backend nor framing layer -- the latter isassumed to be handled by other parts of the system.This document only describes the format, not how the Snappy compressor nordecompressor actually works. The correctness of the decompressor should notdepend on implementation details of the compressor, and vice versa.1. PreambleThe stream starts with the uncompressed length (up to a maximum of 2^32 - 1),stored as a little-endian varint. Varints consist of a series of bytes,where the lower 7 bits are data and the upper bit is set iff there aremore bytes to be read. In other words, an uncompressed length of 64 wouldbe stored as 0x40, and an uncompressed length of 2097150 (0x1FFFFE)would be stored as 0xFE 0xFF 0x7F.2. The compressed stream itselfThere are two types of elements in a Snappy stream: Literals andcopies (backreferences). There is no restriction on the order of elements,except that the stream naturally cannot start with a copy. (Havingtwo literals in a row is never optimal from a compression point ofview, but nevertheless fully permitted.) Each element starts with a tag byte,and the lower two bits of this tag byte signal what type of element willfollow: 00: Literal 01: Copy with 1-byte offset 10: Copy with 2-byte offset 11: Copy with 4-byte offsetThe interpretation of the upper six bits are element-dependent.2.1. Literals (00)Literals are uncompressed data stored directly in the byte stream.The literal length is stored differently depending on the lengthof the literal: - For literals up to and including 60 bytes in length, the upper six bits of the tag byte contain (len-1). The literal follows immediately thereafter in the bytestream. - For longer literals, the (len-1) value is stored after the tag byte, little-endian. The upper six bits of the tag byte describe how many bytes are used for the length; 60, 61, 62 or 63 for 1-4 bytes, respectively. The literal itself follows after the length.2.2. CopiesCopies are references back into previous decompressed data, tellingthe decompressor to reuse data it has previously decoded.They encode two values: The _offset_, saying how many bytes backfrom the current position to read, and the _length_, how many bytesto copy. Offsets of zero can be encoded, but are not legal;similarly, it is possible to encode backreferences that wouldgo past the end of the block (offset &gt; current decompressed position),which is also nonsensical and thus not allowed.As in most LZ77-based compressors, the length can be larger than the offset,yielding a form of run-length encoding (RLE). For instance,&quot;xababab&quot; could be encoded as &lt;literal: &quot;xab&quot;&gt; &lt;copy: offset=2 length=4&gt;Note that since the current Snappy compressor works in 32 kBblocks and does not do matching across blocks, it will never producea bitstream with offsets larger than about 32768. However, thedecompressor should not rely on this, as it may change in the future.There are several different kinds of copy elements, depending onthe amount of bytes to be copied (length), and how far back thedata to be copied is (offset).2.2.1. Copy with 1-byte offset (01)These elements can encode lengths between [4..11] bytes and offsetsbetween [0..2047] bytes. (len-4) occupies three bits and is storedin bits [2..4] of the tag byte. The offset occupies 11 bits, of which theupper three are stored in the upper three bits ([5..7]) of the tag byte,and the lower eight are stored in a byte following the tag byte.2.2.2. Copy with 2-byte offset (10)These elements can encode lengths between [1..64] and offsets from[0..65535]. (len-1) occupies six bits and is stored in the uppersix bits ([2..7]) of the tag byte. The offset is stored as alittle-endian 16-bit integer in the two bytes following the tag byte.2.2.3. Copy with 4-byte offset (11)These are like the copies with 2-byte offsets (see previous subsection),except that the offset is stored as a 32-bit integer instead of a16-bit integer (and thus will occupy four bytes). Compress RawCompress 123456789void RawCompress(const char* input, size_t input_length, char* compressed, size_t* compressed_length) { ByteArraySource reader(input, input_length); UncheckedByteArraySink writer(compressed); Compress(&amp;reader, &amp;writer); // Compute how many bytes were added *compressed_length = (writer.CurrentDestination() - compressed);} 首先根据参数创建reader，writer，然后调用Compress进行压缩，最后计算compressed_length。 下面看一下reader和writer的结构。 ByteArraySource 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// A Source is an interface that yields a sequence of bytesclass Source { public: Source() { } virtual ~Source(); // Return the number of bytes left to read from the source virtual size_t Available() const = 0; // Peek at the next flat region of the source. Does not reposition // the source. The returned region is empty iff Available()==0. // // Returns a pointer to the beginning of the region and store its // length in *len. // // The returned region is valid until the next call to Skip() or // until this object is destroyed, whichever occurs first. // // The returned region may be larger than Available() (for example // if this ByteSource is a view on a substring of a larger source). // The caller is responsible for ensuring that it only reads the // Available() bytes. virtual const char* Peek(size_t* len) = 0; // Skip the next n bytes. Invalidates any buffer returned by // a previous call to Peek(). // REQUIRES: Available() &gt;= n virtual void Skip(size_t n) = 0; private: // No copying Source(const Source&amp;); void operator=(const Source&amp;);};// A Source implementation that yields the contents of a flat arrayclass ByteArraySource : public Source { public: ByteArraySource(const char* p, size_t n) : ptr_(p), left_(n) { } ~ByteArraySource() override; size_t Available() const override; const char* Peek(size_t* len) override; void Skip(size_t n) override; private: const char* ptr_; size_t left_;}; Available: 表示还有多少个字节剩余。 Peek: 返回前面可以窥探到的字节流，并且返回长度。返回的buffer必须持续有效直到Skip。 Skip: 告诉Source某个部分的字节流已经不需要被使用了，将这一部分跳过。 UncheckedByteArraySink 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495// A Sink is an interface that consumes a sequence of bytes.class Sink { public: Sink() { } virtual ~Sink(); // Append &quot;bytes[0,n-1]&quot; to this. virtual void Append(const char* bytes, size_t n) = 0; // Returns a writable buffer of the specified length for appending. // May return a pointer to the caller-owned scratch buffer which // must have at least the indicated length. The returned buffer is // only valid until the next operation on this Sink. // // After writing at most &quot;length&quot; bytes, call Append() with the // pointer returned from this function and the number of bytes // written. Many Append() implementations will avoid copying // bytes if this function returned an internal buffer. // // If a non-scratch buffer is returned, the caller may only pass a // prefix of it to Append(). That is, it is not correct to pass an // interior pointer of the returned array to Append(). // // The default implementation always returns the scratch buffer. virtual char* GetAppendBuffer(size_t length, char* scratch); // For higher performance, Sink implementations can provide custom // AppendAndTakeOwnership() and GetAppendBufferVariable() methods. // These methods can reduce the number of copies done during // compression/decompression. // Append &quot;bytes[0,n-1] to the sink. Takes ownership of &quot;bytes&quot; // and calls the deleter function as (*deleter)(deleter_arg, bytes, n) // to free the buffer. deleter function must be non NULL. // // The default implementation just calls Append and frees &quot;bytes&quot;. // Other implementations may avoid a copy while appending the buffer. virtual void AppendAndTakeOwnership( char* bytes, size_t n, void (*deleter)(void*, const char*, size_t), void *deleter_arg); // Returns a writable buffer for appending and writes the buffer's capacity to // *allocated_size. Guarantees *allocated_size &gt;= min_size. // May return a pointer to the caller-owned scratch buffer which must have // scratch_size &gt;= min_size. // // The returned buffer is only valid until the next operation // on this ByteSink. // // After writing at most *allocated_size bytes, call Append() with the // pointer returned from this function and the number of bytes written. // Many Append() implementations will avoid copying bytes if this function // returned an internal buffer. // // If the sink implementation allocates or reallocates an internal buffer, // it should use the desired_size_hint if appropriate. If a caller cannot // provide a reasonable guess at the desired capacity, it should set // desired_size_hint = 0. // // If a non-scratch buffer is returned, the caller may only pass // a prefix to it to Append(). That is, it is not correct to pass an // interior pointer to Append(). // // The default implementation always returns the scratch buffer. virtual char* GetAppendBufferVariable( size_t min_size, size_t desired_size_hint, char* scratch, size_t scratch_size, size_t* allocated_size); private: // No copying Sink(const Sink&amp;); void operator=(const Sink&amp;);};// A Sink implementation that writes to a flat array without any bound checks.class UncheckedByteArraySink : public Sink { public: explicit UncheckedByteArraySink(char* dest) : dest_(dest) { } ~UncheckedByteArraySink() override; void Append(const char* data, size_t n) override; char* GetAppendBuffer(size_t len, char* scratch) override; char* GetAppendBufferVariable( size_t min_size, size_t desired_size_hint, char* scratch, size_t scratch_size, size_t* allocated_size) override; void AppendAndTakeOwnership( char* bytes, size_t n, void (*deleter)(void*, const char*, size_t), void *deleter_arg) override; // Return the current output pointer so that a caller can see how // many bytes were produced. // Note: this is not a Sink method. char* CurrentDestination() const { return dest_; } private: char* dest_;}; Append: 将bytes[0,n-1]这个字节流写入。 getAppendBuffer: 交出一块length的buffer，这块length的buffer的话必须一直有效直到Append被调用。当然我们也可以直接返回scratch(外围框架分配的内存)。 Compress 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869size_t Compress(Source* reader, Sink* writer) { size_t written = 0; size_t N = reader-&gt;Available(); const size_t uncompressed_size = N; char ulength[Varint::kMax32]; char* p = Varint::Encode32(ulength, N); writer-&gt;Append(ulength, p - ulength); written += (p - ulength); internal::WorkingMemory wmem(N); while (N &gt; 0) { // Get next block to compress (without copying if possible) size_t fragment_size; const char* fragment = reader-&gt;Peek(&amp;fragment_size); assert(fragment_size != 0); // premature end of input const size_t num_to_read = std::min(N, kBlockSize); size_t bytes_read = fragment_size; size_t pending_advance = 0; if (bytes_read &gt;= num_to_read) { // Buffer returned by reader is large enough pending_advance = num_to_read; fragment_size = num_to_read; } else { char* scratch = wmem.GetScratchInput(); std::memcpy(scratch, fragment, bytes_read); reader-&gt;Skip(bytes_read); while (bytes_read &lt; num_to_read) { fragment = reader-&gt;Peek(&amp;fragment_size); size_t n = std::min&lt;size_t&gt;(fragment_size, num_to_read - bytes_read); std::memcpy(scratch + bytes_read, fragment, n); bytes_read += n; reader-&gt;Skip(n); } assert(bytes_read == num_to_read); fragment = scratch; fragment_size = num_to_read; } assert(fragment_size == num_to_read); // Get encoding table for compression int table_size; uint16_t* table = wmem.GetHashTable(num_to_read, &amp;table_size); // Compress input_fragment and append to dest const int max_output = MaxCompressedLength(num_to_read); // Need a scratch buffer for the output, in case the byte sink doesn't // have room for us directly. // Since we encode kBlockSize regions followed by a region // which is &lt;= kBlockSize in length, a previously allocated // scratch_output[] region is big enough for this iteration. char* dest = writer-&gt;GetAppendBuffer(max_output, wmem.GetScratchOutput()); char* end = internal::CompressFragment(fragment, fragment_size, dest, table, table_size); writer-&gt;Append(dest, end - dest); written += (end - dest); N -= num_to_read; reader-&gt;Skip(pending_advance); } Report(&quot;snappy_compress&quot;, written, uncompressed_size); return written;} 头部是原始串长度，使用变长整数方式Encode来编码。 123456789101112131415161718192021222324252627inline char* Varint::Encode32(char* sptr, uint32_t v) { // Operate on characters as unsigneds uint8_t* ptr = reinterpret_cast&lt;uint8_t*&gt;(sptr); static const uint8_t B = 128; if (v &lt; (1 &lt;&lt; 7)) { *(ptr++) = static_cast&lt;uint8_t&gt;(v); } else if (v &lt; (1 &lt;&lt; 14)) { *(ptr++) = static_cast&lt;uint8_t&gt;(v | B); *(ptr++) = static_cast&lt;uint8_t&gt;(v &gt;&gt; 7); } else if (v &lt; (1 &lt;&lt; 21)) { *(ptr++) = static_cast&lt;uint8_t&gt;(v | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v &gt;&gt; 7) | B); *(ptr++) = static_cast&lt;uint8_t&gt;(v &gt;&gt; 14); } else if (v &lt; (1 &lt;&lt; 28)) { *(ptr++) = static_cast&lt;uint8_t&gt;(v | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v &gt;&gt; 7) | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v &gt;&gt; 14) | B); *(ptr++) = static_cast&lt;uint8_t&gt;(v &gt;&gt; 21); } else { *(ptr++) = static_cast&lt;uint8_t&gt;(v | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v&gt;&gt;7) | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v&gt;&gt;14) | B); *(ptr++) = static_cast&lt;uint8_t&gt;((v&gt;&gt;21) | B); *(ptr++) = static_cast&lt;uint8_t&gt;(v &gt;&gt; 28); } return reinterpret_cast&lt;char*&gt;(ptr);} 获取fragment和fragmentsize。 调用CompressFragment。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180// Flat array compression that does not emit the &quot;uncompressed length&quot;// prefix. Compresses &quot;input&quot; string to the &quot;*op&quot; buffer.//// REQUIRES: &quot;input&quot; is at most &quot;kBlockSize&quot; bytes long.// REQUIRES: &quot;op&quot; points to an array of memory that is at least// &quot;MaxCompressedLength(input.size())&quot; in size.// REQUIRES: All elements in &quot;table[0..table_size-1]&quot; are initialized to zero.// REQUIRES: &quot;table_size&quot; is a power of two//// Returns an &quot;end&quot; pointer into &quot;op&quot; buffer.// &quot;end - op&quot; is the compressed size of &quot;input&quot;.namespace internal {char* CompressFragment(const char* input, size_t input_size, char* op, uint16_t* table, const int table_size) { // &quot;ip&quot; is the input pointer, and &quot;op&quot; is the output pointer. const char* ip = input; assert(input_size &lt;= kBlockSize); assert((table_size &amp; (table_size - 1)) == 0); // table must be power of two const uint32_t mask = table_size - 1; const char* ip_end = input + input_size; const char* base_ip = ip; const size_t kInputMarginBytes = 15; if (SNAPPY_PREDICT_TRUE(input_size &gt;= kInputMarginBytes)) { const char* ip_limit = input + input_size - kInputMarginBytes; for (uint32_t preload = LittleEndian::Load32(ip + 1);;) { // Bytes in [next_emit, ip) will be emitted as literal bytes. Or // [next_emit, ip_end) after the main loop. const char* next_emit = ip++; uint64_t data = LittleEndian::Load64(ip); // The body of this loop calls EmitLiteral once and then EmitCopy one or // more times. (The exception is that when we're close to exhausting // the input we goto emit_remainder.) // // In the first iteration of this loop we're just starting, so // there's nothing to copy, so calling EmitLiteral once is // necessary. And we only start a new iteration when the // current iteration has determined that a call to EmitLiteral will // precede the next call to EmitCopy (if any). // // Step 1: Scan forward in the input looking for a 4-byte-long match. // If we get close to exhausting the input then goto emit_remainder. // // Heuristic match skipping: If 32 bytes are scanned with no matches // found, start looking only at every other byte. If 32 more bytes are // scanned (or skipped), look at every third byte, etc.. When a match is // found, immediately go back to looking at every byte. This is a small // loss (~5% performance, ~0.1% density) for compressible data due to more // bookkeeping, but for non-compressible data (such as JPEG) it's a huge // win since the compressor quickly &quot;realizes&quot; the data is incompressible // and doesn't bother looking for matches everywhere. // // The &quot;skip&quot; variable keeps track of how many bytes there are since the // last match; dividing it by 32 (ie. right-shifting by five) gives the // number of bytes to move ahead for each iteration. uint32_t skip = 32; const char* candidate; if (ip_limit - ip &gt;= 16) { auto delta = ip - base_ip; for (int j = 0; j &lt; 4; ++j) { for (int k = 0; k &lt; 4; ++k) { int i = 4 * j + k; // These for-loops are meant to be unrolled. So we can freely // special case the first iteration to use the value already // loaded in preload. uint32_t dword = i == 0 ? preload : static_cast&lt;uint32_t&gt;(data); assert(dword == LittleEndian::Load32(ip + i)); uint32_t hash = HashBytes(dword, mask); candidate = base_ip + table[hash]; assert(candidate &gt;= base_ip); assert(candidate &lt; ip + i); table[hash] = delta + i; if (SNAPPY_PREDICT_FALSE(LittleEndian::Load32(candidate) == dword)) { *op = LITERAL | (i &lt;&lt; 2); UnalignedCopy128(next_emit, op + 1); ip += i; op = op + i + 2; goto emit_match; } data &gt;&gt;= 8; } data = LittleEndian::Load64(ip + 4 * j + 4); } ip += 16; skip += 16; } while (true) { assert(static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(ip)); uint32_t hash = HashBytes(data, mask); uint32_t bytes_between_hash_lookups = skip &gt;&gt; 5; skip += bytes_between_hash_lookups; const char* next_ip = ip + bytes_between_hash_lookups; if (SNAPPY_PREDICT_FALSE(next_ip &gt; ip_limit)) { ip = next_emit; goto emit_remainder; } candidate = base_ip + table[hash]; assert(candidate &gt;= base_ip); assert(candidate &lt; ip); table[hash] = ip - base_ip; if (SNAPPY_PREDICT_FALSE(static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(candidate))) { break; } data = LittleEndian::Load32(next_ip); ip = next_ip; } // Step 2: A 4-byte match has been found. We'll later see if more // than 4 bytes match. But, prior to the match, input // bytes [next_emit, ip) are unmatched. Emit them as &quot;literal bytes.&quot; assert(next_emit + 16 &lt;= ip_end); op = EmitLiteral&lt;/*allow_fast_path=*/true&gt;(op, next_emit, ip - next_emit); // Step 3: Call EmitCopy, and then see if another EmitCopy could // be our next move. Repeat until we find no match for the // input immediately after what was consumed by the last EmitCopy call. // // If we exit this loop normally then we need to call EmitLiteral next, // though we don't yet know how big the literal will be. We handle that // by proceeding to the next iteration of the main loop. We also can exit // this loop via goto if we get close to exhausting the input. emit_match: do { // We have a 4-byte match at ip, and no need to emit any // &quot;literal bytes&quot; prior to ip. const char* base = ip; std::pair&lt;size_t, bool&gt; p = FindMatchLength(candidate + 4, ip + 4, ip_end, &amp;data); size_t matched = 4 + p.first; ip += matched; size_t offset = base - candidate; assert(0 == memcmp(base, candidate, matched)); if (p.second) { op = EmitCopy&lt;/*len_less_than_12=*/true&gt;(op, offset, matched); } else { op = EmitCopy&lt;/*len_less_than_12=*/false&gt;(op, offset, matched); } if (SNAPPY_PREDICT_FALSE(ip &gt;= ip_limit)) { goto emit_remainder; } // Expect 5 bytes to match assert((data &amp; 0xFFFFFFFFFF) == (LittleEndian::Load64(ip) &amp; 0xFFFFFFFFFF)); // We are now looking for a 4-byte match again. We read // table[Hash(ip, shift)] for that. To improve compression, // we also update table[Hash(ip - 1, mask)] and table[Hash(ip, mask)]. table[HashBytes(LittleEndian::Load32(ip - 1), mask)] = ip - base_ip - 1; uint32_t hash = HashBytes(data, mask); candidate = base_ip + table[hash]; table[hash] = ip - base_ip; // Measurements on the benchmarks have shown the following probabilities // for the loop to exit (ie. avg. number of iterations is reciprocal). // BM_Flat/6 txt1 p = 0.3-0.4 // BM_Flat/7 txt2 p = 0.35 // BM_Flat/8 txt3 p = 0.3-0.4 // BM_Flat/9 txt3 p = 0.34-0.4 // BM_Flat/10 pb p = 0.4 // BM_Flat/11 gaviota p = 0.1 // BM_Flat/12 cp p = 0.5 // BM_Flat/13 c p = 0.3 } while (static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(candidate)); // Because the least significant 5 bytes matched, we can utilize data // for the next iteration. preload = data &gt;&gt; 8; } }emit_remainder: // Emit the remaining bytes as a literal if (ip &lt; ip_end) { op = EmitLiteral&lt;/*allow_fast_path=*/false&gt;(op, ip, ip_end - ip); } return op;}} // end namespace internal 核心代码是for (uint32_t preload = LittleEndian::Load32(ip + 1);;)控制的大循环。 j和k控制两层for循环，指针每次向后移动1个byte（即内层循环k每次加1，data右移8位），对于当前指针指向的4bytes内容dword，将其放入hashtable中。 如果在循环中出现了candidata==dword的情况，则将从next_emit开始的16个bytes作为literal写入op，然后goto emit_match。 1234567if (SNAPPY_PREDICT_FALSE(LittleEndian::Load32(candidate) == dword)) { *op = LITERAL | (i &lt;&lt; 2); UnalignedCopy128(next_emit, op + 1); ip += i; op = op + i + 2; goto emit_match; } 否则，进入下面的while循环。 12345678910111213141516171819202122while (true) { assert(static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(ip)); uint32_t hash = HashBytes(data, mask); uint32_t bytes_between_hash_lookups = skip &gt;&gt; 5; skip += bytes_between_hash_lookups; const char* next_ip = ip + bytes_between_hash_lookups; if (SNAPPY_PREDICT_FALSE(next_ip &gt; ip_limit)) { ip = next_emit; goto emit_remainder; } candidate = base_ip + table[hash]; assert(candidate &gt;= base_ip); assert(candidate &lt; ip); table[hash] = ip - base_ip; if (SNAPPY_PREDICT_FALSE(static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(candidate))) { break; } data = LittleEndian::Load32(next_ip); ip = next_ip; } 这就是注释中提到的启发式搜索，skip右移5位作为检查标准，不超过32bytes逐字节检查，超过32bytes不超过64bytes每两个字节检查一次…以此类推，bytes_between_hash_lookups的含义就是每多少个字节检查一次。最终会出现两种情况，一种是next_ip大于ip_limit，直接将其作为literal。另一种是data等于candidate，break跳出循环。 while循环结束后，我们得到了4bytes的match，先将match对应的literal写入op。 12assert(next_emit + 16 &lt;= ip_end);op = EmitLiteral&lt;/*allow_fast_path=*/true&gt;(op, next_emit, ip - next_emit); 然后进入emit_match这个label标记的程序段。 12345678910111213141516171819202122232425262728293031323334353637383940414243emit_match: do { // We have a 4-byte match at ip, and no need to emit any // &quot;literal bytes&quot; prior to ip. const char* base = ip; std::pair&lt;size_t, bool&gt; p = FindMatchLength(candidate + 4, ip + 4, ip_end, &amp;data); size_t matched = 4 + p.first; ip += matched; size_t offset = base - candidate; assert(0 == memcmp(base, candidate, matched)); if (p.second) { op = EmitCopy&lt;/*len_less_than_12=*/true&gt;(op, offset, matched); } else { op = EmitCopy&lt;/*len_less_than_12=*/false&gt;(op, offset, matched); } if (SNAPPY_PREDICT_FALSE(ip &gt;= ip_limit)) { goto emit_remainder; } // Expect 5 bytes to match assert((data &amp; 0xFFFFFFFFFF) == (LittleEndian::Load64(ip) &amp; 0xFFFFFFFFFF)); // We are now looking for a 4-byte match again. We read // table[Hash(ip, shift)] for that. To improve compression, // we also update table[Hash(ip - 1, mask)] and table[Hash(ip, mask)]. table[HashBytes(LittleEndian::Load32(ip - 1), mask)] = ip - base_ip - 1; uint32_t hash = HashBytes(data, mask); candidate = base_ip + table[hash]; table[hash] = ip - base_ip; // Measurements on the benchmarks have shown the following probabilities // for the loop to exit (ie. avg. number of iterations is reciprocal). // BM_Flat/6 txt1 p = 0.3-0.4 // BM_Flat/7 txt2 p = 0.35 // BM_Flat/8 txt3 p = 0.3-0.4 // BM_Flat/9 txt3 p = 0.34-0.4 // BM_Flat/10 pb p = 0.4 // BM_Flat/11 gaviota p = 0.1 // BM_Flat/12 cp p = 0.5 // BM_Flat/13 c p = 0.3 } while (static_cast&lt;uint32_t&gt;(data) == LittleEndian::Load32(candidate)); // Because the least significant 5 bytes matched, we can utilize data // for the next iteration. preload = data &gt;&gt; 8; FindMatchLength求出最大的match长度，将offset和matched写入op，最后更新hashtable。如果data和candidate不相等，退出循环。 CompressFragment结束后，回到Compress中，最后通过writer-&gt;Append(dest, end - dest)写入writer。 Uncompress Overview At first, the size of the uncompressed file stored into the first several (less than six) bytes is extracted. If the most significant bit (MSB) of a byte is 1, it means the next byte is also used to describe the uncompressed file size. Otherwise, the current byte is the last byte indicating the uncompressed file size. After this procedure, the start and end address of the output file can be determined. Second, the data is sequentially read and processed. The tag byte is parsed to determine the token type and the number of extra bytes, and then literal length (for literal type), or copy length and offset (for copy type) are determined. The third step is the read and the write operation. For literals, the data is directly copied from the input file into the output file, and for copy, memory copy is performed, data is moved from one position to another position in the output file according to the copy length and offset. After the third step, the decompressor will go to the second step again to find the tag byte of the next token. This procedure is repeatedly executed until reaching the end of input file. After that, the entire input file is decompressed completely, and an uncompressed output file can be obtained. Performance Snappy is intended to be fast. On a single core of a Core i7 processor in 64-bit mode, it compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more. (These numbers are for the slowest inputs in our benchmark suite; others are much faster.) In our tests, Snappy usually is faster than algorithms in the same class (e.g. LZO, LZF, QuickLZ, etc.) while achieving comparable compression ratios. Typical compression ratios (based on the benchmark suite) are about 1.5-1.7x for plain text, about 2-4x for HTML, and of course 1.0x for JPEGs, PNGs and other already-compressed data. Similar numbers for zlib in its fastest mode are 2.6-2.8x, 3-7x and 1.0x, respectively. More sophisticated algorithms are capable of achieving yet higher compression rates, although usually at the expense of speed. Of course, compression ratio will vary significantly with the input. Although Snappy should be fairly portable, it is primarily optimized for 64-bit x86-compatible processors, and may run slower in other environments. In particular: Snappy uses 64-bit operations in several places to process more data at once than would otherwise be possible. Snappy assumes unaligned 32 and 64-bit loads and stores are cheap. On some platforms, these must be emulated with single-byte loads and stores, which is much slower. Snappy assumes little-endian throughout, and needs to byte-swap data in several places if running on a big-endian platform. Experience has shown that even heavily tuned code can be improved. Performance optimizations, whether for 64-bit x86 or other platforms, are of course most welcome; see “Contact”, below. Reference https://github.com/google/snappy https://dirtysalt.github.io/html/snappy.html","link":"/2021/10/18/Embedded/snappy/"},{"title":"DSA：（五）数组和矩阵","text":"本文通过单个线性表（三元组）按照行主次序将稀疏矩阵映射到一维数组中，提供重置、转置、加法、乘法、输入、输出操作。稀疏矩阵类sparseMatrix在arrayList类的基础上实现，对arrayList类的方法进行了一些扩充。在代码实现过程中需要注意OJ对时间复杂度的要求，对代码进行优化。 P1008:稀疏矩阵 题目描述 创建稀疏矩阵类（参照课本MatrixTerm三元组定义），采用行主顺序把稀疏矩阵非0元素映射到一维数组中，提供操作:两个稀疏矩阵相加、两个稀疏矩阵相乘、稀疏矩阵的转置、输出矩阵。 键盘输入矩阵的行数、列数，并按行优先顺序输入矩阵的各元素值，建立矩阵。 对建立的矩阵执行相加、相乘、转置的操作，输出操作的结果矩阵。 要求 1.数据类型请使用int，本题中所有运算的结果均视作对int型自然溢出。 2.可以使用vector等STL中的容器保存稀疏矩阵元素，减少不必要的bug。 3.各操作需在稀疏矩阵上进行，充分考虑数据的稀疏性，不得直接或间接转换为二维数组形式计算，否则取消成绩。 操作描述 格式 输入 第一行一个w代表操作个数，接下来若干行是各个操作，其中保证第一个操作一定为重置矩阵。 输出 当执行操作4时，输出矩阵P;当执行操作2或3时，若对应运算不合法，则输出-1。 样例 样例1 输入 12345678910111213141516171819202122232425715 52 1 0 0 00 0 -1 0 00 0 0 0 00 0 -1 0 00 0 0 0 035 542 2 53 5 84 4 25 3 4425 531 1 82 4 43 5 2454 输出 1234567891011121314151617185 52 1 0 0 0 0 5 -1 0 0 0 0 0 0 8 0 0 -1 2 0 0 0 4 0 0 5 516 0 0 4 0 0 0 0 20 -2 0 0 0 0 0 0 0 0 0 -2 0 0 0 0 8 5 516 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 20 0 0 0 0 -2 0 -2 8 样例2 输入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828940110 20-1 0 1 0 0 0 0 0 -1 0 0 0 -1 0 -1 0 0 -1 1 -10 0 2 -1 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 -2 01 0 0 0 0 0 0 0 0 0 -1 -2 -1 0 -1 0 0 0 0 00 0 0 1 0 -1 -1 -1 0 0 1 0 0 0 0 0 0 0 -1 00 0 0 1 0 0 0 0 0 1 -1 1 0 0 0 0 -1 0 0 01 0 -1 1 2 0 0 0 1 0 0 0 0 -1 0 1 -1 1 -1 0-1 0 0 0 -1 0 0 0 0 0 -1 0 0 -1 2 0 0 -1 0 0-1 -1 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 00 0 0 0 0 0 -3 0 0 0 0 -1 -2 1 0 2 0 -1 -1 0-1 1 0 1 -1 0 0 0 -1 0 -1 0 0 0 0 1 0 0 -1 1210 2072 16 93 7 33 17 46 3 47 12 108 13 610 8 3210 2081 20 14 20 56 5 46 10 107 4 87 6 108 12 99 17 5210 2091 8 43 8 63 17 75 1 105 8 46 9 47 12 79 10 99 17 7310 2073 3 105 18 48 5 28 19 58 20 109 12 310 11 104210 2023 16 44 10 6210 2071 16 82 9 83 8 94 2 44 20 78 10 710 3 4210 2011 19 5210 20101 9 82 15 53 2 104 2 54 3 94 7 106 6 66 14 67 2 79 16 9210 2073 14 54 9 86 19 57 17 78 13 49 6 109 20 15220 1076 9 27 8 107 9 911 1 1012 5 618 4 820 6 4220 10213 2 517 5 10119 192 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 10 0 1 0 1 -3 0 0 -1 1 -2 0 -2 0 0 1 0 0 0-1 -1 0 0 1 0 0 1 0 -1 0 0 1 1 0 0 0 1 00 0 -1 0 0 -2 -1 0 0 0 1 0 0 1 2 -1 2 0 00 1 0 -1 0 0 -1 0 0 -1 0 0 0 -1 0 -1 0 -1 00 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -11 0 -1 1 0 0 -1 0 1 1 0 0 0 0 1 0 1 0 -10 0 0 1 0 0 0 -1 0 0 0 0 0 0 0 0 -1 0 -10 -1 1 0 0 0 0 0 0 0 -1 0 0 0 -1 1 0 0 00 0 -1 0 0 0 0 1 0 -1 2 0 2 -1 -1 0 -1 0 01 0 0 -1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 00 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 -1-1 0 0 0 2 -1 2 -2 0 0 0 -1 1 0 0 0 0 0 00 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 -1 0 0 -20 0 -1 0 0 1 0 0 1 -1 0 0 0 1 0 0 0 0 10 0 0 0 1 -1 -1 1 1 0 0 0 0 -1 0 0 0 0 00 -1 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 -10 0 0 -1 0 -1 0 0 0 0 0 -1 0 0 0 0 0 0 00 -1 -1 0 0 1 0 -1 1 0 -1 0 0 0 0 0 0 0 14219 1965 5 25 17 512 3 313 15 514 3 515 9 7219 1987 9 110 1 612 2 414 3 914 8 216 7 318 1 118 14 4219 1991 5 31 18 104 15 46 7 911 19 612 2 114 7 614 14 217 9 8219 1974 18 75 9 17 2 611 9 312 16 315 9 216 5 5219 1933 12 417 7 518 16 45219 19117 17 2319 19611 8 511 14 512 19 617 5 417 15 619 19 4219 1971 1 44 12 56 1 97 8 39 18 813 12 216 14 2219 1928 11 712 4 8319 1971 16 53 9 65 15 314 14 1015 9 615 14 315 19 7219 1961 19 25 8 66 16 69 6 610 18 915 7 555219 1966 7 110 7 613 5 515 16 617 9 1019 15 3219 1963 5 44 9 55 15 111 3 517 5 617 7 7219 19114 6 75219 1933 10 84 18 115 15 8219 1945 8 106 9 106 16 614 15 454219 1992 17 34 18 912 3 813 11 1013 19 714 12 415 4 917 8 919 4 5219 1917 17 6 输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061-1-1-110 200 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 0 0 0 6 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 5 10 0 0 0 0 0 0 0 0 0 9 0 3 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 0 0 0 0 0 0 0 0 -1-1-1-1-1-1-119 192 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 -3 0 0 -1 1 -2 0 -2 0 0 1 0 0 0 -1 -1 0 0 1 0 0 1 0 -1 0 0 1 1 0 0 0 1 0 0 0 -1 0 0 -2 -1 0 0 0 1 0 0 1 2 -1 2 0 0 0 1 0 -1 0 0 -1 0 0 -1 0 0 0 -1 0 -1 0 -1 0 0 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 -1 1 0 0 -1 0 1 1 0 0 0 0 1 0 1 0 -1 0 0 0 1 0 0 0 -1 0 0 0 0 0 0 0 0 -1 0 -1 0 -1 1 0 0 0 0 0 0 0 -1 0 0 0 -1 1 0 0 0 0 0 -1 0 0 0 0 1 0 -1 2 0 2 -1 -1 0 -1 0 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 -1 -1 0 0 0 2 -1 2 -2 0 0 0 -1 1 0 0 0 0 0 0 0 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 -1 0 0 -2 0 0 -1 0 0 1 0 0 1 -1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 -1 -1 1 1 0 0 0 0 -1 0 0 0 0 0 0 -1 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 -1 0 0 0 -1 0 -1 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 -1 -1 0 0 1 0 -1 1 0 -1 0 0 0 0 0 0 0 1 19 190 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 样例3 输入 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085092015 11-22324 -8307 9206 122 -7218 21649 -16209 11639 3813 12960 15895-6355 8061 -4443 9028 -2663 20150 6485 8100 -12939 -1189 -895417884 -3031 -10317 6894 9240 -1078 9344 -16194 -1543 -16063 -15494-19732 3868 -25565 1922 4300 8148 -13256 4611 2077 26163 1073810610 -2944 6357 4205 -12046 2795 13566 18396 11768 -5985 -345525 5251 1 11 2 21 3 21 4 21 5 32 1 12 2 12 3 32 4 22 5 23 1 13 2 13 3 33 4 23 5 14 1 24 2 14 3 34 4 24 5 25 1 25 2 25 3 35 4 25 5 2425 5251 1 21 2 11 3 21 4 11 5 22 1 32 2 22 3 12 4 32 5 13 1 13 2 13 3 13 4 23 5 34 1 24 2 14 3 24 4 34 5 35 1 25 2 25 3 25 4 15 5 325 5251 1 31 2 11 3 11 4 21 5 12 1 12 2 12 3 22 4 22 5 33 1 33 2 13 3 33 4 13 5 14 1 24 2 34 3 24 4 34 5 15 1 15 2 15 3 25 4 15 5 125 5251 1 21 2 21 3 11 4 31 5 22 1 12 2 32 3 32 4 12 5 13 1 23 2 23 3 23 4 13 5 34 1 34 2 14 3 14 4 24 5 25 1 25 2 25 3 15 4 15 5 325 5251 1 21 2 11 3 11 4 21 5 22 1 22 2 32 3 12 4 22 5 23 1 33 2 13 3 33 4 33 5 24 1 34 2 24 3 34 4 24 5 15 1 15 2 25 3 35 4 25 5 2425 5251 1 21 2 31 3 21 4 21 5 32 1 12 2 32 3 22 4 12 5 23 1 13 2 13 3 23 4 33 5 14 1 14 2 24 3 14 4 14 5 15 1 35 2 25 3 25 4 15 5 225 5251 1 31 2 21 3 21 4 31 5 22 1 32 2 22 3 22 4 22 5 33 1 33 2 33 3 13 4 33 5 14 1 24 2 34 3 14 4 34 5 15 1 35 2 35 3 35 4 35 5 235 5251 1 21 2 21 3 11 4 31 5 22 1 12 2 12 3 32 4 32 5 13 1 23 2 13 3 33 4 23 5 14 1 24 2 34 3 24 4 14 5 25 1 15 2 15 3 35 4 15 5 244212 131561 1 31 2 21 3 21 4 31 5 31 6 31 7 11 8 21 9 31 10 21 11 11 12 31 13 32 1 12 2 12 3 22 4 32 5 22 6 22 7 32 8 12 9 12 10 22 11 12 12 12 13 23 1 23 2 23 3 23 4 23 5 13 6 33 7 33 8 23 9 23 10 33 11 23 12 33 13 24 1 34 2 24 3 24 4 24 5 34 6 24 7 24 8 34 9 24 10 24 11 24 12 24 13 35 1 25 2 15 3 35 4 35 5 35 6 25 7 35 8 25 9 15 10 35 11 25 12 35 13 36 1 16 2 36 3 36 4 26 5 16 6 36 7 26 8 36 9 26 10 16 11 36 12 26 13 37 1 27 2 27 3 37 4 17 5 17 6 17 7 27 8 17 9 37 10 17 11 17 12 37 13 38 1 18 2 28 3 18 4 38 5 38 6 28 7 38 8 18 9 28 10 18 11 28 12 38 13 19 1 39 2 39 3 29 4 19 5 39 6 39 7 39 8 19 9 19 10 39 11 29 12 29 13 210 1 310 2 310 3 110 4 110 5 110 6 310 7 210 8 110 9 110 10 310 11 310 12 310 13 211 1 111 2 211 3 211 4 311 5 211 6 111 7 111 8 211 9 311 10 211 11 311 12 211 13 312 1 212 2 312 3 112 4 212 5 212 6 212 7 312 8 312 9 212 10 212 11 112 12 112 13 225 5251 1 11 2 31 3 31 4 11 5 32 1 22 2 22 3 32 4 22 5 13 1 33 2 13 3 13 4 23 5 14 1 14 2 34 3 14 4 14 5 35 1 35 2 25 3 15 4 25 5 125 5251 1 21 2 11 3 21 4 11 5 22 1 12 2 12 3 22 4 22 5 23 1 13 2 13 3 13 4 33 5 34 1 24 2 14 3 34 4 34 5 35 1 25 2 15 3 25 4 15 5 1425 5251 1 21 2 31 3 21 4 31 5 32 1 12 2 22 3 32 4 32 5 23 1 33 2 13 3 33 4 23 5 14 1 34 2 14 3 34 4 24 5 35 1 15 2 15 3 35 4 35 5 2425 5251 1 31 2 11 3 21 4 21 5 12 1 12 2 32 3 32 4 32 5 13 1 13 2 23 3 13 4 13 5 34 1 24 2 24 3 14 4 34 5 15 1 25 2 25 3 35 4 25 5 1 输出 123456789101112131415161718192021222324252627282930313233343536373839-15 51 2 2 2 3 1 1 3 2 2 1 1 3 2 1 2 1 3 2 2 2 2 3 2 2 5 516143 13975 16499 16583 13958 14052 12162 14360 14438 12152 12440 10759 12704 12777 10751 15373 13308 15713 15794 13293 17168 14856 17540 17632 14838 5 51945386 1782533 1254468 1903751 1285027 1693395 1551629 1091979 1657151 1118577 1498468 1373016 966290 1466390 989824 1852660 1697571 1194674 1813009 1223776 2068355 1895207 1333773 2024085 1366260 5 51945386 1782533 1254468 1903751 1285027 1693395 1551629 1091979 1657151 1118577 1498468 1373016 966290 1466390 989824 1852660 1697571 1194674 1813009 1223776 2068355 1895207 1333773 2024085 1366260 -1-15 516 11 20 22 23 15 10 19 22 24 14 8 17 15 18 14 9 18 16 17 15 9 19 17 20 5 5192 135 260 234 202 187 130 255 229 198 150 108 202 184 156 156 111 208 188 160 167 119 225 204 173 限制 2s, 64MB for each test case. 算法描述 定义结构体matrixTerm，成员为矩阵元素所在的行row，矩阵元素所在的列col，矩阵元素的值value。 在数组描述线性表arrayList的基础上增加方法reSet,set,clear。reSet方法把线性表元素个数改为newSize，必要时增大数组容量，set方法使元素theElement成为表中索引为theIndex的元素，clear方法使表的元素个数为0。增加赋值运算符重载方法，实现一个线性表对当前线性表的赋值。 使用数组存储结构，按照行主映射，封装稀疏矩阵类sparseMatrix，私有成员包括矩阵的行数rows和列数cols，非0项表terms。公有成员包括构造函数，复制构造函数，析构函数，对赋值运算符的重载，重置矩阵，矩阵转置，矩阵相加，矩阵相乘，输入矩阵，输出矩阵。每个方法的具体思想如下： reSet：重置矩阵。清空terms表，首先读入矩阵的行数和列数，然后按照行列读入元素值，读入后判断元素值是否为0，若不为0，对三元组mTerm的row，col，value赋值，将mTerm插入到terms中的合适位置。 transpose：矩阵转置。创建稀疏矩阵类的对象b用来保存* this的转置，设置转置矩阵的特征，通过colSize和rowNext找出b中每一行的起点，利用迭代器遍历* this的terms表中的每个元素，通过rowNext的记录将b中对应位置的元素设置为mTerm，最后将b赋值给* this。 add：矩阵相加。创建稀疏矩阵类的对象b，调用input方法读入稀疏矩阵。根据矩阵加法的定义判断* this和b是否可以相加，若不能输出-1然后返回，若能，创建稀疏矩阵类的对象c存储相加结果，设置c的特征，首先通过循环利用迭代器遍历* this和b，把相关的项相加，每次相加分为三种情况进行考虑，b项在后，t项在后，两项在同一个位置。循环结束后对* this或b中剩余的元素进行处理，将其插入到c中terms表的合适位置。最后将c赋值给* this。 multiply：矩阵相乘。创建稀疏矩阵类的对象b，调用input方法读入稀疏矩阵。根据矩阵乘法的定义判断* this和b是否可以相乘，若不能输出-1然后返回，若能，创建稀疏矩阵类的对象c存储相乘结果，设置c的特征。与矩阵转置类似，先通过循环寻找b中每一行的项的数目和每一行的起点。通过循环利用迭代器遍历* this，根据rowNext和rowSize在内部嵌套一层循环把相关的项相乘，两层循环结束后将非零元素插入到c中terms表的合适位置。最后将c赋值给* this。 input：输入矩阵。首先输入矩阵的特征rows，cols，numberOfTerms，调用terms的reSet方法，确定terms的长度，然后循环读入每个非零元素，通过terms的set方法将terms对应位置的值设置为mTerm。 output：输出矩阵。首先输出矩阵的行数和列数，然后定义迭代器i和iEnd，设计两层循环，判断当前位置是否是i所指的三元组的位置，若是则表明当前位置是非零元素，输出三元组对应位置的value值，然后i++，若不是则输出0。 C++实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;iterator&gt;using namespace std;template &lt;class T&gt;class arrayList{protected: int listSize; //线性表的元素个数 int arrayLength; //一维数组的容量 T* element; //存储线性表的一维数组public: arrayList(int initialCapacity=10); //构造函数 arrayList(const arrayList&amp; theList); //复制构造函数 ~arrayList(); //析构函数 //ADT方法 bool empty() const {return listSize==0;} //判断线性表是否为空 int size() const {return listSize;} //返回线性表的大小 T&amp; get(int theIndex) const; //返回索引为theIndex的元素 int indexOf(const T&amp; theElement) const; //返回元素theElement第一次出现时的索引，若不存在返回-1 void erase(int theIndex); //删除索引为theIndex的元素 void insert(int theIndex,const T&amp; theElement);//在索引为theIndex处插入元素theElement void output(ostream&amp; out) const; //把线性表插入输入流 //其他方法 int capacity() const {return arrayLength;} //返回一维数组容量的大小 //运算符重载 arrayList&lt;T&gt;&amp; operator=(const arrayList&lt;T&gt;&amp; a) {//赋值运算符重载，使用前必须先调用reSet方法 copy(a.element,a.element+a.listSize,element); return *this; } //扩展方法 //用于稀疏矩阵的方法 void reSet(int newSize); //把线性表元素个数改为newSize，必要时增大数组容量 void set(int theIndex,const T&amp; theElement); //使元素theElement成为表中索引为theIndex的元素 void clear(); //使表的元素个数为0 //迭代器 class iterator { protected: T* position; //指向表元素的指针 public: //用C++的typedef语句实现双向迭代器 typedef bidirectional_iterator_tag __iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference; iterator(T* thePosition=0) //构造函数 { position=thePosition; } //解引用操作符 T&amp; operator* () const {return *position;} T* operator-&gt; () const {return &amp;*position;} //迭代器加法操作 iterator&amp; operator++ ()//前++ { ++position; return *this; } iterator operator++ (int)//后++ { iterator old=*this; ++position; return old; } //迭代器减法操作 iterator&amp; operator-- ()//前-- { --position; return *this; } iterator operator-- (int)//后-- { iterator old=*this; --position; return old; } //相等检验 bool operator!= (const iterator right) const { return position!=right.position; } bool operator== (const iterator right) const { return position==right.position; } }; iterator begin() const {return iterator(element);} iterator end() const {return iterator(element+listSize);} //iterator setIterator(int offset) const {return iterator(element+offset);}};template&lt;class T&gt;arrayList&lt;T&gt;::arrayList(int initialCapacity){//构造函数 arrayLength=initialCapacity; element=new T[arrayLength]; listSize=0;}template&lt;class T&gt;arrayList&lt;T&gt;::arrayList(const arrayList&amp; theList){//复制构造函数 arrayLength=theList.arrayLength; listSize=theList.listSize; element=new T[arrayLength]; copy(theList.element,theList.element+listSize,element);}template&lt;class T&gt;arrayList&lt;T&gt;::~arrayList(){//析构函数 delete []element;}template&lt;class T&gt;T&amp; arrayList&lt;T&gt;::get(int theIndex) const{//返回索引为theIndex的元素 return element[theIndex];}template&lt;class T&gt;int arrayList&lt;T&gt;::indexOf(const T&amp; theElement) const{//返回元素theElement第一次出现时的索引，若不存在返回-1 //查找元素theElement int theIndex=(int) (find(element,element+listSize,theElement)-element); //确定元素theElement是否找到 if(theIndex==listSize) //没有找到 return -1; else //已经找到 return theIndex;}template&lt;class T&gt;void arrayList&lt;T&gt;::erase(int theIndex){//删除索引为theIndex的元素 //移动其索引大于theIndex的元素 copy(element+theIndex+1,element+listSize,element+theIndex); element[--listSize].~T(); //调用析构函数}template&lt;class T&gt;void arrayList&lt;T&gt;::insert(int theIndex,const T&amp; theElement){//在索引为theIndex处插入元素theElement if(listSize==arrayLength) //确定数组是否已满 { T* Nelement=new T[arrayLength*2]; arrayLength=arrayLength*2; copy(element,element+listSize,Nelement); delete []element; element=Nelement; } //把元素向右移动一个位置 copy_backward(element+theIndex,element+listSize,element+listSize+1); element[theIndex]=theElement; listSize++;}template&lt;class T&gt;void arrayList&lt;T&gt;::output(ostream&amp; out) const{//把线性表插入输入流 copy(element,element+listSize,ostream_iterator&lt;T&gt;(cout,&quot; &quot;));}template&lt;class T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out,const arrayList&lt;T&gt;&amp; x){//重载&lt;&lt; x.output(out); return out;}template &lt;class T&gt;void arrayList&lt;T&gt;::reSet(int newSize){//把线性表元素个数改为newSize，必要时增大数组容量 if(newSize==0) //设置为空表 { for(int i=0;i&lt;listSize;i++) element[i].~T(); listSize=0; return ; } if(listSize==newSize) ; else if(listSize&gt;newSize) { for(int i=newSize;i&lt;listSize;i++) element[i].~T(); listSize=newSize; } else //listSize&lt;newSize { if(arrayLength&gt;=newSize) //数组容量足够 { listSize=newSize; } else //数组容量不够 { T* Nelement=new T[newSize]; delete []element; element=Nelement; arrayLength=newSize; listSize=newSize; } }}template &lt;class T&gt;void arrayList&lt;T&gt;::set(int theIndex,const T&amp; theElement){//使元素theElement成为表中索引为theIndex的元素 element[theIndex]=theElement;}template &lt;class T&gt;void arrayList&lt;T&gt;::clear(){//使表的元素个数为0 for(int i=0;i&lt;listSize;i++) element[i].~T(); listSize=0;}template &lt;class T&gt;struct matrixTerm //三元组{ int row,col; //矩阵元素所在行和所在列 T value; //矩阵元素的值};template &lt;class T&gt;class sparseMatrix{private: int rows,cols; //矩阵的行数和列数 arrayList&lt;matrixTerm&lt;T&gt;&gt; terms; //非0项表public: //构造函数、复制构造函数和析构函数 sparseMatrix() {} sparseMatrix(const sparseMatrix&lt;T&gt;&amp; x):terms(x.terms),rows(x.rows),cols(x.cols) {} ~sparseMatrix() {} //方法 void reSet(); //重置矩阵 void transpose(); //矩阵转置 void add(); //矩阵相加 void mul(); //矩阵相乘 void input(); //输入矩阵 void output(); //输出矩阵 //运算符重载 sparseMatrix&lt;T&gt;&amp; operator=(const sparseMatrix&lt;T&gt;&amp; x);};template &lt;class T&gt;void sparseMatrix&lt;T&gt;::reSet(){//重置矩阵 terms.clear(); //清空表 int value; //输入的矩阵元素值 int mSize=0; //插入三元组线性表的位置 matrixTerm&lt;T&gt; mTerm; cin&gt;&gt;rows&gt;&gt;cols; for(int i=1;i&lt;=rows;i++) { for(int j=1;j&lt;=cols;j++) { cin&gt;&gt;value; if(value!=0) //非零元素插入线性表 { mTerm.row=i; mTerm.col=j; mTerm.value=value; terms.insert(mSize,mTerm); mSize++; } } }}template&lt;class T&gt;void sparseMatrix&lt;T&gt;::transpose(){//b保存*this的转置，再将b赋值给*this sparseMatrix&lt;T&gt; b; //保存*this的转置 //设置转置矩阵的特征 b.cols=rows; b.rows=cols; b.terms.reSet(terms.size()); //初始化以实现转置 int* colSize=new int[cols+1]; int* rowNext=new int[cols+1]; //寻找*this中每一列的项的数目 for(int i=1;i&lt;=cols;i++)//初始化 colSize[i]=0; for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator i=terms.begin();i!=terms.end();i++) colSize[(*i).col]++; //寻找b中每一行的起点 rowNext[1]=0; for(int i=2;i&lt;=cols;i++) rowNext[i]=rowNext[i-1]+colSize[i-1]; //实施从*this到b的转置复制 matrixTerm&lt;T&gt; mTerm; for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator i=terms.begin();i!=terms.end();i++) { int j=rowNext[(*i).col]++; //b中的位置 mTerm.row=(*i).col; mTerm.col=(*i).row; mTerm.value=(*i).value; b.terms.set(j,mTerm); } delete []colSize; delete []rowNext; *this=b;}template &lt;class T&gt;void sparseMatrix&lt;T&gt;::add(){//计算c=(*this)+b，再将c赋值给*this sparseMatrix&lt;T&gt; b; //和*this做加法的矩阵 b.input(); //不满足矩阵相加的条件 if(rows!=b.rows||cols!=b.cols) { *this=b; cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; //printf(&quot;-1\\n&quot;); return ; } //可以进行矩阵相加 sparseMatrix&lt;T&gt; c; //结果矩阵 //设置结果为矩阵c的特征 c.rows=rows; c.cols=cols; c.terms.clear(); int cSize=0; //定义*this和b的迭代器 typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator it=terms.begin(); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ib=b.terms.begin(); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator itEnd=terms.end(); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ibEnd=b.terms.end(); //遍历*this和b，把相关的项相加 while(it!=itEnd &amp;&amp; ib!=ibEnd) { //行主索引加上每一行的列数 int tIndex=(*it).row*cols+(*it).col; int bIndex=(*ib).row*cols+(*ib).col; if(tIndex&lt;bIndex) {//b项在后 c.terms.insert(cSize++,*it); it++; } else if(tIndex==bIndex) {//两项在同一个位置 //仅当相加后不为0时加入c if((*it).value+(*ib).value!=0) { matrixTerm&lt;T&gt; mTerm; mTerm.row=(*it).row; mTerm.col=(*it).col; mTerm.value=(*it).value+(*ib).value; c.terms.insert(cSize++,mTerm); } it++; ib++; } else //t项在后 { c.terms.insert(cSize++,*ib); ib++; } } //复制剩余项 for(;it!=itEnd;it++) c.terms.insert(cSize++,*it); for(;ib!=ibEnd;ib++) c.terms.insert(cSize++,*ib); *this=c;}template &lt;class T&gt;void sparseMatrix&lt;T&gt;::mul(){//计算c=(*this)*b，再将c赋值给*this sparseMatrix&lt;T&gt; b; //和*this做乘法的矩阵 b.input(); //不满足矩阵相乘的条件 if(cols!=b.rows) { *this=b; cout&lt;&lt;&quot;-1&quot;&lt;&lt;endl; //printf(&quot;-1\\n&quot;); return ; } //可以进行矩阵相乘 sparseMatrix&lt;T&gt; c; //结果矩阵 //设置结果为矩阵c的特征 c.rows=rows; c.cols=b.cols; c.terms.clear(); int cSize = 0; //rowSize表示第i行元素的数目，rowNext表示第i行首元素的位置，0号位置不用 int* rowSize=new int[b.rows+1]; int* rowNext=new int[b.rows+1]; //寻找b中每一行的项的数目 for(int i=1;i&lt;=b.rows;i++) //初始化 rowSize[i]=0; for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator i=b.terms.begin();i!=b.terms.end();i++) rowSize[(*i).row]++; //寻找b中每一行的起点 rowNext[1]=0; for(int i=2;i&lt;=cols;i++) rowNext[i]=rowNext[i-1]+rowSize[i-1]; //定义*this的迭代器 typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator itEnd=terms.end(); matrixTerm&lt;T&gt; sumTerm[c.rows*c.cols]; //保存计算结果 for(int i=0;i&lt;c.rows*c.cols;i++) //初始化 sumTerm[i].value=0; for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator it=terms.begin();it!=itEnd;it++) { /*方法一：定义指向线性表首元素的迭代器，根据rowNext的值移动迭代器到合适位置 typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ib=b.terms.begin(); for(int i=0;i&lt;rowNext[(*it).col];i++) //移动迭代器 ib++; */ /*方法二：在arrayList中增加方法setIterator，可直接声明指向线性表任意位置的迭代器 typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ib=b.terms.setIterator(rowNext[(*it).col]); */ /*方法一和方法二实现相乘 for(int k=0;k&lt;rowSize[(*it).col];k++) //相关的两个元素相乘 { sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].value+=(*it).value * (*ib).value; //确定行数和列数 sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].row=(*it).row; sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].col=(*ib).col; ib++; }*/ //方法三：使用terms的get方法 int iib=rowNext[(*it).col]; for(int k=0;k&lt;rowSize[(*it).col];k++) { sumTerm[(((*it).row-1) * c.cols) + b.terms.get(iib).col-1].value+=(*it).value * b.terms.get(iib).value; //确定行数和列数 sumTerm[(((*it).row-1) * c.cols) + b.terms.get(iib).col-1].row=(*it).row; sumTerm[(((*it).row-1) * c.cols) + b.terms.get(iib).col-1].col=b.terms.get(iib).col; iib++; } } for(int i=0;i&lt;c.rows*c.cols;i++) { if(sumTerm[i].value!=0) //非零元素插入到三元组的线性表中 { c.terms.insert(cSize++, sumTerm[i]); } } delete []rowSize; delete []rowNext; /*矩阵乘法O(n^4)实现方法 //定义*this和b的迭代器 typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator itEnd=terms.end(); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ibEnd=b.terms.end(); matrixTerm&lt;T&gt; sumTerm[c.rows*c.cols]; //保存计算结果 for(int i=0;i&lt;c.rows*c.cols;i++) //初始化 sumTerm[i].value=0; for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator it=terms.begin();it!=itEnd;it++) { for(typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator ib=b.terms.begin();ib!=ibEnd;ib++) { if((*it).col==(*ib).row) //相关的两个元素相乘 { sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].value+=(*it).value * (*ib).value; //确定行数和列数 sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].row=(*it).row; sumTerm[(((*it).row-1) * c.cols) + (*ib).col-1].col=(*ib).col; } } } for(int i=0;i&lt;c.rows*c.cols;i++) { if(sumTerm[i].value!=0) //非零元素插入到三元组的线性表中 { c.terms.insert(cSize++, sumTerm[i]); } }*/ *this=c;}template &lt;class T&gt;void sparseMatrix&lt;T&gt;::input(){//输入一个稀疏矩阵 //输入矩阵特征 int numberOfTerms; //非零元素个数 cin&gt;&gt;rows&gt;&gt;cols&gt;&gt;numberOfTerms; terms.reSet(numberOfTerms); matrixTerm&lt;T&gt; mTerm; for(int i=0;i&lt;numberOfTerms;i++) { cin&gt;&gt;mTerm.row&gt;&gt;mTerm.col&gt;&gt;mTerm.value; terms.set(i,mTerm); }}template &lt;class T&gt;void sparseMatrix&lt;T&gt;::output(){//输出一个稀疏矩阵 cout&lt;&lt;rows&lt;&lt;&quot; &quot;&lt;&lt;cols&lt;&lt;endl; //输出矩阵的行数和列数 //printf(&quot;%d %d\\n&quot;,rows,cols); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator i=terms.begin(); typename arrayList&lt;matrixTerm&lt;T&gt;&gt;::iterator iEnd=terms.end(); int val; //元素值 for(int k=1;k&lt;=rows;k++) { for(int j=1;j&lt;=cols;j++) { val=0; if(k==(*i).row &amp;&amp; j==(*i).col &amp;&amp;i!=iEnd) //不是非零元素 { val=(*i).value; //非零元素的值 i++; } cout&lt;&lt;val&lt;&lt;&quot; &quot;; //printf(&quot;%d &quot;,val); } cout&lt;&lt;endl; //printf(&quot;\\n&quot;); }}template &lt;class T&gt;sparseMatrix&lt;T&gt;&amp; sparseMatrix&lt;T&gt;::operator=(const sparseMatrix&lt;T&gt; &amp;x){//赋值运算符重载 if(this==&amp;x) //自我复制 return *this; terms.reSet(x.terms.size()); terms=x.terms; rows=x.rows; cols=x.cols; return *this;}int main(){ int w; //操作个数 int instruction; //指令编号 sparseMatrix&lt;int&gt; s; //创建对象 cin&gt;&gt;w; for(int i=0;i&lt;w;i++) { cin&gt;&gt;instruction; switch(instruction) { case 1: s.reSet(); break; case 2: s.mul(); break; case 3: s.add(); break; case 4: s.output(); break; case 5: s.transpose(); break; } } return 0;} 结果分析 1.本题时间限制为2s，只有当稀疏矩阵乘法的时间复杂度为O(n3)(n为矩阵的行数)时才能保证不超时，O(n4)最后2个节点会超时。 如果对于* this中的每一个元素，遍历b中每一个元素，比较所在行和列判断是否需要相乘，时间复杂度是O(n^4)，n为矩阵行数。优化方法与矩阵转置中的思想类似，先通过循环寻找b中每一行的元素个数和每一行的起点，对于* this中的某一个元素，由* this所在的列直接找出b中对应的行，该行的所有元素即为需要与其相乘的元素，循环次数为b中对应行的元素个数，这样时间复杂度是O(n^3)。 2.对“=”的运算符重载实现一个对象赋值给当前对象，不能使用默认的赋值运算符重载函数，因为arrayList类的成员中涉及到T类型的指针element，需要深复制，重新申请内存将element所指的数组中各个元素的值依次复制过来，而默认的运算符重载实现的是浅复制，只复制指针，不能复制指针指向的数组。 PS:最后五个节点是矩阵不稀疏的情况，最大数据量为100次询问，操作为100 * 100矩阵的乘法、加法、转置（大部分是乘法）。","link":"/2020/10/21/CS/DSA/DSA_5/"},{"title":"计算机网络","text":"How to build a network? Computer Networks 1Mbps=106bps1Mbps=10^{6}bps1Mbps=106bps 1Gbps=109bps1Gbps=10^{9}bps1Gbps=109bps 第一章：引言 1.1 名词解释 计算机网络：一组通过单一技术相互连接的自主计算机集合。 VPN（Virtual Private Networks）：虚拟专用网络。 peer-to-peer：对等。 P2P：对等计算机网络，是一种在对等者（Peer）之间分配任务和工作负载的分布式应用架构，是对等计算模型在应用层形成的一种组网或网络形式。 RFID（Radio Frequency IDentification）：射频识别。 hotspot：无线热点。 GPS（Global Positioning System）：全球定位系统。 NFC（Near Field Communication）：近场通信。 点到点，端到端。 单播（unicasting）、广播（broadcasting）：同时给全部目标地址发送一个数据包、组播（multicasting）。 PAN（Personal Area Network）：个域网 LAN（Local Area Network）：局域网 WIFI：无线局域网的一个标准 IEEE 802.11 Ethernet：以太网 IEEE 802.3 VLAN（Virtual LAN）：虚拟局域网 MAN（Metropolitan Area Network）：城域网 WAN（Wide Area Network）：广域网 通信子网（subnet）、子网：子网的工作是把信息从一个主机携带到另一个主机。 子网由两个不同部分组成：传输线路（e.g. 铜线、光纤、无线）和交换元素（交换机、路由器）。 ISP（Internet Service Provider）：Internet服务提供商。相应的子网称为ISP网络。 协议：通信双方就如何进行通信的一种约定。 对等体：不同机器上构成相应层次的实体。 接口：定义了下层向上层提供哪些原语操作和服务。 网络体系结构：层和协议的集合。 协议栈：一个特定的系统所使用的一组协议，即每一层一个协议。 统计复用：许多网络设计根据主机的短期需求变化动态共享网络带宽，而不是给每个主机分配可能用也可能不会用的固定比例带宽。 流量控制：保持快速发送方不会用数据把慢速接收方淹没。 拥塞：太多的计算机需要发送太多的流量，而网络没有能力传递所有的数据包。 面向连接的服务：按照电话系统建模。 无连接服务：按照邮政系统建模。 存储-转发交换：中间节点只能在收到报文的全部内容后再将该报文发送给下一个节点。 直通式交换：报文还未全部接受完毕之前就向下一个节点传输。 DNS（Domain Name System）：域名系统，将主机名字映射到网络地址。 ISO（International Standards Organization）：国际标准化组织。 OSI（Open Systems Interconnection）：开放系统互连。 物理层：关注在一条通信信道上传输原始比特。 数据链路层：将一个原始的传输设施转变成一条没有漏检传输错误的线路。 网络层：控制子网的运行。关注如何将数据报从源端路由到接收方。 传输层：接收来自上一层的数据，在必要的时候把这些数据分割成较小的单元，然后把这些数据单元传递给网络层，并且确保这些数据单元正确地到达另一端。 IP（Internet Protocol）：因特网协议。 ICMP（Internet Control Message Protocol）：因特网控制报文协议。 TCP（Transport Control Protocol）：传输控制协议，可靠的、面向连接的。 UDP（User Datagram Protocol）：用户数据报协议，不可靠的、无连接的。 DSL（Digital Subscriber Line）：数字用户线。 modem ：调制解调器。 CMTS（Cable Modem Termination System）：线缆调制解调终端系统。 宽带（broadband）：以高于拨号速率（56kbps）接入Internet。IEEE 802.16 FTTH（Fiber to the Home）：光纤到户。 POP（Point of Presence）：ISP存点，客户数据报进入ISP网络使用其服务的位置。 IXP（Internet eXchange Point）：Internet交换点。相互连接的ISP被认为彼此对等。 AMPS（Advanced Mobile Phone System）：高级移动电话系统。 1G GSM（Global System for Mobile communications）：全球移动通信系统。 2G UMTS（Universal Mobile Telecommunications System）：通用移动通信系统。 3G CDMA（Code Division Multiple Access）：码分多址。 WCDMA（Wideband Code Division Multiple Access）：宽带码分多址。 GPRS（General Packet Radio Service）：通用数据报无线业务。 软切换（soft handover）–硬切换（hard handover） SIM（Subscriber Identity Module）：用户识别模块。 ISM（Industral Scientific and Medical）：工业科学医疗频段。 AP（Access Point）：接入点。 OFDM（Orthogonal Frequency Division Multiplexing）：正交频分复用。 CSMA（Carrier Sense Multiple Access）：载波侦听多路访问。 WPA（WiFi Protected Access）：WiFi保护接入。 第二章：物理层 2.1 数据通信的理论基础 2.1.1 傅里叶分析 2.1.2 带宽有限的信号 带宽：在传输过程中振幅不会明显减弱的频率的宽度 or 单位时间内可以传递的数据位数 带宽是传输介质的一种物理特性，通常取决于介质的构成、厚度和电线或者光纤的长度。 一般将从0到某个最大频率的信号称为基带信号，将被搬移并占用某个更大频率范围的信号称为通带信号。 2.1.3 信道的最大数据速率 尼奎斯特定理 在无噪声信道中，如果物理带宽为 BBB ，信号离散度等级为 VVV ，则该信道最大数据速率 （数字带宽）= 2Blog2V bps2B log_{2}V \\ bps2Blog2​V bps ，计算后还要乘每秒采样数。 任意一个信号的通过一个物理带宽为 BBB 的低通滤波器只要进行每秒 2B2B2B 次的采样就可完全重构出被滤掉的信号。 信道一定，物理带宽确定时，要提高数字带宽只有增加离散等级。 香农定理 在有噪声信道中，如果物理带宽为 BBB ，信噪比为 S/NS/NS/N ，则该信道最大数据速率 （数字带宽）= Blog2(1+S/N) bpsB log_{2}(1+S/N) \\ bpsBlog2​(1+S/N) bps 。 分贝值 = 10log10S/N dB10log_{10}S/N \\ dB10log10​S/N dB 信道一定，物理带宽确定时，要提高数字带宽只有增加信噪比。 2.2 引导性传输介质 全双工（full-deplex）：可以双向同时使用的链路。 半双工（half-deplex）：可以双向使用但是一次只能使用一个方向的链路。 单双工（simplex）：只允许一个方向上的传输的链路。 2.3 无线传输 2.4 通信卫星 2.5 数字调制与多路复用 多路复用：信道被多个信号共享。 基带传输：信号的传输占有传输介质上从零到最大值之间的全部频率。 通带传输：信号占据了以载波信号频率为中心的一段频带。 2.5.1 基带传输 NRZ（Non-Return-to-Zero）：不归零。 曼彻斯特编码 从低到高：逻辑0 从高到低：逻辑1 需要两倍于NRZ编码的带宽。 每一位的中间有一跳变，位中间的跳变既作时钟信号，又作数据信号。 差分曼彻斯特编码 每位中间的跳变仅提供时钟定时。 第一个信号：如果中间位电平从低到高，则表示0；如果中间位电平从高到低，则表示1。 从第二个信号开始，每位开始时有无跳变表示&quot;0&quot;或&quot;1&quot;，有跳变为&quot;0&quot;，无跳变为&quot;1&quot;。 NRZI（Non-Return-to-Zero Inverted）：不归零逆转 信号有跳变：1 信号无跳变：0 4B/5B 4个比特被映射为5个比特 保证永远不会出现连续三个0 双极编码 使用两个电压级别表示逻辑1 发送1时在+1V和-1V之间进行选择 2.5.2 通带传输 ASK（Amplitude Shift Keying）：幅移键控。通过两个不同的振幅表示0和1。 FSK（Frequency Shift Keying）：频移键控。通过两个不同的频率表示0和1。 最简单的形式是相移键控（PSK，Phase Shift Keying）。 二进制相移键控（BPSK，Binary Phase Shift Keying）：载波波形偏移0°或180°。 正交相移键控（QPSK，Quadrature Phase Shift Keying）：4个偏移，45°、135°、225°、315°。 2.5.3 频分复用 FDM：Frequency Division Multiplexing 保护带（guardband）：使信道之间完全隔离。 OFDM（Orthogonal Frequency Division Multiplexing）：正交频分复用。 2.5.4 时分复用 TDM：Time Division Multiplexing 每个用户周期性获得整个带宽非常短的一个时间。 要求时间上必须同步，各用户需要的带宽不均衡，而TDW用户时间片的使用却是一样的，将造成信道的浪费，不高效。 2.5.5 码分复用 CDMA：Code Division Multiple Access 允许每个站利用整个频段发送信号，没有时间限制。 可以将TDM看作许多人按顺序交谈，将FDM看作不用人按不同语调交谈，CDMA则是每对交谈者使用不用的语言。 CDMA关键在于能够提取出需要的信号，同时拒绝所有其他的信号并把这些信号当作噪声。 2.6 公共电话交换网络 本地回路(Local loops)：模拟线路，连接端局和千家万户，通常用三类双绞线承担。 干线、中继线(Trunks)：数字光纤，连接交换局。 交换局(Switching offices)：语音接驳干线的场所，包括端局。 56k（64k）的调制解调器：V.90标准电话线路频率为4kHz，采样率 =2×4000=8000sample/sec=2×4000=8000sample/sec=2×4000=8000sample/sec ，每个码元传输8bit，其中1个比特控制错误，故传输数据速率 =8000×7=56000kbps=8000×7=56000kbps=8000×7=56000kbps，若算上控制错误的比特，毛速率为64kbps。 ADSL（Asymmetric Digital Subscriber Lines）： 非对称数字用户线。 连接调制解调器的本地回路带宽，被限制为4k，因为电话占频为4k；xDSL取消了电话系统里的滤波器后，可使用本地回路的全部（1.1兆）物理带宽。 使用离散多音（DMT，Discrete MultiTone）调制方法的ADSL操作： 1.1MHz的频谱，分为256根信道，每根4kHz（4312.5Hz）。信道0用于简单老式电话服务（POTS），信道1~5空闲， 剩下250条信道中，一条用于上行流控制，一条用于下行流控制，剩余248条信道用于数据传输（一种常见的分法是32条用于上行数据流）。 每条信道内使用QAM调制方案，速率约为4000符号/秒。 QAM-64每个符号传输6bits。 1999年设定国际标准G.dmt，下行速度8Mbps，上行速度1Mbps。 DSLAM（Digital Subscriber Line Access Multiplexer）：数字用户线路接入复用器。 NID（Network Interface Device）：网络接口设备。 光纤入户（FttH）: PON（Passive Optical Network）：无源光网络。 下行流：光分离器 。上行流：光合并器。 脉冲编码调制：PCM，Pulse Code Modulation 模拟信号数字化的技术。构成了现代PSTN的核心。 采样、量化、编码、传输。 每125微秒发送一个语音样值，该采样率足以捕捉4kHz电话信道带宽上的信息。 时分多路复用TDM T1载波（北美和日本），24路。 每帧24×8=192个比特，加上控制用的一个比特的帧码，每125微秒产生193个比特，即数据传输率为193bits/0.000125s=1.544Mbps，8kbps用于信令控制。 每个样值中每个信道有7个数据比特，故1帧中包含的数据为24×7=168bits。 E1载波（中国），32路语音的复用 每125微秒传递32*8=256个比特，即数据传输率为256bits/0.000125s=2.048Mbps TDM允许更高级别的复用，比如4条T1流复用为1条T2流，7条T2流复用为1条T3流（每一步复用有少量开销用于同步控制、成帧） SONET/SDH：光介质上进行同步数据传输的标准 SONET（Synchronous Optical NETwork）：同步光网络，美国ANSIS制定。 SDH（Synchronous Digital Hierarchy）：同步数字序列，国际标准组织ITU制定。 每隔125微秒发送810字节数据块，SONET是同步系统故不管是否有用该帧都被发送出去，总的传输速率为51.84Mbps。 9行，90列，有效载荷（SPE）为87列，共 87×9×8bits×8000sample/sec=50.112Mbps87×9×8bits×8000sample/sec=50.112Mbps87×9×8bits×8000sample/sec=50.112Mbps 。 SPE第一列是路径开销，因此用户数据为86列。 每帧前三列，保留用作传输系统管理信息。 前三列的前三行包含section开销。 前三列的后六行包含line开销，其中前两个字节包含了指向SPE首地址的指针。 源端正在构造SONET空帧时来了一个有效载荷数据，它可直接半途插入到当前构造的帧中，比如下图，SPE就从第1个帧的半途开始，横跨了两个帧。 对应于STS-n的光纤载波称为OC-n，其复用也是按比特进行的。 如果一个载波（比如OC-3）没有被复用，而是仅承载了来自单个源的数据，则在线路名称后面加一个字母c（表示级联），因此OC-3表示由三条独立的OC-1载波构成的一条155.52Mbps载波，而OC-3c则表示来自于单个源的155.52Mbps数据流。 波分多路复用WDM WDM，Wavelength Division Multiplexing 波长λ，c=λf 按照波长分成若干份，承载不同用户的光信号。 交换 电路交换 包交换 第三章：数据链路层 3.1 数据链路层的设计问题 无确认的无连接服务。 以太网 有确认的无连接服务。WiFi。 有确认的有连接服务。 成帧： 字节计数法：每帧开始使以一个计数字段表示该帧的总字符数。 字节填充的标志字节法： 以某些特殊字符作帧的开始/结束标志，同时增加转义环节以免该字符无法表达。 缺点：容易造成帧界混淆（故增加转义字节），依赖8位字符。 比特填充的标志比特法： 用特殊的位模式01111110作为帧标志，即一个帧的开始（前一个帧的结束） 且为了处理帧内容中出现一个和帧标志相同的位串01111110。发送方一般在5个1后插入1个0，变为01111101。接收方自动删除第5个1后的0。 优点：可传输任意比特数的帧，传输速率更高。 物理层编码违禁法： 在物理层的线路编码方法里头，有一些冗余信号是不会出现在传输数据里的，以其作帧界。 比如，在4B/5B编码中，4B被映射成5B传输，32个模式，只用到16个，剩下的可以用作帧界。 比如，曼彻斯特编码，高电位跳变到低电位表示”1”，相反表示”0”。所以有两个跳变（高-&gt;高，低-&gt;低），两个冗余的跳变是没有使用的，也可拿作帧界。好处是使用冗余信号，不会混淆也不需要填充，故传输速率高。 3.2 差错检测和纠正 码字：包含数据位和校验位的n位单元（n=m+r）。 码率：码字中不包含冗余部分所占的比例，m/n。 海明距离：两个码字中不相同的位的个数。 意义：如果两个码字的海明距离为d，则需要d个1位错误才能将一个码字转变成另一个码字。 海明码，见计组和数字逻辑。 循环冗余校验码（CRC）： 任何一个kkk位的帧，可以看做一个k−1k-1k−1次的多项式。如1011001，看做x6+x4+x3+x0x_6+x_4+x_3+x_0x6​+x4​+x3​+x0​（6阶7项多项式） 约定一个生成多项式（Generator Polynomial）：G(x)G(x)G(x)，阶数为rrr，项数为r+1r+1r+1。 现在有一个要计算CRC的mmm位帧的多项式M(x)M(x)M(x)，m&gt;rm&gt;rm&gt;r，即M(x)M(x)M(x)比G(x)G(x)G(x)长。 在M(x)M(x)M(x)后附上 rrr个0，成为 xrM(x)xrM(x)xrM(x)。 xrM(x)/G(x)=Q(x)+R(x)xrM(x)/G(x)=Q(x)+R(x)xrM(x)/G(x)=Q(x)+R(x)，其中Q(x)Q(x)Q(x)为商、R(x)R(x)R(x)为余数，则xrM(x)−R(x)xrM(x)-R(x)xrM(x)−R(x)一定能被G(x)G(x)G(x)整除。 3.3 基本数据链路层协议 3.4 滑动窗口协议 发送窗口、接收窗口 含义：允许发送的帧、允许接收的帧。 如何移动： 发送窗口：任何时候当有新的数据包从网络层到来时，它被赋予窗口的下一个最高序号，并且窗口的上边界前移一格。当收到一个确认时，窗口的下边界也前移一格。 接收窗口：任何落在窗口内的帧被放入接收方的缓冲区。当收到一个帧，而且其序号等于窗口下边界时，接收方将它传递给网络层，并将整个窗口向前移动1个位置。 回退N协议：当位于某个数据流中间的一个帧损坏或丢失，接收方丢弃所有到达的后序帧，而且针对这些丢弃的帧不返回确认。 选择重传协议：当位于某个数据流中间的一个帧损坏或丢失，接收方将收到的坏帧丢弃，但接收并缓存坏帧后面的所有好帧。当发送方超时，只重传那个最早的未被确认的帧。 第四章：介质访问控制子层 介质访问控制子层（MAC, Medium Access Control）：用来确定多路访问信道下一个使用者的协议，属于数据链路层的一个子层。 MAC子层位于数据链路层底部。 4.1 信道分配问题 4.2 多路访问协议 4.2.1 ALOHA 纯ALOHA 任何一个工作站都可以在帧生成后立即发送，并通过信号的反馈检测信道以判断是否发送成功。冲突则随机等待后重发。 即任性，想发就发。 生成k帧的概率服从泊松分布： Pr[k]=Gke−G/k!Pr[k]=G^ke^{-G}/k!Pr[k]=Gke−G/k! 例如生成0帧的概率是 Pr[0]=e−GPr[0]=e^{-G}Pr[0]=e−G 。 在2t时间内，发送成功的概率应为，2t内都不才产生新帧的概率： P0=Pr[0]×Pr[0]=e−2GP0=Pr[0]×Pr[0]=e^{-2G}P0=Pr[0]×Pr[0]=e−2G 。 将 P0=e−2GP0=e^{-2G}P0=e−2G 代入 S=G×P0S=G×P0S=G×P0 ，得 S=G×e−2GS=G×e^{-2G}S=G×e−2G 。 求导求吞吐率S的极大值： S′=e−2G−2G×e−2G=0S'=e^{-2G}-2G×e^{-2G}=0S′=e−2G−2G×e−2G=0 ，故当 G=0.5G=0.5G=0.5 时， S≈0.184S≈0.184S≈0.184 。 即，纯ALOHA信道的利用率最高为18.4%。 分槽ALOHA 把时间分成时隙（时间片），时隙 = 帧时T（较纯ALOHA降低一半） 发送帧必须在时隙的起点，所以冲突值发生在时隙的起点 冲突危险期缩短为T，一旦某个站占用某个时隙并发送成功，则在该时隙内不会出现冲突 P0=P[0]=e−GP0=P[0]=e^{-G}P0=P[0]=e−G， S=G×e−GS=G×e^{-G}S=G×e−G 在G=1时取得最大吞吐率： Smax=1e≈0.368Smax=1e≈0.368Smax=1e≈0.368 即，分隙ALOHA信道的利用率最高为36.8%。 4.2.2 载波侦听多路访问协议 载波侦听多路访问协议（CSMA，Carrier Sense Multiple Access），改进的ALOHA协议。特点：先听后发。 非坚持CSMA 概念：发送数据之前先侦听信道，若信道空闲，则发送帧；若信道忙碌，则等待一段随机时间后再侦听。 缺点：随机等待时间内介质上没有数据传送，这段时间被浪费，带来更大的延迟。 优点：更好的信道利用率。 持续式CSMA 分为：1-坚持CSMA、P-坚持CSMA P-坚持CSMA（适用于分时间槽的信道） 发送数据之前先侦听信道，若信道空闲，则以P的概率发送，以1-P的概率延迟一个时间槽发送；若信道忙碌，则等待直至信道变成空闲。如果发生冲突，等待一段随机时间后再侦听。 1-坚持CSMA 发送数据之前先侦听信道，若信道空闲，则发送帧；若信道忙碌，则等待直至信道变成空闲。如果发生冲突，等待一段随机时间后再侦听。 CSMA仍然会冲突的原因 同时侦听同时传送。 传播延迟。信号在介质传播速度是光速的65%（每微秒200米），在信号未到达接收方的时候，接收方监听信道发现空闲，随后发帧，两帧碰撞冲突。 冲突窗口 冲突危险期：一个工作站能够检测到冲突的时间最大值。 冲突窗口定义为上限：来回时间（RTT，Round Trip Time），2个帧时。 信号在信道传播速度： V=200m/usV = 200m/usV=200m/us 网卡处理帧的时间：网卡延时 tPHYt_{PHY}tPHY​ 最远的两个工作站相距： SSS 计算得到：冲突窗口 = 2t+2tPHY2t+2t_{PHY}2t+2tPHY​，其中 t=SVt=\\frac{S}{V}t=VS​ 。 倘若最远两个工作站间还有中继器，中继器处理时间：trepeatert_{repeater}trepeater​，则冲突窗口 = 2(t+tPHY+N×trepeater)2(t+t_{PHY}+N×t_{repeater})2(t+tPHY​+N×trepeater​)，其中 t=SVt=\\frac{S}{V}t=VS​ 。 如果冲突发生在最远两个工作站的正中间，那么此时检测到冲突的时间等于最远两个工作站之间的传播延迟。 带冲突检测的载波侦听多路访问协议（CSMA/CD,CSMA with Collision Detection），也是1-持续的CSMA。半双工以太网中使用。 工作原理 先听后发、边发边听。 经侦听，若介质空闲，则发送；若介质忙碌，持续侦听至空闲；发送之后，持续侦听是否碰撞冲突，若不冲突则发送成功，若冲突则随机等待后再重复侦听。 发送站感知冲突后，中断发送，之后发送一个非常简短的拥塞信号（Jam信号，是一个强化信号，广播出去通知各工作组该地方发生了碰撞）。 冲突检测和处理 冲突检测的方法：比较发出和收到的两个信号的能量与脉冲宽度变化。 冲突检测的要求： 时隙宽度 = 冲突窗口(最大冲突检测时间) ----&gt; 保证在一个时隙内能够检测到最远距离的冲突。 发送有效帧的时间 &gt;= 冲突窗口 ----&gt; 防止因为在发生冲突时，已完成短帧发送而无法知道实际上已发送失败。 4.2.3 无冲突协议 以根本不可能产生冲突的方式解决信道竞争问题。 位图协议 假定有 N 个站，每个竞争期有 N 个槽。 j 号站在 j 号槽中插入1位来声明自己有帧要发送。 经过 N 个槽后，按照数字顺序开始传送数据。 效率 低负载：每一帧的额外开销为 N 位，数据长度为 d 位，信道利用率为 d/(n+d)d/(n+d)d/(n+d) 。 高负载：若所有站在任何时候都有数据要发送，则 N 位竞争期被分摊到 N 个帧上，因此每一帧的额外开销只有1位，信道利用率为 d/(1+d)d/(1+d)d/(1+d) 。 令牌传递 令牌代表发送权限。 如果站有个等待传输的帧队列，当它接收到令牌就可以发送帧，然后再把令牌传递到下一站。 如果站没有排队的帧要传，则只把令牌传递下去。 二进制倒计数 如果一个站想要使用信道，它就以二进制位串的形式广播自己的地址，从高序的位开始。 假定所有的地址具有相同的长度。 不同站地址中相同位在同时发送时被信道布尔或在一起。 假设传输延迟可忽略。 一个站只要看到自己的地址位中的0值被改写成了1，则它必须放弃竞争。 特性：高序站的优先级比低序站的优先级高。 信道利用率 d/(d+log2N)d/(d+log_2N)d/(d+log2​N) ，如果精心设计帧格式，使得发送方的地址正好是帧内的第一个字段，信道利用率为100%。 4.2.4 有限竞争协议 低负载下采用竞争的做法而提供较短的延迟，高负载下采用无冲突技术获得良好的信道效率。 4.2.5 无线局域网协议 隐藏终端问题：由于竞争者离得太远而导致站无法检测到潜在的竞争者。 暴露终端问题：发送方监听到有一个传输正在进行，错误地得出结论不能开始将要进行的传输，而事实上将要进行的传输不会破坏正在进行的这个传输。 MACA（Multiple Access with Collision Avoidance）：冲突避免多路访问。 基本思想：发送方刺激接收方输出一个短帧，以便其附近的站能检测到这次传输，从而避免在接下去进行的（较大）数据帧传输中也发送数据。 A首先给B发送一个RTS（Request to Send）帧，包含了随后将要发送的数据帧的长度。 B用一个CTS（Clear to Send）作为应答，此CTS帧也包含了数据长度（从RTS）中复制过来。 A收到CTS之后开始传输。 4.3 以太网 经典以太网 交换式以太网 4.3.1 经典以太网物理层 可以包含多个电缆段和多个中继器，但是不允许任意两个收发器之间的距离超过2.5km，并且任意两个收发器之间经过的中继器不能超过4个。 4.3.2 经典以太网MAC子层协议 SOF（Start of Frame）：帧起始定界符。 LLC（Logical Link Control）：逻辑链路控制。 IEEE 802.3帧结构： 前导码+帧起始字段：8个Bytes，前7个Bytes都是10101010，最后一个字节10101011（最后一位是1表明帧的开始）。前导码的作用——表明一个帧的开始。 而在DIX以太网帧中，帧起始字段最后一位是0。 目的地址：6个Bytes（MAC地址，前24位为OUI表示某公司，后24位表序号）。 源地址：6个Bytes（MAC地址，全球唯一，表示方法是’-‘、’:’、’.’配合16进制）。 长度字段：表明帧长度（不包括前导码、但包括帧头帧尾），帧长度最小64字节最大1518字节。 而在DIX以太网帧中，该字段是类型字段，表明上层网络层是什么协议。 如何区分是长度字段还是类型字段：判断大小，长度字段大小&lt;=1536(0x600)， 类型字段大小&gt;1536(0x600)。 数据字段：搭载了LLC的数据，长度最小是46字节，实际内容小于46则要填充到46，如此加上帧头帧尾的18字节再能保证整个帧至少64字节。 校验字段：4个Bytes，CRC循环冗余校验，除了前导码+帧起始字段都被校验。 有效帧长度至少64Bytes ★ CDMA/CD的要求：最短帧发送时间 &gt;= 冲突窗口 2τ2τ2τ 以太网(802.3)规定，在10Mbps局域网中 时隙： 2τ=51.2μs2τ=51.2μs2τ=51.2μs 最短帧长度： 10Mbps×2τ/8=64Bytes10Mbps×2τ/8=64Bytes10Mbps×2τ/8=64Bytes 或 (51200/100ns)/8=64Bytes(51200/100ns)/8=64Bytes(51200/100ns)/8=64Bytes 为了更加容易区分有效帧和垃圾数据，以太网要求有效帧必须至少64字节。 二进制指数后退的CSMA/CD 冲突检测到后，时间被分成离散的时隙，时隙长度等于信号在介质上来回传输时间 51.2μs51.2μs51.2μs 。一般地，第 iii 次冲突后，等待的时间将从 000 ~ 2i−12^i-12i−1 之间随机选择一个数，然后等待这么多个时间槽。达到10次冲突后，随机数的选择区间被固定在最大值1023，以后不再增加。在16次冲突之后，控制器放弃努力，并给计算机返回一个失败报告。 有效性 如果只有少量站发生冲突，则可确保较低的延迟。 当许多站发生冲突时，可以保证在一个相对合理的时间间隔内解决冲突。将延迟后退的步子截断在1023​可避免延迟增长的太大。 4.3.3 以太网性能 4.3.4 交换式以太网 集线器 交换机 4.3.5 快速以太网 快速以太网（100M以太网——IEEE802.3u） 要求：跟10M以太网兼容 基本思想：保留原有的帧格式、接口和过程规则 比特时间：100ns -&gt; 10ns 电缆最大长度：2500m - &gt; 250m 编码方式 10M以太网：曼彻斯特编码 快速以太网：4B/5B（4bits数据被编码成5bits信号，易实现、电压平衡、效率80%） 4.3.6 千兆以太网 千兆以太网（G比特以太网，GE）：IEEE802.3z 兼容10/100M以太网（同时期的两个技术FDDI、ATM不兼容） 主要工作在全双工模式，若半双工，则需要CSMA/CD技术，可能带来传输距离过短的问题 -&gt; 可使用帧串、帧扩充等方法解决 编码方式：8B/10B 4.3.7 万兆以太网 4.3.8 以太网回顾 4.4 无线局域网 4.4.1 802.11体系结构和协议栈 分布式系统（distribution system） 自组织网络（ad hoc network） MAC子层决定如何分配信道，LLC子层隐藏802系列协议之间的差异，使它们在网络层看起来并无差别。 4.4.2 802.11物理层 频段：2.4GHz或5GHz 4.4.3 802.11MAC子层协议 CSMA/CA原理： 带冲突避免的载波侦听多路访问协议。 首先检测信道是否有使用，如果检测出信道空闲，则等待一段随机时间后，才送出数据。 接收端如果正确收到此帧，则经过一段时间间隔后，向发送端发送确认帧ACK。 发送端收到ACK帧，确定数据正确传输，在经历一段时间间隔后，会出现一段空闲时间。 隐藏站问题： 假设有3无线通信站ABC如下所示： A —&gt; (B &lt;— C) 其中B在C的无线电波范围内，但A不在C的无线电波范围内。此时C正在向B传送数据，而A也试图向B传送数据。此时，A不能够监听到B正在忙，而错误的认为此时可以向B传送数据了。如果A向B传送数据，则将导致错误。此即隐藏站问题。其中C是A的隐藏站。 暴露站问题： 假设有3无线通信站ABC如下所示： &lt;—–(A B) —&gt; C 其中B在A的无线电波范围内，但C不在A的无线电波范围内。此时A正在传送数据（向除B以外的某通信站），而B希望给C发送数据，但是错误地认为该传送过程将会失败（因为B会监听到一次传输，所以它会错误地认为此时不能向C发送数据）。此即暴露站问题。其中A是B的暴露站。 网络分配向量（NAV，Network Allocation Vector）：说明这个帧所属的一系列数据将传输多长时间。 4.4.4 802.11帧结构 三种类型的帧：数据帧、控制帧和管理帧。 数据帧： 第一个字段是帧控制字段，包括11个子字段：协议版本、类型（比如数据帧10、控制帧01或者管理帧00）、子类型（比如RTS和CTS）、去往DS、来自DS、更多段、重传、电源管理、更多数据、受保护的、顺序。 第二个字段是持续时间字段，它通告本帧和其确认帧将会占用信道多长时间，按微秒计时。 接下来是地址字段，包括3个地址：接收方地址、发送方地址、远程端点。 序号字段是帧的编号，可用于重复帧的检测。 数据字段包含了有效载荷，长度可以达到2312字节。 帧校验序列字段（CRC）。 管理帧的格式与数据帧的格式相同，其数据部分的的格式因子类型的不同而变。 控制帧要短一些，有帧控制字段、持续时间字段、帧校验序列字段，但只有一个地址，没有数据部分，大多数关键信息都转换成子类型字段。 4.4.5 服务 4.5 宽带无线 4.6 蓝牙 4.7 RFID 4.8 数据链路层交换 交换机在交换帧时的三种方式 存储转发：交换机把整个帧接收下来，计算校验和并检查该帧无错再做策略。（延迟大、出错率小） 直通交换（贯穿）：在接收时即读入目的端口转发出去。（延迟小、出错率高） 无分片交换：交换时，读满64字节后才转发，不会转发碎片帧，而冲突碎片往往是小于64字节的非法短帧runt。（延迟不大、出错率不高） 学习网桥： 后向学习法：学习的是源地址。 泛洪算法：对于每个发向未知目标地址的入境帧，网桥将它输出到所有的端口，但它来的那个输入端口除外。 若目的端口与源端口相同，则丢弃该帧。 若目的端口与源端口不同，则转发该帧到目的端口。 若目的端口未知，则使用泛洪法，将帧送到所有的端口，除了它入境的那个。 网桥可以进行协议转换。 生成树网桥： 生成树算法：Radia Perlman。 STP，Spanning Tree Protocol，IEEE802.1D 每一个网络有一个根网桥；每一个网桥有一个根端口；每一个网段有一个指定端口；剩下的非指定端口不被使用 生成树算法，可在有物理回路的网络中，生成逻辑无回路的生成树，但并不能保证其中的路径最优。 非指定端口虽不参与数据帧的转发，但它会侦听树的工作报文。当树上某些端口失效后，非指定端口将重新启用，形成新的生成树。 物理层：repeater中继器、hub 数据链路层：Bridge、switch 网络层：Router 传输层：Transport gateway 应用层：Application gateway 虚拟局域网 802.1Q标准 VLAN：一组逻辑上的设备或用户，不考虑地理位置。 VLAN的实现： 基于MAC地址 基于三层协议 基于端口（大多数）：在交换机内部有一张VLAN成员配置表 VLAN成员跨越不同交换机（帧标记法）： 帧在通过Trunk干线起点时打上标签，干线终点拆除标签（把这个帧涂上它所在VLAN的颜色） 第五章：网络层 5.1 网络层的设计问题 数据报网络：无连接的服务，携带目的机地址，一路查路由表。 虚电路网络：面向连接的服务，不携带目的机地址，携带路径的标号，沿途路由器有带路径标号的路由表。 标签交换：label switching 多协议标签交换：MPLS，MultiProtocol Label Switching 5.2 路由算法 非自适应算法（静态路由）和自适应算法（动态路由） 最优化原理： 如果一个路由器 J 处在路由器I到路由器K的最优路径上，那么，从路由器J到路由器K的最优路径也在同样的这条路径上。 ==汇集树（sink tree）：从所有的源到一个指定目标的最优路径的集合构成的一棵以目标节点为根的树。==汇聚树不唯一。路由算法的目的，为所有的路由器发现和使用汇聚树。 距离矢量路由（distance vector routing）选择算法 DV是分布式Bellman-Ford路由算法，常被用于小型网络，RIP是一个典型的DV。 工作原理： 维护：每个路由器维护两个向量，DiD_iDi​ , SiS_iSi​ 。 交换：在邻居路由器之间交换路由信息（矢量）。 更新：每个路由器根据收到的矢量信息更新自己的路由表。 DV 算法的特点： 优点：简单。 缺点：交换的信息太大；路由信息传播慢，可能导致路径信息不一致；收敛慢；度量计数到无穷、路径环；不适合大型的网络。 可能的问题： 路由环路 无穷计数 “好事传千里，坏事传得慢”。 解决办法：定义最大跳数、加快收敛。 收敛慢 收敛：网络查找最佳路径的过程。 收敛的加快：水平分割、毒性逆转、抑制定时器、触发更新。 因为站得不够高看得不够远，每个路由只从近邻拿信息，无法判断正确与否，可能学习、传播过时信息。全网不断传播错误、过时信息，无法稳定、收敛。 链路状态路由选择算法 为解决DV站得不够高看得不够远的问题。 算法思想： 发现邻居：向邻居发Hello包，等待回复了解它们的全球唯一名字。 设置链路成本：到它的每个邻居的成本度量。 链路带宽的反比。 延迟：发送ECHO包，等待回复，通过测量往返时间RTT，获得合理的延迟估计值。 构造链路状态包：Link State Packet，一个分组，包含发送方标识、序列号（防序列号回转问题，用32bits表示）、年龄（解决路由器崩溃和序列号损坏，每过1s，age-1，age=0则丢弃LSP）、邻居列表、到邻居的成本/度量。基于事件/时钟去触发构造。 分发链路状态包：这个分组给所有其他的路由器。 逆向路径转发：新的分组到达，若该分组是新的，被从除了来线路外的其他线路转发/泛洪出去；重复分组丢弃，过时分组拒绝。 保留区：到达的分组不先处理，而是每时钟时间处理一次，期间保留区的相同分组就会被丢弃。 计算新路由：dijkstra到每个路由器的最短路径，最短路树。 层次路由 网络规模不断增长，路由表成比例增长，消耗路由器内存。 广播路由 组播路由 选播路由 移动主机路由 自组织网络路由 5.3 拥塞控制算法 增加资源 在某些点之间使用更多的通道增加带宽（增加通路） 把流量分散到多条路径 启用空闲或备份的路由器 降低负载 拒绝为某些用户提供服务 给某些用户的服务降低等级 让用户更有预见性地安排他们的需求 网络供给 流量感知路由 准入控制 流量限制 负载脱落 随机早期检测（RED，Random Early Detection） 路由器维护一个运行队列长度的平均值。当某条链路上的平均队列长度超过某个阈值时，该链路就被认为即将拥塞，因此路由器随机丢弃一小部分数据包。当没有出现期待的回复信息时，受此影响的发送方将会发现丢包，然后传输协议将放慢速度。 丢失的数据包起到了传递抑制包的同样作用，但却是隐含的，无须路由器发送任何显式信号。 5.4 服务质量 四个主要参数：带宽、延迟、抖动和丢失。 流量整形：用户产生的流量忽大忽小，流量整形就是调节数据传输的平均速率和突发数据流，以减少突发而带来的拥塞、缓存溢出、丢包等问题。 漏桶（Leaky Bucket） 每个主机连接到网络的接口中都有一个漏桶，即一个优先长度的内部队列。 当桶中有分组的时候，输出速率是恒定的，当桶空的时候，输出速率是0。 当一个分组到达满的桶的时候，分组将被丢弃（满则溢）。 每个时钟周期tick，仅允许一个分组或固定数量的分组发送出去。 令牌桶（Token Bucket） 改进了漏桶中桶满溢出的问题，桶满丢令牌而不丢分组。 允许有上限的数据输出突发。 令牌桶拥有令牌（tokens），且以每△T秒产生一个令牌的速度往桶中输入令牌。 一个分组要发送的时候，它必要从桶中取出和获取到一个令牌。 令牌桶算法允许累积令牌，但最多可以累积 n（令牌桶的容量）个令牌。 其他：资源预留、准入控制、分组调度等。 最大突发时间的计算： 设突发时间：SSS 秒。 已知，令牌桶容量 BBB 字节，令牌到达速率 RRR 字节/秒，最大输出速率 MMM 字节/秒。 得到 B+RS=MSB+ RS = MSB+RS=MS ，即 S=B/(M−R)S = B/(M-R)S=B/(M−R) 。 5.5 网络互联 隧道技术 MTU（Path Maximum Transmission Unit）：路径最大传输单元 数据包分段 5.6 Internet的网络层 5.6.1 IPv4协议 协议版本：4位，IPv4为0100，IPv6为0110 报头长度（IHL）：4位，表示IP分组的头部有多长，数据范围为0101~1111，单位是 4 Byte，即最小 20 Byte，最大 60 Byte 区分服务（ds，Differentiated services）：8位，表示分组的重要程度优先级等，可提供一定的服务质量保证、拥塞控制 总长度：16位，表示包括头部和数据的数据报总长度，单位是 1 Byte，最大为 65535 Byte 标识：16位，标识当前的数据分组的序列号（由发送者来分配，接收方可通过该号码来进行重组） 一个未使用的位：1位 标志位：2位，决定分组是否要进行分片 DF（Don’t Fragment）：不分段 MF（More Fragment）：更多的段 分段偏移量：13位，指明了该段在当前数据报中的位置。除了数据报的最后一个段外，其他所有段的长度必须是8字节的倍数。 每个数据报最多8192个段，由此支持总长度字段限制的最大数据报。 分片后接收方可通过分片偏移进行重组。 为什么要分片？分组穿越的网络 MTU (载重力)不同。 生存时间（TTL）：8位，单位 hop，每经过一个路由器，重新封装时把TTL生存时间减1，当TTL=0时，分组被丢弃，向源发回一个超时消息。该字段可防止分组在网络中无限循环。最大的生存期为255秒。 用户协议：8位，指明它的上层传输层采用的协议，UDP (17)、TCP (6)。 报头校验和：16位，每一跳必须重新计算头校验和，因为TTL总在不断改变。 源IP地址 目的IP地址 数据报选项：可选、可变长的选项，长度不等，该字段允许主机支持不同的选项，比如安全、源路由、时间戳等。 填充：将数据报选项字段填充到32位（4字节）的整数倍 5.6.2 IP地址 前缀 一个网络对应的一块连续的IP地址空间。 子网 IP分组如何送达子网：路由器使用子网掩码来决定分组往哪个子网转发 主路由器（边界路由器）：负责和外部联系 子网掩码：了解内部网络结构的机制 点分十进制：如255.255.255.224 /网络位数+子网位数：如/27 目的网络地址 = 目的IP地址 &amp; 子网掩码 举例：131.108.2.2目的IP地址 &amp; 255.255.255.0子网掩码 = 131.108.2.0子网络地址 ABC类IP地址的子网掩码分别是：/8、/16、/24 子网位由主机位借位而来，剩下的主机位中全0为网络地址、全1为广播地址，不能标识主机。 CIDR——无类域间路由 如果路由表中有多个表项匹配 (这些表项有不同的子网掩码) ，使用子网掩码最长（子网最小）的那个表项。 分类和特殊寻址 A类地址——大型 前1×8位是网络部分，后3×8位是主机部分 第一字节的最高位固定为0，故第一字节取值范围为 0∼127 全世界的A类地址总共只有128个 每一个A类网络可容纳 2^24-2个主机 B类地址——中型 前2×8位是网络部分，后2×8位是主机部分 第一字节的最高位固定为10，故第一字节取值范围为 128∼191 全世界的B类地址总共只有 2^14 个 每一个B类网络可容纳 2^16-2 个主机 C类地址——小型 前3×8位是网络部分，后1×8位是主机部分 第一字节的最高位固定为110，故第一字节取值范围为 192∼223 全世界的C类地址总共只有 2^21 个 每一个C类网络可容纳 254 个主机 区分ABC——看第一字节值的 D类：用作组播 E类：用作一些科研 特殊的保留地址（不分配给特定主机）： 网络地址：主机部分全0的地址 广播地址：主机部分全1的地址 0.0.0.0：指该主机、该网络，路由表中默认路由的目的地址 255.255.255.255：泛洪广播地址，为防广播风暴，又退化成本地广播地址 127.0.0.0：环回地址(Lookback Network)，如127.0.0.1表示本机 169.254.0.0：非正常地址，不能与外部正常通信 NAT——网络地址转换 NAT思想： 内网使用私人地址，当内网需与外网通信，私人地址转换为合法的global的IP地址 NAT转换器（NAT Box），维护地址转换表 NAT优点： 节省了公有IP地址 提供了内部网访问外网的灵活性 有一定的保密性 NAT缺点： 违背了IP的结构模型——每个IP地址唯一地标识了一台机器 将互联网改变成了“面向连接”的网络，NAT转换器维护着连接的状态，一旦它崩溃，连接也没有了 违背了最基本的协议分层原则，IP是网络层，Port是传输层，跨层工作了 如果传输层不是采用TCP或UDP，而是采用了其它的协议，NAT将不再工作 有些应用会在payload中插入IP地址，然后接收方会提取出该IP地址并使用，但是NAT转换器对此一无所知，导致该类应用不再有效 NAT让一个IP地址可以承载61,440 （65536-4096）个私人地址（超载，PAT） ARP——地址解析协议：完成主机或者路由器从IP地址到MAC地址的映射 ARP思想： 将IP地址映射到MAC地址。 向周围广播：”我是128.1.2.7，谁知道128.1.2.15的MAC地址”。 128.1.2.15收到询问自己的ARP请求，才回复。 远程主机的MAC地址解析（跨LAN进行ARP）： 源将目的MAC地址填上默认网关的MAC 默认网关解封装后重封装时将源、目的MAC分别变为默认网关MAC、目的机MAC ARP的优化——ARP表： 动态建立、更新、维护ARP表 机器上线/配置改变时，向周围广播免费ARP（srcIP=trgtIP），告知周边的MAC地址，不期望收到应答，若意外收到应答则表明自己的IP冲突 收到源的ARP请求非目标机虽不应答，但默默记下源的MAC地址到自己的ARP表 定时删除超时ARP信息 静态配置ARP可以解决动态更新的病毒隐患 第六章：传输层 6.1 传输服务 目标：向用户提供高效的、可靠的和成本有效的数据传输服务，用于通常是应用层的进程。 传输层、网络层分层原因： 网络层运行在由承运商操作的路由器上，用户无法真正控制到网络层，只能眼睁睁看着丢包、延迟 把另一层放在网络层之上，可让用户能够控制道服务质量 传输层原语独立于网络层原语，而网络层原语会因网络的不同而不同 两层的作用范围不同 网络层负责把数据从源机送达目的机，hostToHost 传输层负责把数据送到具体的应用进程，endToEnd 数据段： TPDU（Transport Protocol Data Unit），传输层协议数据单元。是从传输实体发到对端传输实体的信息 TPDUs 被封装在分组（packet）中，由网络层交换 分组被封装在帧（frames）中，由数据链路层交换 传输层两大协议： 用户数据报协议，UDP，User Datagram Protocol 传输控制协议，TCP，Transport Control Protocol 6.2 传输协议的要素 6.2.1 寻址 端口：port 传输服务访问点：TSAP，Transport Service Access Point 网络服务访问点：NSAP，Network Serivice Access Point，IP地址是NSAP的实例。 6.2.2 连接建立 三次握手 (1)客户发送第一个报文，这是一个SYN报文，在这个报文中只有SYN标志置为1。这个报文的作用是使序号同步。 (2)服务器发送第二个报文，即SYN+ACK报文，其中SYN和ACK标志被置为1。这个报文有两个目的。首先，它是一个用来和对方进行通信的SYN报文。服务器使用这个报文同步初始序号，以便从服务器向客户发送字节。服务器还使用ACK标志确认已从客户端收到了SYN报文，同时给出期望从客户端收到的下一个序号。另外，服务器还定义了客户端要使用的接收窗口的大小。 (3)客户发送第三个报文。这仅仅是一个ACK报文。它使用ACK标志和确认号字段来确认收到了第二个报文。 6.2.3 连接释放 非对称释放 对称释放 三次挥手 (1)当客户端想关闭TCP连接时，它发送一个TCP报文，把FIN标志位设置为1。 (2)服务器端在收到这个TCP报文后，把TCP连接即将关闭的消息发送给相应的进程，并发送第二个报文——FIN+ACK报文，以证实从客户端收到了FIN报文，同时也说明，另一个方向的连接也关闭了。 (3)客户端发送最后一个报文以证实从TCP服务器收到了FIN报文。这个报文包括确认号，它等于从服务器收到的FIN报文的序号加1。 6.2.4 差错控制和流量控制 6.2.5 多路复用 6.2.6 崩溃恢复 6.3 拥塞控制 AIMD（Additive Increase Multiplicative Decrease）：加法递增乘法递减 6.4 Internet传输协议：UDP UDP数据段头——头部（8字节）+数据： 头部第1字段，源端口，16bits 头部第2字段，目的端口，16bits 头部第3字段，UDP长度，表示包括头部（8字节）和数据共多少字节，16bits 范围：8~65515 头部第4字段，校验和，可选(不选择填0)，16bits，校验头部、数据、IP伪头 IP伪头：源地址、目的地址、UDP协议号、UDP段（包括头）的字节计数。 端口Port： 16位，0~65535 &lt; 1023，知名端口，用于公共应用（保留，全局分配，用于标准服务器），IANA分配 1024-49151，非特权用户端口，注册端口，比如BT使用6881-6887 ≥ 49152，动态端口，私人端口 自由端口 free port 本地分配、动态随机端口 远程过程调用（RPC，Remote Procedure Call） RTP（Real-time Transport Protocol）：实时传输协议 RTCP（Real-time Transport Control Protocol）：实时传输控制协议 6.5 Internet传输协议：TCP 格式： head，20字节的头部（去掉可选项）。 Options，变长的数据字段/域（可是0个或更多字节）。 Data 头部第1字段，源端口，16bits。 头部第2字段，目的端口，16bits。 头部第3字段，序列号，表示一个字节的编号，32bits。 ISNs(initial sequence numbers)：初始序列号，是随机产生的。 SYN：携带了ISNs 和SYN 控制位的数据段。 头部第4字段，确认号，表示期望对方发来的字节的编号，32bits。 TCP的可靠传输保证，采用肯定确认机制和累计确认技术。 如确认号是500，表示收到了发方发送的499、498…等字节。下次我就可以发500序列号的字节过去了。 头部第5字段，TCP段头长度，单位是4字节，4bits。 下一字段是保留字段，现在逐步启用做拥塞控制。 头部第6、7、8、9、10、11字段，控制比特，URG、ACK、PSH、RST、SYN、FIN，各1bit。 URG：当紧急指针使用的时候，URG 被置为1，表明有紧急数据，必须先处理。 ACK：等于1表示确认号有效，启用了捎带确认，等于0表示确认号无效。 PSH：表示这是带有PUSH标志的数据，接收方收到这样的数据，应该立刻送到上层，而不需要缓存它。 RST：被用来重置一个已经混乱的连接。如果在连接建立阶段，就直接拒绝建立连接。 SYN：用在连接建立过程中。与ACK配合使用可以表示连接请求(SYN=1,ACK=0)或连接接收(SYN=1,ACK=1)。 FIN：被用来释放连接，表示发送方已经没有数据要传输，但可继续接收数据。 头部第12字段，窗口尺寸，告诉对方可以发送的数据字节数，即从确认字节号开始，连续发送的字节总数，16bits。 为避免接收方被大量涌入的数据所淹没，TCP实体进行了流量控制，用可变长的滑动窗口来完成，这个窗口尺寸的大小取决于接收方。 头部第13字段，校验和，16bits。 头部第14字段，紧急指针，与URG控制位配合使用，16bits。 紧急指针是一个对于当前序列号的字节偏移量，标明紧急数据从哪里开始。 Options，选项域，提供了一种增加基本头没有包含内容的方法。 TCP连接的建立 Host1发送连接请求，控制位SYN=1, ACK=0。SEQ=x，x是随机产生的初始序列号。 Host2接收后，回答，控制位SYN=1, ACK=1。SEQ=y，y是随机产生的初始序列号，ACK Number=x+1，表示对x之前的字节都确认收到。 Host1接收应答，回发最后的确认，控制位SYN=0, ACK=1。SEQ=x+1，ACK Number=y+1，表示对y之前的字节确认收到。 TCP连接的释放 任何一方没数据要发送时，都可发送一个FIN置位的TCP数据段。 当FIN被确认时，该方式的连接被关闭。 当双向连接都关闭后，连接释放。 TCP连接的释放是对称，要求两方的释放请求都被确认，而一次只能确认一个，这有一些问题，解决方案是把释放连接的决定权交给请求者： 一方发送 连接释放请求DR（Disconnect Request），并期待对方的确认ACK。 DR到达接收端，它回发ACK，并且也发送一个DR。 ACK到达发送端，连接释放；同时回发确认ACK，当这个ACK到达接收端，反方向的连接也释放。 采用定时器： 避免DR、ACK丢失而引发的问题，在任何时候发出DR的同时，都启动一个定时器。 如果一方发送了FIN置位的DR数据段出去，若在定时器超时都没收到应答，释放连接。 另一方最终也会注意到连接的对方已不在，即定时器超时后连接释放。 杀死半开放连接： 半开放连接：最初的DR及其重传都丢失了的话，发送者因超时放弃继续发送且释放连接，但另一端却不知道这些情况仍处于活跃的状态。 杀死方式：在一定时间内没有TPDUs到达则单方面自动释放；同时利用定时器，超时时自动发一个哑TPDU（dummy TPDU），避免被对方释放。 TCP传输策略： 类似LLC，TCP链路传输，采用了基本的肯定确认重传机制。 使用Window Size字段进行流量控制： 当窗口数为0时，发送者不能正常发送数据段，除非： Urgent紧急数据。比如用户想杀掉远端机器上的进程时 发送者可发送一个字节的数据段，以便让接受者再次发送(期待接收的字节号或ACK, WIN)，以免死锁 优化接收端，不要急着回复确认 接收端推迟500ms发送确认分组和窗口更新，以便可免费搭载在处理后的回显分组内（free ride便车） 优化发送端——Nagle’s Algorithm 当数据以一次一字节的速度到达的时候，只发送第一个字节，然后将后续的字节缓存起来，直到发出的字节得到确认； 将缓存起来的字节在一个数据段中发出，再继续缓存，直到发出的数据得到确认。 傻瓜窗口综合征： silly window syndrome problem 当有大块数据被传递给发送端TCP实体，但接收端的交互式应用每次只读取一个字节的时候，往返发送的有效信息大小与代价相差甚远。 解决方案——Clark解决方案 阻止接收方发送只有1个字节的窗口更新，相反，它必须等待一段时间，当有了一定数量的空间之后再告诉发送方。 接收方可以可以维护一个内部缓冲，且阻塞上层应用的READ 请求，直到它有大块的数据提供。 发送方和接收方的优化： 发送方，Nagle’s Algorithm。尽量不发送数据含量小的数据段；缓存应用层数据到一定量才发送。 接收方，Clark’s Solution。不请求对方发送短数据段(Window Size)；延迟窗口变更信息，使接收缓冲区足够大。 TCP拥塞控制 虽然网络层也管理拥塞，但大多数管理任务由TCP完成。 因为针对拥塞的真正解决方案是减慢数据率，所以TCP拥塞控制遵循分组守恒原则，即老分组离开后新分组才注入网络。 拥塞检测： Congestion Detection 所有的互联网TCP算法都假定超时是由于拥塞引起的，并通过监视超时的情况来判断是否出现问题。 拥塞控制： Congestion Control 当一个连接建立的时候，双方选择一个合适的窗口大小，接收方根据自己的缓冲区大小来指定窗口的大小。 若发送者遵循这窗口大小的限制，则接收端不会出现缓冲区溢出的问题，但可能由于网络内部的拥塞而发生问题。 拥塞的两种情形： 接收方容量不足，比如快速的网络向小容量接收方传输数据。 网络容量瓶颈，比如慢速的网络向大容量的接收方传输数据。 拥塞控制： 针对拥塞的两种情形，单独解决问题。 发送者维护两个窗口： 流量控制窗口，反映了目前接收者的处理能力（容易获取）。 拥塞窗口cwnd，反映了目前网络容量（难以获取），也就是发送端可以往网络发送的字节数。 发送数据大小 = 上述两个窗口的较小值 慢启动算法Slow Start： 获取拥塞窗口大小。 指数的增长：连接建立时，发送者用当前使用的最大数据段长度MaxSeqL初始化拥塞窗口，然后发送一个最大的数据段，若在定时器超时前得到确认，则将拥塞窗口翻倍，发送两个数据段，直到超时。 线性的增长：采用阈值参数，初始为64K，拥塞窗口增长到阈值时，就停止指数增长，按照线性增长，即每次成功的传输让拥塞窗口增加一个最大的数据段长度。 当超时发生时，阈值降为当前拥塞窗口的一半，同时将拥塞窗口重设为一个最大的数据段的长度，重新开启新一次的慢启动。 下图，一开始阈值Threshold=32k，当指数增长到阈值时改为线性增长，在第14次发送时超时，阈值设为拥塞窗口的一半20k，且发送窗口重置为一个数据段大小，重新开启新一次的慢启动。 线性增长，可将窗口尝试粒度变小，以获得更准确的拥塞窗口值。 TCP慢启动算法就是这样不断超时、不断重启，尝试出的拥塞窗口值也随之网络状况变化而变化，达到拥塞控制的目的。 快速恢复：重新慢启动时，拥塞窗口值可以不重置为一个数据段大小，而是设置为阈值大小，从这里开始直接线性增长。 TCP定时器等 TCP采用肯定确认重传技术，保证每一个字节的可靠传输。 重传定时器： retransmission timer 为了解决数据段丢失的问题，每发一个数据段都会启动一个重传定时器。 其时间设置需要良好的考量，设置过长则等待过长，设置过短引发频繁超时重传。 持续定时器： persistence timer 用来避免以下死锁deadlock发生。 接收方发送了一个窗口数为零的确认（窗口更新），告诉发送方等待。 稍后，接收方空出了缓冲，发送更新窗口的数据段，但是该分组丢失啦！ 现在，收发双方都在等待对方发送数据段过来，但永远等不到，死锁产生。 发送方在收到win=0时，启动一个持续定时器，如果定时器超时没有收到更新窗口，则发送一个探测数据段，引发对方重新发出更新窗口。 保活定时器： keep-alive timer 用来检查连接是否存活，当一个连接空闲的时间超过保活定时器的时间，该连接将被杀掉。 在关闭时刻处于TIMED WAIT状态中使用的定时器： 运行两倍的最大分组生存时间，以确保连接关闭之后，该连接上的所有分组都完全消失。 第七章：应用层 7.1 DNS 原理： 1.应用程序以域名作为参数调用解析器。 2.解析器发送UDP分组给本地DNS服务器。 3.如果待查询域名在该DNS服务器的管辖范围内或存在缓存则返回资源记录给解析器。 4.反之则本地DNS服务器向根域名服务器发送一条查询此域的迭代查询请求。 5.根域名服务器会返回所查询域的IP地址或者本地DNS服务器下一步应该向之查询的域名服务器地址。 6.本地域名服务器向正确的域名服务器查询到IP后返回给解析器。同时缓存查询过的域名服务器地址。 7.2 邮件 协议：SMTP、POP Reference 《计算机网络》第五版 严伟 潘爱民 译 tt学长的笔记：https://zhangt.top/CS/Computer-Network-Study-Notes MOOC华南理工大学《计算机网络》by 袁华：https://www.icourse163.org/learn/SCUT-1002700002?tid=1463162477#/learn/announce 2019王道考研计算机网络：https://www.bilibili.com/video/BV19E411D78Q?from=search&amp;seid=5912359002984844436","link":"/2021/06/13/CS/ComputerNetworks/"},{"title":"RocksDB Compaction源码分析","text":"RocksDB的Compaction过程整体可分为三个部分，prepare keys、process keys、write keys。 入口：db/db_impl_compaction_flush.cc中的BackgroundCompaction() Prepare keys 触发条件 RocksDB的compaction都是后台运行，通过线程BGWorkCompaction进行compaction的调度。Compaction分为两种： Manual compaction by CompactFiles() Auto compaction by BackgroundCompaction() MaybeScheduleFlushOrCompaction 1234567891011while (bg_compaction_scheduled_ &lt; bg_job_limits.max_compactions &amp;&amp; unscheduled_compactions_ &gt; 0) { CompactionArg* ca = new CompactionArg; ca-&gt;db = this; ca-&gt;prepicked_compaction = nullptr; bg_compaction_scheduled_++; //正在被调度的compaction线程数目 unscheduled_compactions_--; //待调度的线程个数，及待调度的cfd的长度 //调度BGWorkCompaction线程 env_-&gt;Schedule(&amp;DBImpl::BGWorkCompaction, ca, Env::Priority::LOW, this, &amp;DBImpl::UnscheduleCompactionCallback);} ​ 可以看到最大线程数量限制是bg_job_limits.max_compactions。 队列DBImpl::compaction_queue_ 1std::deque&lt;ColumnFamilyData*&gt; compaction_queue_; ​ 这个队列的更新是在函数SchedulePendingCompaction更新的，且unscheduled_compactions_变量是和该函数一起更新的，也就是只有设置了该变量才能够正常调度compaction后台线程。 123456void DBImpl::SchedulePendingCompaction(ColumnFamilyData* cfd) { if (!cfd-&gt;queued_for_compaction() &amp;&amp; cfd-&gt;NeedsCompaction()) { AddToCompactionQueue(cfd); ++unscheduled_compactions_; }} ​ 上面的核心函数是NeedsCompaction,通过这个函数来判断是否有sst需要被compact。 123456789101112131415161718192021bool LevelCompactionPicker::NeedsCompaction( const VersionStorageInfo* vstorage) const { if (!vstorage-&gt;ExpiredTtlFiles().empty()) { //有超时的sst(ExpiredTtlFiles) return true; } if (!vstorage-&gt;FilesMarkedForPeriodicCompaction().empty()) { return true; } if (!vstorage-&gt;BottommostFilesMarkedForCompaction().empty()) { return true; } if (!vstorage-&gt;FilesMarkedForCompaction().empty()) { return true; } for (int i = 0; i &lt;= vstorage-&gt;MaxInputLevel(); i++) { if (vstorage-&gt;CompactionScore(i) &gt;= 1) { //遍历所有的level的sst,根据score判断是否需要compact return true; } } return false;} SST文件的选择 下面这两个变量分别保存了level以及每个level所对应的score，score越高，优先级越高。 12std::vector&lt;double&gt; compaction_score_; //当前sst的scorestd::vector&lt;int&gt; compaction_level_; //当前sst需要被compact到的层level 这两个变量的更新在函数VersionStorageInfo::ComputeCompactionScore中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125void VersionStorageInfo::ComputeCompactionScore( const ImmutableOptions&amp; immutable_options, const MutableCFOptions&amp; mutable_cf_options) { for (int level = 0; level &lt;= MaxInputLevel(); level++) { double score; if (level == 0) { // We treat level-0 specially by bounding the number of files // instead of number of bytes for two reasons: // // (1) With larger write-buffer sizes, it is nice not to do too // many level-0 compactions. // // (2) The files in level-0 are merged on every read and // therefore we wish to avoid too many files when the individual // file size is small (perhaps because of a small write-buffer // setting, or very high compression ratios, or lots of // overwrites/deletions). int num_sorted_runs = 0; uint64_t total_size = 0; for (auto* f : files_[level]) { if (!f-&gt;being_compacted) { total_size += f-&gt;compensated_file_size; num_sorted_runs++; } } if (compaction_style_ == kCompactionStyleUniversal) { // For universal compaction, we use level0 score to indicate // compaction score for the whole DB. Adding other levels as if // they are L0 files. for (int i = 1; i &lt; num_levels(); i++) { // Its possible that a subset of the files in a level may be in a // compaction, due to delete triggered compaction or trivial move. // In that case, the below check may not catch a level being // compacted as it only checks the first file. The worst that can // happen is a scheduled compaction thread will find nothing to do. if (!files_[i].empty() &amp;&amp; !files_[i][0]-&gt;being_compacted) { num_sorted_runs++; } } } if (compaction_style_ == kCompactionStyleFIFO) { score = static_cast&lt;double&gt;(total_size) / mutable_cf_options.compaction_options_fifo.max_table_files_size; if (mutable_cf_options.compaction_options_fifo.allow_compaction || mutable_cf_options.compaction_options_fifo.age_for_warm &gt; 0) { // Warm tier move can happen at any time. It's too expensive to // check very file's timestamp now. For now, just trigger it // slightly more frequently than FIFO compaction so that this // happens first. score = std::max( static_cast&lt;double&gt;(num_sorted_runs) / mutable_cf_options.level0_file_num_compaction_trigger, score); } if (mutable_cf_options.ttl &gt; 0) { score = std::max( static_cast&lt;double&gt;(GetExpiredTtlFilesCount( immutable_options, mutable_cf_options, files_[level])), score); } } else { score = static_cast&lt;double&gt;(num_sorted_runs) / mutable_cf_options.level0_file_num_compaction_trigger; if (compaction_style_ == kCompactionStyleLevel &amp;&amp; num_levels() &gt; 1) { // Level-based involves L0-&gt;L0 compactions that can lead to oversized // L0 files. Take into account size as well to avoid later giant // compactions to the base level. uint64_t l0_target_size = mutable_cf_options.max_bytes_for_level_base; if (immutable_options.level_compaction_dynamic_level_bytes &amp;&amp; level_multiplier_ != 0.0) { // Prevent L0 to Lbase fanout from growing larger than // `level_multiplier_`. This prevents us from getting stuck picking // L0 forever even when it is hurting write-amp. That could happen // in dynamic level compaction's write-burst mode where the base // level's target size can grow to be enormous. l0_target_size = std::max(l0_target_size, static_cast&lt;uint64_t&gt;(level_max_bytes_[base_level_] / level_multiplier_)); } score = std::max(score, static_cast&lt;double&gt;(total_size) / l0_target_size); } } } else { // Compute the ratio of current size to size limit. uint64_t level_bytes_no_compacting = 0; for (auto f : files_[level]) { if (!f-&gt;being_compacted) { level_bytes_no_compacting += f-&gt;compensated_file_size; } } score = static_cast&lt;double&gt;(level_bytes_no_compacting) / MaxBytesForLevel(level); } compaction_level_[level] = level; compaction_score_[level] = score; } // sort all the levels based on their score. Higher scores get listed // first. Use bubble sort because the number of entries are small. for (int i = 0; i &lt; num_levels() - 2; i++) { for (int j = i + 1; j &lt; num_levels() - 1; j++) { if (compaction_score_[i] &lt; compaction_score_[j]) { double score = compaction_score_[i]; int level = compaction_level_[i]; compaction_score_[i] = compaction_score_[j]; compaction_level_[i] = compaction_level_[j]; compaction_score_[j] = score; compaction_level_[j] = level; } } } ComputeFilesMarkedForCompaction(); ComputeBottommostFilesMarkedForCompaction(); if (mutable_cf_options.ttl &gt; 0) { ComputeExpiredTtlFiles(immutable_options, mutable_cf_options.ttl); } if (mutable_cf_options.periodic_compaction_seconds &gt; 0) { ComputeFilesMarkedForPeriodicCompaction( immutable_options, mutable_cf_options.periodic_compaction_seconds); } EstimateCompactionBytesNeeded(mutable_cf_options);} compaction每一层level大小的确定 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147void VersionStorageInfo::CalculateBaseBytes(const ImmutableOptions&amp; ioptions, const MutableCFOptions&amp; options) { // Special logic to set number of sorted runs. // It is to match the previous behavior when all files are in L0. int num_l0_count = static_cast&lt;int&gt;(files_[0].size()); if (compaction_style_ == kCompactionStyleUniversal) { // For universal compaction, we use level0 score to indicate // compaction score for the whole DB. Adding other levels as if // they are L0 files. for (int i = 1; i &lt; num_levels(); i++) { if (!files_[i].empty()) { num_l0_count++; } } } set_l0_delay_trigger_count(num_l0_count); level_max_bytes_.resize(ioptions.num_levels); if (!ioptions.level_compaction_dynamic_level_bytes) { base_level_ = (ioptions.compaction_style == kCompactionStyleLevel) ? 1 : -1; // Calculate for static bytes base case for (int i = 0; i &lt; ioptions.num_levels; ++i) { if (i == 0 &amp;&amp; ioptions.compaction_style == kCompactionStyleUniversal) { level_max_bytes_[i] = options.max_bytes_for_level_base; } else if (i &gt; 1) { level_max_bytes_[i] = MultiplyCheckOverflow( MultiplyCheckOverflow(level_max_bytes_[i - 1], options.max_bytes_for_level_multiplier), options.MaxBytesMultiplerAdditional(i - 1)); } else { level_max_bytes_[i] = options.max_bytes_for_level_base; } } } else { uint64_t max_level_size = 0; int first_non_empty_level = -1; // Find size of non-L0 level of most data. // Cannot use the size of the last level because it can be empty or less // than previous levels after compaction. for (int i = 1; i &lt; num_levels_; i++) { uint64_t total_size = 0; for (const auto&amp; f : files_[i]) { total_size += f-&gt;fd.GetFileSize(); } if (total_size &gt; 0 &amp;&amp; first_non_empty_level == -1) { first_non_empty_level = i; } if (total_size &gt; max_level_size) { max_level_size = total_size; } } // Prefill every level's max bytes to disallow compaction from there. for (int i = 0; i &lt; num_levels_; i++) { level_max_bytes_[i] = std::numeric_limits&lt;uint64_t&gt;::max(); } if (max_level_size == 0) { // No data for L1 and up. L0 compacts to last level directly. // No compaction from L1+ needs to be scheduled. base_level_ = num_levels_ - 1; } else { uint64_t l0_size = 0; for (const auto&amp; f : files_[0]) { l0_size += f-&gt;fd.GetFileSize(); } uint64_t base_bytes_max = std::max(options.max_bytes_for_level_base, l0_size); uint64_t base_bytes_min = static_cast&lt;uint64_t&gt;( base_bytes_max / options.max_bytes_for_level_multiplier); // Try whether we can make last level's target size to be max_level_size uint64_t cur_level_size = max_level_size; for (int i = num_levels_ - 2; i &gt;= first_non_empty_level; i--) { //从倒数第二层level往上到first non empty level // Round up after dividing cur_level_size = static_cast&lt;uint64_t&gt;( cur_level_size / options.max_bytes_for_level_multiplier); } // Calculate base level and its size. uint64_t base_level_size; if (cur_level_size &lt;= base_bytes_min) { // Case 1. If we make target size of last level to be max_level_size, // target size of the first non-empty level would be smaller than // base_bytes_min. We set it be base_bytes_min. base_level_size = base_bytes_min + 1U; base_level_ = first_non_empty_level; ROCKS_LOG_INFO(ioptions.logger, &quot;More existing levels in DB than needed. &quot; &quot;max_bytes_for_level_multiplier may not be guaranteed.&quot;); } else { // Find base level (where L0 data is compacted to). base_level_ = first_non_empty_level; while (base_level_ &gt; 1 &amp;&amp; cur_level_size &gt; base_bytes_max) { --base_level_; cur_level_size = static_cast&lt;uint64_t&gt;( cur_level_size / options.max_bytes_for_level_multiplier); } if (cur_level_size &gt; base_bytes_max) { // Even L1 will be too large assert(base_level_ == 1); base_level_size = base_bytes_max; } else { base_level_size = cur_level_size; } } level_multiplier_ = options.max_bytes_for_level_multiplier; assert(base_level_size &gt; 0); if (l0_size &gt; base_level_size &amp;&amp; (l0_size &gt; options.max_bytes_for_level_base || static_cast&lt;int&gt;(files_[0].size() / 2) &gt;= options.level0_file_num_compaction_trigger)) { // We adjust the base level according to actual L0 size, and adjust // the level multiplier accordingly, when: // 1. the L0 size is larger than level size base, or // 2. number of L0 files reaches twice the L0-&gt;L1 compaction trigger // We don't do this otherwise to keep the LSM-tree structure stable // unless the L0 compaction is backlogged. base_level_size = l0_size; if (base_level_ == num_levels_ - 1) { level_multiplier_ = 1.0; } else { level_multiplier_ = std::pow( static_cast&lt;double&gt;(max_level_size) / static_cast&lt;double&gt;(base_level_size), 1.0 / static_cast&lt;double&gt;(num_levels_ - base_level_ - 1)); } } uint64_t level_size = base_level_size; for (int i = base_level_; i &lt; num_levels_; i++) { if (i &gt; base_level_) { level_size = MultiplyCheckOverflow(level_size, level_multiplier_); } // Don't set any level below base_bytes_max. Otherwise, the LSM can // assume an hourglass shape where L1+ sizes are smaller than L0. This // causes compaction scoring, which depends on level sizes, to favor L1+ // at the expense of L0, which may fill up and stall. level_max_bytes_[i] = std::max(level_size, base_bytes_max); } } }} static：每一层的大小都是固定的 dynamic：动态根据每一层大小进行计算 引入base level的概念，通常使用空间放大来衡量空间效率，忽略数据压缩的影响，空间放大 = size_on_file_system / size_of_user_data。 挑选参与compaction的文件 12345678910111213141516171819202122232425262728Compaction* LevelCompactionBuilder::PickCompaction() { // Pick up the first file to start compaction. It may have been extended // to a clean cut. SetupInitialFiles(); if (start_level_inputs_.empty()) { return nullptr; } assert(start_level_ &gt;= 0 &amp;&amp; output_level_ &gt;= 0); // If it is a L0 -&gt; base level compaction, we need to set up other L0 // files if needed. if (!SetupOtherL0FilesIfNeeded()) { return nullptr; } // Pick files in the output level and expand more files in the start level // if needed. if (!SetupOtherInputsIfNeeded()) { return nullptr; } // Form a compaction object containing the files we picked. Compaction* c = GetCompaction(); TEST_SYNC_POINT_CALLBACK(&quot;LevelCompactionPicker::PickCompaction:Return&quot;, c); return c;} 这里PickCompaction分别调用了三个主要的函数。 SetupInitialFiles 初始化需要compact的文件 SetupOtherL0FilesIfNeeded 如果需要的话，setup一些其他的L0文件 SetupOtherInputsIfNeeded 如果需要的话，setup一些其他的inputs 下面首先分析SetupInitialFiles。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687void LevelCompactionBuilder::SetupInitialFiles() { // Find the compactions by size on all levels. bool skipped_l0_to_base = false; for (int i = 0; i &lt; compaction_picker_-&gt;NumberLevels() - 1; i++) { start_level_score_ = vstorage_-&gt;CompactionScore(i); start_level_ = vstorage_-&gt;CompactionScoreLevel(i); assert(i == 0 || start_level_score_ &lt;= vstorage_-&gt;CompactionScore(i - 1)); if (start_level_score_ &gt;= 1) { if (skipped_l0_to_base &amp;&amp; start_level_ == vstorage_-&gt;base_level()) { // If L0-&gt;base_level compaction is pending, don't schedule further // compaction from base level. Otherwise L0-&gt;base_level compaction // may starve. continue; } output_level_ = (start_level_ == 0) ? vstorage_-&gt;base_level() : start_level_ + 1; if (PickFileToCompact()) { // found the compaction! if (start_level_ == 0) { // L0 score = `num L0 files` / `level0_file_num_compaction_trigger` compaction_reason_ = CompactionReason::kLevelL0FilesNum; } else { // L1+ score = `Level files size` / `MaxBytesForLevel` compaction_reason_ = CompactionReason::kLevelMaxLevelSize; } break; } else { // didn't find the compaction, clear the inputs start_level_inputs_.clear(); if (start_level_ == 0) { skipped_l0_to_base = true; // L0-&gt;base_level may be blocked due to ongoing L0-&gt;base_level // compactions. It may also be blocked by an ongoing compaction from // base_level downwards. // // In these cases, to reduce L0 file count and thus reduce likelihood // of write stalls, we can attempt compacting a span of files within // L0. if (PickIntraL0Compaction()) { output_level_ = 0; compaction_reason_ = CompactionReason::kLevelL0FilesNum; break; } } } } else { // Compaction scores are sorted in descending order, no further scores // will be &gt;= 1. break; } } if (!start_level_inputs_.empty()) { return; } // if we didn't find a compaction, check if there are any files marked for // compaction parent_index_ = base_index_ = -1; compaction_picker_-&gt;PickFilesMarkedForCompaction( cf_name_, vstorage_, &amp;start_level_, &amp;output_level_, &amp;start_level_inputs_); if (!start_level_inputs_.empty()) { compaction_reason_ = CompactionReason::kFilesMarkedForCompaction; return; } // Bottommost Files Compaction on deleting tombstones PickFileToCompact(vstorage_-&gt;BottommostFilesMarkedForCompaction(), false); if (!start_level_inputs_.empty()) { compaction_reason_ = CompactionReason::kBottommostFiles; return; } // TTL Compaction PickFileToCompact(vstorage_-&gt;ExpiredTtlFiles(), true); if (!start_level_inputs_.empty()) { compaction_reason_ = CompactionReason::kTtl; return; } // Periodic Compaction PickFileToCompact(vstorage_-&gt;FilesMarkedForPeriodicCompaction(), false); if (!start_level_inputs_.empty()) { compaction_reason_ = CompactionReason::kPeriodicCompaction; return; }} 首先遍历所有的level，从之前计算好的的compaction信息中得到每个level对应的score，只有当score&gt;=1才能继续进行compact的处理。 通过PickFileToCompact来选择input以及output文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273bool LevelCompactionBuilder::PickFileToCompact() { // level 0 files are overlapping. So we cannot pick more // than one concurrent compactions at this level. This // could be made better by looking at key-ranges that are // being compacted at level 0. if (start_level_ == 0 &amp;&amp; !compaction_picker_-&gt;level0_compactions_in_progress()-&gt;empty()) { TEST_SYNC_POINT(&quot;LevelCompactionPicker::PickCompactionBySize:0&quot;); return false; } start_level_inputs_.clear(); assert(start_level_ &gt;= 0); // Pick the largest file in this level that is not already // being compacted const std::vector&lt;int&gt;&amp; file_size = vstorage_-&gt;FilesByCompactionPri(start_level_); const std::vector&lt;FileMetaData*&gt;&amp; level_files = vstorage_-&gt;LevelFiles(start_level_); unsigned int cmp_idx; for (cmp_idx = vstorage_-&gt;NextCompactionIndex(start_level_); cmp_idx &lt; file_size.size(); cmp_idx++) { int index = file_size[cmp_idx]; auto* f = level_files[index]; // do not pick a file to compact if it is being compacted // from n-1 level. if (f-&gt;being_compacted) { continue; } start_level_inputs_.files.push_back(f); start_level_inputs_.level = start_level_; if (!compaction_picker_-&gt;ExpandInputsToCleanCut(cf_name_, vstorage_, &amp;start_level_inputs_) || compaction_picker_-&gt;FilesRangeOverlapWithCompaction( {start_level_inputs_}, output_level_)) { // A locked (pending compaction) input-level file was pulled in due to // user-key overlap. start_level_inputs_.clear(); continue; } // Now that input level is fully expanded, we check whether any output files // are locked due to pending compaction. // // Note we rely on ExpandInputsToCleanCut() to tell us whether any output- // level files are locked, not just the extra ones pulled in for user-key // overlap. InternalKey smallest, largest; compaction_picker_-&gt;GetRange(start_level_inputs_, &amp;smallest, &amp;largest); CompactionInputFiles output_level_inputs; output_level_inputs.level = output_level_; vstorage_-&gt;GetOverlappingInputs(output_level_, &amp;smallest, &amp;largest, &amp;output_level_inputs.files); if (!output_level_inputs.empty() &amp;&amp; !compaction_picker_-&gt;ExpandInputsToCleanCut(cf_name_, vstorage_, &amp;output_level_inputs)) { start_level_inputs_.clear(); continue; } base_index_ = index; break; } // store where to start the iteration in the next call to PickCompaction vstorage_-&gt;SetNextCompactionIndex(start_level_, cmp_idx); return start_level_inputs_.size() &gt; 0;} 首先得到当前level(start_level_)的未compacted的最大大小的文件。 通过cmp_idx索引到对应的文件。 通过ExpandInputsToCleanCut扩展当前文件的key的范围，需要满足&quot;clean cut&quot;。 通过FilesRangeOverlapWithCompaction判断是否有正在compact的out_level的文件范围和已经选择好的文件的key有overlap，如果有则跳过（clear start_level_inputs然后continue）。 最后在output_level中选择和start_level已经选择的文件的key有overlap的文件，通过ExpandInputsToCleanCut来判断output level files是否有被lock的，如果有则跳过（clear start_level_inputs然后continue）。 继续分析PickCompaction，在RocksDB中level-0比较特殊，因为只有level-0中的sst文件之间是无序的，因此接下来我们需要特殊处理level-0的情况，这个函数就是SetupOtherL0FilesIfNeeded。 1234567bool LevelCompactionBuilder::SetupOtherL0FilesIfNeeded() { if (start_level_ == 0 &amp;&amp; output_level_ != 0) { return compaction_picker_-&gt;GetOverlappingL0Files( vstorage_, &amp;start_level_inputs_, output_level_, &amp;parent_index_); } return true;} 如果调用start_level_ == 0 且 output_level_ != 0则调用GetOverlappingL0Files。 123456789101112131415161718192021222324252627bool CompactionPicker::GetOverlappingL0Files( VersionStorageInfo* vstorage, CompactionInputFiles* start_level_inputs, int output_level, int* parent_index) { // Two level 0 compaction won't run at the same time, so don't need to worry // about files on level 0 being compacted. assert(level0_compactions_in_progress()-&gt;empty()); InternalKey smallest, largest; GetRange(*start_level_inputs, &amp;smallest, &amp;largest); // Note that the next call will discard the file we placed in // c-&gt;inputs_[0] earlier and replace it with an overlapping set // which will include the picked file. start_level_inputs-&gt;files.clear(); vstorage-&gt;GetOverlappingInputs(0, &amp;smallest, &amp;largest, &amp;(start_level_inputs-&gt;files)); // If we include more L0 files in the same compaction run it can // cause the 'smallest' and 'largest' key to get extended to a // larger range. So, re-invoke GetRange to get the new key range GetRange(*start_level_inputs, &amp;smallest, &amp;largest); if (IsRangeInCompaction(vstorage, &amp;smallest, &amp;largest, output_level, parent_index)) { return false; } assert(!start_level_inputs-&gt;files.empty()); return true;} 从level-0中得到所有的重合key的文件，然后加入到start_level_inputs中。 最后调用SetupOtherInputsIfNeeded()。 123456789101112131415161718192021222324252627282930313233343536bool LevelCompactionBuilder::SetupOtherInputsIfNeeded() { // Setup input files from output level. For output to L0, we only compact // spans of files that do not interact with any pending compactions, so don't // need to consider other levels. if (output_level_ != 0) { output_level_inputs_.level = output_level_; if (!compaction_picker_-&gt;SetupOtherInputs( cf_name_, mutable_cf_options_, vstorage_, &amp;start_level_inputs_, &amp;output_level_inputs_, &amp;parent_index_, base_index_)) { return false; } compaction_inputs_.push_back(start_level_inputs_); if (!output_level_inputs_.empty()) { compaction_inputs_.push_back(output_level_inputs_); } // In some edge cases we could pick a compaction that will be compacting // a key range that overlap with another running compaction, and both // of them have the same output level. This could happen if // (1) we are running a non-exclusive manual compaction // (2) AddFile ingest a new file into the LSM tree // We need to disallow this from happening. if (compaction_picker_-&gt;FilesRangeOverlapWithCompaction(compaction_inputs_, output_level_)) { // This compaction output could potentially conflict with the output // of a currently running compaction, we cannot run it. return false; } compaction_picker_-&gt;GetGrandparents(vstorage_, start_level_inputs_, output_level_inputs_, &amp;grandparents_); } else { compaction_inputs_.push_back(start_level_inputs_); } return true;} 调用SetupOtherInputs，扩展start_level_inputs对应的output。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118// Populates the set of inputs of all other levels that overlap with the// start level.// Now we assume all levels except start level and output level are empty.// Will also attempt to expand &quot;start level&quot; if that doesn't expand// &quot;output level&quot; or cause &quot;level&quot; to include a file for compaction that has an// overlapping user-key with another file.// REQUIRES: input_level and output_level are different// REQUIRES: inputs-&gt;empty() == false// Returns false if files on parent level are currently in compaction, which// means that we can't compact thembool CompactionPicker::SetupOtherInputs( const std::string&amp; cf_name, const MutableCFOptions&amp; mutable_cf_options, VersionStorageInfo* vstorage, CompactionInputFiles* inputs, CompactionInputFiles* output_level_inputs, int* parent_index, int base_index) { assert(!inputs-&gt;empty()); assert(output_level_inputs-&gt;empty()); const int input_level = inputs-&gt;level; const int output_level = output_level_inputs-&gt;level; if (input_level == output_level) { // no possibility of conflict return true; } // For now, we only support merging two levels, start level and output level. // We need to assert other levels are empty. for (int l = input_level + 1; l &lt; output_level; l++) { assert(vstorage-&gt;NumLevelFiles(l) == 0); } InternalKey smallest, largest; // Get the range one last time. GetRange(*inputs, &amp;smallest, &amp;largest); // Populate the set of next-level files (inputs_GetOutputLevelInputs()) to // include in compaction vstorage-&gt;GetOverlappingInputs(output_level, &amp;smallest, &amp;largest, &amp;output_level_inputs-&gt;files, *parent_index, parent_index); if (AreFilesInCompaction(output_level_inputs-&gt;files)) { return false; } if (!output_level_inputs-&gt;empty()) { if (!ExpandInputsToCleanCut(cf_name, vstorage, output_level_inputs)) { return false; } } // See if we can further grow the number of inputs in &quot;level&quot; without // changing the number of &quot;level+1&quot; files we pick up. We also choose NOT // to expand if this would cause &quot;level&quot; to include some entries for some // user key, while excluding other entries for the same user key. This // can happen when one user key spans multiple files. if (!output_level_inputs-&gt;empty()) { const uint64_t limit = mutable_cf_options.max_compaction_bytes; const uint64_t output_level_inputs_size = TotalCompensatedFileSize(output_level_inputs-&gt;files); const uint64_t inputs_size = TotalCompensatedFileSize(inputs-&gt;files); bool expand_inputs = false; CompactionInputFiles expanded_inputs; expanded_inputs.level = input_level; // Get closed interval of output level InternalKey all_start, all_limit; GetRange(*inputs, *output_level_inputs, &amp;all_start, &amp;all_limit); bool try_overlapping_inputs = true; vstorage-&gt;GetOverlappingInputs(input_level, &amp;all_start, &amp;all_limit, &amp;expanded_inputs.files, base_index, nullptr); uint64_t expanded_inputs_size = TotalCompensatedFileSize(expanded_inputs.files); if (!ExpandInputsToCleanCut(cf_name, vstorage, &amp;expanded_inputs)) { try_overlapping_inputs = false; } if (try_overlapping_inputs &amp;&amp; expanded_inputs.size() &gt; inputs-&gt;size() &amp;&amp; output_level_inputs_size + expanded_inputs_size &lt; limit &amp;&amp; !AreFilesInCompaction(expanded_inputs.files)) { InternalKey new_start, new_limit; GetRange(expanded_inputs, &amp;new_start, &amp;new_limit); CompactionInputFiles expanded_output_level_inputs; expanded_output_level_inputs.level = output_level; vstorage-&gt;GetOverlappingInputs(output_level, &amp;new_start, &amp;new_limit, &amp;expanded_output_level_inputs.files, *parent_index, parent_index); assert(!expanded_output_level_inputs.empty()); if (!AreFilesInCompaction(expanded_output_level_inputs.files) &amp;&amp; ExpandInputsToCleanCut(cf_name, vstorage, &amp;expanded_output_level_inputs) &amp;&amp; expanded_output_level_inputs.size() == output_level_inputs-&gt;size()) { expand_inputs = true; } } if (!expand_inputs) { vstorage-&gt;GetCleanInputsWithinInterval(input_level, &amp;all_start, &amp;all_limit, &amp;expanded_inputs.files, base_index, nullptr); expanded_inputs_size = TotalCompensatedFileSize(expanded_inputs.files); if (expanded_inputs.size() &gt; inputs-&gt;size() &amp;&amp; output_level_inputs_size + expanded_inputs_size &lt; limit &amp;&amp; !AreFilesInCompaction(expanded_inputs.files)) { expand_inputs = true; } } if (expand_inputs) { ROCKS_LOG_INFO(ioptions_.logger, &quot;[%s] Expanding@%d %&quot; ROCKSDB_PRIszt &quot;+%&quot; ROCKSDB_PRIszt &quot;(%&quot; PRIu64 &quot;+%&quot; PRIu64 &quot; bytes) to %&quot; ROCKSDB_PRIszt &quot;+%&quot; ROCKSDB_PRIszt &quot; (%&quot; PRIu64 &quot;+%&quot; PRIu64 &quot; bytes)\\n&quot;, cf_name.c_str(), input_level, inputs-&gt;size(), output_level_inputs-&gt;size(), inputs_size, output_level_inputs_size, expanded_inputs.size(), output_level_inputs-&gt;size(), expanded_inputs_size, output_level_inputs_size); inputs-&gt;files = expanded_inputs.files; } } return true;} 将start_level_inputs和output_level_inputs加入到compaction_inputs中。 防止一些可能会出现的conflict情况，进行一些判断。 回到PickCompaction函数，最后构造一个compaction然后返回。 1234// Form a compaction object containing the files we picked.Compaction* c = GetCompaction();TEST_SYNC_POINT_CALLBACK(&quot;LevelCompactionPicker::PickCompaction:Return&quot;, c);return c; Compaction job:根据获取到数据分配compaction线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950TEST_SYNC_POINT_CALLBACK(&quot;DBImpl::BackgroundCompaction:BeforeCompaction&quot;, c-&gt;column_family_data()); int output_level __attribute__((__unused__)); output_level = c-&gt;output_level(); TEST_SYNC_POINT_CALLBACK(&quot;DBImpl::BackgroundCompaction:NonTrivial&quot;, &amp;output_level); std::vector&lt;SequenceNumber&gt; snapshot_seqs; SequenceNumber earliest_write_conflict_snapshot; SnapshotChecker* snapshot_checker; GetSnapshotContext(job_context, &amp;snapshot_seqs, &amp;earliest_write_conflict_snapshot, &amp;snapshot_checker); assert(is_snapshot_supported_ || snapshots_.empty()); CompactionJob compaction_job( job_context-&gt;job_id, c.get(), immutable_db_options_, mutable_db_options_, file_options_for_compaction_, versions_.get(), &amp;shutting_down_, preserve_deletes_seqnum_.load(), log_buffer, directories_.GetDbDir(), GetDataDir(c-&gt;column_family_data(), c-&gt;output_path_id()), GetDataDir(c-&gt;column_family_data(), 0), stats_, &amp;mutex_, &amp;error_handler_, snapshot_seqs, earliest_write_conflict_snapshot, snapshot_checker, table_cache_, &amp;event_logger_, c-&gt;mutable_cf_options()-&gt;paranoid_file_checks, c-&gt;mutable_cf_options()-&gt;report_bg_io_stats, dbname_, &amp;compaction_job_stats, thread_pri, io_tracer_, is_manual ? &amp;manual_compaction_paused_ : nullptr, is_manual ? manual_compaction-&gt;canceled : nullptr, db_id_, db_session_id_, c-&gt;column_family_data()-&gt;GetFullHistoryTsLow(), &amp;blob_callback_); compaction_job.Prepare(); NotifyOnCompactionBegin(c-&gt;column_family_data(), c.get(), status, compaction_job_stats, job_context-&gt;job_id); mutex_.Unlock(); TEST_SYNC_POINT_CALLBACK( &quot;DBImpl::BackgroundCompaction:NonTrivial:BeforeRun&quot;, nullptr); // Should handle erorr? compaction_job.Run().PermitUncheckedError(); TEST_SYNC_POINT(&quot;DBImpl::BackgroundCompaction:NonTrivial:AfterRun&quot;); mutex_.Lock(); status = compaction_job.Install(*c-&gt;mutable_cf_options()); io_s = compaction_job.io_status(); if (status.ok()) { InstallSuperVersionAndScheduleWork(c-&gt;column_family_data(), &amp;job_context-&gt;superversion_contexts[0], *c-&gt;mutable_cf_options()); } *made_progress = true; TEST_SYNC_POINT_CALLBACK(&quot;DBImpl::BackgroundCompaction:AfterCompaction&quot;, c-&gt;column_family_data()); Prepare 1234567891011121314151617181920212223242526272829303132333435363738void CompactionJob::Prepare() { AutoThreadOperationStageUpdater stage_updater( ThreadStatus::STAGE_COMPACTION_PREPARE); // Generate file_levels_ for compaction before making Iterator auto* c = compact_-&gt;compaction; assert(c-&gt;column_family_data() != nullptr); assert(c-&gt;column_family_data()-&gt;current()-&gt;storage_info()-&gt;NumLevelFiles( compact_-&gt;compaction-&gt;level()) &gt; 0); write_hint_ = c-&gt;column_family_data()-&gt;CalculateSSTWriteHint(c-&gt;output_level()); bottommost_level_ = c-&gt;bottommost_level(); if (c-&gt;ShouldFormSubcompactions()) { { StopWatch sw(db_options_.clock, stats_, SUBCOMPACTION_SETUP_TIME); GenSubcompactionBoundaries(); } assert(sizes_.size() == boundaries_.size() + 1); for (size_t i = 0; i &lt;= boundaries_.size(); i++) { Slice* start = i == 0 ? nullptr : &amp;boundaries_[i - 1]; Slice* end = i == boundaries_.size() ? nullptr : &amp;boundaries_[i]; compact_-&gt;sub_compact_states.emplace_back(c, start, end, sizes_[i], static_cast&lt;uint32_t&gt;(i)); } RecordInHistogram(stats_, NUM_SUBCOMPACTIONS_SCHEDULED, compact_-&gt;sub_compact_states.size()); } else { constexpr Slice* start = nullptr; constexpr Slice* end = nullptr; constexpr uint64_t size = 0; compact_-&gt;sub_compact_states.emplace_back(c, start, end, size, /*sub_job_id*/ 0); }} 调用GenSubcompactionBoundaries构造subcompaction。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128void CompactionJob::GenSubcompactionBoundaries() { auto* c = compact_-&gt;compaction; auto* cfd = c-&gt;column_family_data(); const Comparator* cfd_comparator = cfd-&gt;user_comparator(); std::vector&lt;Slice&gt; bounds; int start_lvl = c-&gt;start_level(); int out_lvl = c-&gt;output_level(); // Add the starting and/or ending key of certain input files as a potential // boundary for (size_t lvl_idx = 0; lvl_idx &lt; c-&gt;num_input_levels(); lvl_idx++) { int lvl = c-&gt;level(lvl_idx); if (lvl &gt;= start_lvl &amp;&amp; lvl &lt;= out_lvl) { const LevelFilesBrief* flevel = c-&gt;input_levels(lvl_idx); size_t num_files = flevel-&gt;num_files; if (num_files == 0) { continue; } if (lvl == 0) { // For level 0 add the starting and ending key of each file since the // files may have greatly differing key ranges (not range-partitioned) for (size_t i = 0; i &lt; num_files; i++) { bounds.emplace_back(flevel-&gt;files[i].smallest_key); bounds.emplace_back(flevel-&gt;files[i].largest_key); } } else { // For all other levels add the smallest/largest key in the level to // encompass the range covered by that level bounds.emplace_back(flevel-&gt;files[0].smallest_key); bounds.emplace_back(flevel-&gt;files[num_files - 1].largest_key); if (lvl == out_lvl) { // For the last level include the starting keys of all files since // the last level is the largest and probably has the widest key // range. Since it's range partitioned, the ending key of one file // and the starting key of the next are very close (or identical). for (size_t i = 1; i &lt; num_files; i++) { bounds.emplace_back(flevel-&gt;files[i].smallest_key); } } } } } std::sort(bounds.begin(), bounds.end(), [cfd_comparator](const Slice&amp; a, const Slice&amp; b) -&gt; bool { return cfd_comparator-&gt;Compare(ExtractUserKey(a), ExtractUserKey(b)) &lt; 0; }); // Remove duplicated entries from bounds bounds.erase( std::unique(bounds.begin(), bounds.end(), [cfd_comparator](const Slice&amp; a, const Slice&amp; b) -&gt; bool { return cfd_comparator-&gt;Compare(ExtractUserKey(a), ExtractUserKey(b)) == 0; }), bounds.end()); // Combine consecutive pairs of boundaries into ranges with an approximate // size of data covered by keys in that range uint64_t sum = 0; std::vector&lt;RangeWithSize&gt; ranges; // Get input version from CompactionState since it's already referenced // earlier in SetInputVersioCompaction::SetInputVersion and will not change // when db_mutex_ is released below auto* v = compact_-&gt;compaction-&gt;input_version(); for (auto it = bounds.begin();;) { const Slice a = *it; ++it; if (it == bounds.end()) { break; } const Slice b = *it; // ApproximateSize could potentially create table reader iterator to seek // to the index block and may incur I/O cost in the process. Unlock db // mutex to reduce contention db_mutex_-&gt;Unlock(); uint64_t size = versions_-&gt;ApproximateSize(SizeApproximationOptions(), v, a, b, start_lvl, out_lvl + 1, TableReaderCaller::kCompaction); db_mutex_-&gt;Lock(); ranges.emplace_back(a, b, size); sum += size; } // Group the ranges into subcompactions const double min_file_fill_percent = 4.0 / 5; int base_level = v-&gt;storage_info()-&gt;base_level(); uint64_t max_output_files = static_cast&lt;uint64_t&gt;(std::ceil( sum / min_file_fill_percent / MaxFileSizeForLevel( *(c-&gt;mutable_cf_options()), out_lvl, c-&gt;immutable_options()-&gt;compaction_style, base_level, c-&gt;immutable_options()-&gt;level_compaction_dynamic_level_bytes))); uint64_t subcompactions = std::min({static_cast&lt;uint64_t&gt;(ranges.size()), static_cast&lt;uint64_t&gt;(c-&gt;max_subcompactions()), max_output_files}); if (subcompactions &gt; 1) { double mean = sum * 1.0 / subcompactions; // Greedily add ranges to the subcompaction until the sum of the ranges' // sizes becomes &gt;= the expected mean size of a subcompaction sum = 0; for (size_t i = 0; i + 1 &lt; ranges.size(); i++) { sum += ranges[i].size; if (subcompactions == 1) { // If there's only one left to schedule then it goes to the end so no // need to put an end boundary continue; } if (sum &gt;= mean) { boundaries_.emplace_back(ExtractUserKey(ranges[i].range.limit)); sizes_.emplace_back(sum); subcompactions--; sum = 0; } } sizes_.emplace_back(sum + ranges.back().size); } else { // Only one range so its size is the total sum of sizes computed above sizes_.emplace_back(sum); }} 遍历所有的需要compact的level,然后取得每一个level的边界(最大key和最小key)加入到bounds数组之中。 然后对获取到的bounds进行排序去重。 计算理想情况下所需要的subcompactions的个数以及输出文件的个数。 最后更新boundaries_，这里会根据文件的大小，通过平均的size,把所有的range分为几份，最终这些都会保存在boundaries_中。 Run 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185Status CompactionJob::Run() { AutoThreadOperationStageUpdater stage_updater( ThreadStatus::STAGE_COMPACTION_RUN); TEST_SYNC_POINT(&quot;CompactionJob::Run():Start&quot;); log_buffer_-&gt;FlushBufferToLog(); LogCompaction(); const size_t num_threads = compact_-&gt;sub_compact_states.size(); assert(num_threads &gt; 0); const uint64_t start_micros = db_options_.clock-&gt;NowMicros(); // Launch a thread for each of subcompactions 1...num_threads-1 std::vector&lt;port::Thread&gt; thread_pool; thread_pool.reserve(num_threads - 1); for (size_t i = 1; i &lt; compact_-&gt;sub_compact_states.size(); i++) { thread_pool.emplace_back(&amp;CompactionJob::ProcessKeyValueCompaction, this, &amp;compact_-&gt;sub_compact_states[i]); } // Always schedule the first subcompaction (whether or not there are also // others) in the current thread to be efficient with resources ProcessKeyValueCompaction(&amp;compact_-&gt;sub_compact_states[0]); // Wait for all other threads (if there are any) to finish execution for (auto&amp; thread : thread_pool) { thread.join(); } compaction_stats_.micros = db_options_.clock-&gt;NowMicros() - start_micros; compaction_stats_.cpu_micros = 0; for (size_t i = 0; i &lt; compact_-&gt;sub_compact_states.size(); i++) { compaction_stats_.cpu_micros += compact_-&gt;sub_compact_states[i].compaction_job_stats.cpu_micros; } RecordTimeToHistogram(stats_, COMPACTION_TIME, compaction_stats_.micros); RecordTimeToHistogram(stats_, COMPACTION_CPU_TIME, compaction_stats_.cpu_micros); TEST_SYNC_POINT(&quot;CompactionJob::Run:BeforeVerify&quot;); // Check if any thread encountered an error during execution Status status; IOStatus io_s; bool wrote_new_blob_files = false; for (const auto&amp; state : compact_-&gt;sub_compact_states) { if (!state.status.ok()) { status = state.status; io_s = state.io_status; break; } if (!state.blob_file_additions.empty()) { wrote_new_blob_files = true; } } if (io_status_.ok()) { io_status_ = io_s; } if (status.ok()) { constexpr IODebugContext* dbg = nullptr; if (output_directory_) { io_s = output_directory_-&gt;Fsync(IOOptions(), dbg); } if (io_s.ok() &amp;&amp; wrote_new_blob_files &amp;&amp; blob_output_directory_ &amp;&amp; blob_output_directory_ != output_directory_) { io_s = blob_output_directory_-&gt;Fsync(IOOptions(), dbg); } } if (io_status_.ok()) { io_status_ = io_s; } if (status.ok()) { status = io_s; } if (status.ok()) { thread_pool.clear(); std::vector&lt;const CompactionJob::SubcompactionState::Output*&gt; files_output; for (const auto&amp; state : compact_-&gt;sub_compact_states) { for (const auto&amp; output : state.outputs) { files_output.emplace_back(&amp;output); } } ColumnFamilyData* cfd = compact_-&gt;compaction-&gt;column_family_data(); auto prefix_extractor = compact_-&gt;compaction-&gt;mutable_cf_options()-&gt;prefix_extractor.get(); std::atomic&lt;size_t&gt; next_file_idx(0); auto verify_table = [&amp;](Status&amp; output_status) { while (true) { size_t file_idx = next_file_idx.fetch_add(1); if (file_idx &gt;= files_output.size()) { break; } // Verify that the table is usable // We set for_compaction to false and don't OptimizeForCompactionTableRead // here because this is a special case after we finish the table building // No matter whether use_direct_io_for_flush_and_compaction is true, // we will regard this verification as user reads since the goal is // to cache it here for further user reads ReadOptions read_options; InternalIterator* iter = cfd-&gt;table_cache()-&gt;NewIterator( read_options, file_options_, cfd-&gt;internal_comparator(), files_output[file_idx]-&gt;meta, /*range_del_agg=*/nullptr, prefix_extractor, /*table_reader_ptr=*/nullptr, cfd-&gt;internal_stats()-&gt;GetFileReadHist( compact_-&gt;compaction-&gt;output_level()), TableReaderCaller::kCompactionRefill, /*arena=*/nullptr, /*skip_filters=*/false, compact_-&gt;compaction-&gt;output_level(), MaxFileSizeForL0MetaPin( *compact_-&gt;compaction-&gt;mutable_cf_options()), /*smallest_compaction_key=*/nullptr, /*largest_compaction_key=*/nullptr, /*allow_unprepared_value=*/false); auto s = iter-&gt;status(); if (s.ok() &amp;&amp; paranoid_file_checks_) { OutputValidator validator(cfd-&gt;internal_comparator(), /*_enable_order_check=*/true, /*_enable_hash=*/true); for (iter-&gt;SeekToFirst(); iter-&gt;Valid(); iter-&gt;Next()) { s = validator.Add(iter-&gt;key(), iter-&gt;value()); if (!s.ok()) { break; } } if (s.ok()) { s = iter-&gt;status(); } if (s.ok() &amp;&amp; !validator.CompareValidator(files_output[file_idx]-&gt;validator)) { s = Status::Corruption(&quot;Paranoid checksums do not match&quot;); } } delete iter; if (!s.ok()) { output_status = s; break; } } }; for (size_t i = 1; i &lt; compact_-&gt;sub_compact_states.size(); i++) { thread_pool.emplace_back(verify_table, std::ref(compact_-&gt;sub_compact_states[i].status)); } verify_table(compact_-&gt;sub_compact_states[0].status); for (auto&amp; thread : thread_pool) { thread.join(); } for (const auto&amp; state : compact_-&gt;sub_compact_states) { if (!state.status.ok()) { status = state.status; break; } } } TablePropertiesCollection tp; for (const auto&amp; state : compact_-&gt;sub_compact_states) { for (const auto&amp; output : state.outputs) { auto fn = TableFileName(state.compaction-&gt;immutable_options()-&gt;cf_paths, output.meta.fd.GetNumber(), output.meta.fd.GetPathId()); tp[fn] = output.table_properties; } } compact_-&gt;compaction-&gt;SetOutputTableProperties(std::move(tp)); // Finish up all book-keeping to unify the subcompaction results AggregateStatistics(); UpdateCompactionStats(); RecordCompactionIOStats(); LogFlush(db_options_.info_log); TEST_SYNC_POINT(&quot;CompactionJob::Run():End&quot;); compact_-&gt;status = status; return status;} 遍历所有的sub_compact,然后启动线程来进行对应的compact工作，最后等到所有的线程完成，然后退出。 通过ProcessKeyValueCompaction拿到的sub_compact_states进行真正的compaction处理实际的key-value数据。 Process keys 构造能够访问所有key的迭代器 首先进入到ProcessKeyValueCompaction函数中，通过之前步骤中填充的sub_compact数据取出对应的key-value数据，构造一个InternalIterator。这一部分主要做key之间的排序以及inernal key的merge操作。 1234std::unique_ptr&lt;InternalIterator&gt; raw_input( versions_-&gt;MakeInputIterator(read_options, sub_compact-&gt;compaction, &amp;range_del_agg, file_options_for_read_));InternalIterator* input = raw_input.get(); 构造的过程是通过函数MakeInputIterator进行的，我们进入到该函数，这个函数构造迭代器的逻辑同样区分level-0和level-其他。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253InternalIterator* VersionSet::MakeInputIterator( const ReadOptions&amp; read_options, const Compaction* c, RangeDelAggregator* range_del_agg, const FileOptions&amp; file_options_compactions) { auto cfd = c-&gt;column_family_data(); // Level-0 files have to be merged together. For other levels, // we will make a concatenating iterator per level. // TODO(opt): use concatenating iterator for level-0 if there is no overlap const size_t space = (c-&gt;level() == 0 ? c-&gt;input_levels(0)-&gt;num_files + c-&gt;num_input_levels() - 1 : c-&gt;num_input_levels()); InternalIterator** list = new InternalIterator* [space]; size_t num = 0; for (size_t which = 0; which &lt; c-&gt;num_input_levels(); which++) { if (c-&gt;input_levels(which)-&gt;num_files != 0) { if (c-&gt;level(which) == 0) { const LevelFilesBrief* flevel = c-&gt;input_levels(which); for (size_t i = 0; i &lt; flevel-&gt;num_files; i++) { list[num++] = cfd-&gt;table_cache()-&gt;NewIterator( read_options, file_options_compactions, cfd-&gt;internal_comparator(), *flevel-&gt;files[i].file_metadata, range_del_agg, c-&gt;mutable_cf_options()-&gt;prefix_extractor.get(), /*table_reader_ptr=*/nullptr, /*file_read_hist=*/nullptr, TableReaderCaller::kCompaction, /*arena=*/nullptr, /*skip_filters=*/false, /*level=*/static_cast&lt;int&gt;(c-&gt;level(which)), MaxFileSizeForL0MetaPin(*c-&gt;mutable_cf_options()), /*smallest_compaction_key=*/nullptr, /*largest_compaction_key=*/nullptr, /*allow_unprepared_value=*/false); } } else { // Create concatenating iterator for the files from this level list[num++] = new LevelIterator( cfd-&gt;table_cache(), read_options, file_options_compactions, cfd-&gt;internal_comparator(), c-&gt;input_levels(which), c-&gt;mutable_cf_options()-&gt;prefix_extractor.get(), /*should_sample=*/false, /*no per level latency histogram=*/nullptr, TableReaderCaller::kCompaction, /*skip_filters=*/false, /*level=*/static_cast&lt;int&gt;(c-&gt;level(which)), range_del_agg, c-&gt;boundaries(which)); } } } assert(num &lt;= space); InternalIterator* result = NewMergingIterator(&amp;c-&gt;column_family_data()-&gt;internal_comparator(), list, static_cast&lt;int&gt;(num)); delete[] list; return result;} 首先获取当前sub_compact所属的cfd。 针对level-0,为其中的每一个sst文件构建一个table_cache迭代器，放入list中。 针对其他非level-0的层，每一层直接创建一个级联的迭代器并放入list中。也就是这个迭代器从它的start就能够顺序访问到该层最后一个sst文件的最后一个key。 将所有层的迭代器添加到一个迭代器数组list中，通过NewMergingIterator迭代器维护一个底层的排序堆结构，完成所有层之间的key-value的排序。 1234567891011121314151617InternalIterator* NewMergingIterator(const InternalKeyComparator* cmp, InternalIterator** list, int n, Arena* arena, bool prefix_seek_mode) { assert(n &gt;= 0); if (n == 0) { return NewEmptyInternalIterator&lt;Slice&gt;(arena); } else if (n == 1) { return list[0]; } else { if (arena == nullptr) { return new MergingIterator(cmp, list, n, false, prefix_seek_mode); } else { auto mem = arena-&gt;AllocateAligned(sizeof(MergingIterator)); return new (mem) MergingIterator(cmp, list, n, true, prefix_seek_mode); } }} 如果list是空的，则直接返回空。 如果只有一个，那么认为这个迭代器本身就是有序的，不需要构建一个堆排序的迭代器（level-0的sst内部是有序的，之前创建的时候是为level-0每一个sst创建一个list元素；非level-0的整层都是有序的）。 如果有多个，那么直接通过MergingIterator来创建堆排序的迭代器。 12345678910111213141516171819MergingIterator(const InternalKeyComparator* comparator, InternalIterator** children, int n, bool is_arena_mode, bool prefix_seek_mode) : is_arena_mode_(is_arena_mode), comparator_(comparator), current_(nullptr), direction_(kForward), minHeap_(comparator_), prefix_seek_mode_(prefix_seek_mode), pinned_iters_mgr_(nullptr) { children_.resize(n); for (int i = 0; i &lt; n; i++) { children_[i].Set(children[i]); } for (auto&amp; child : children_) { AddToMinHeapOrCheckStatus(&amp;child); } current_ = CurrentForward(); } 通过将传入的list也就是函数中的children中的所有元素添加到一个vector中，再遍历其中的每一个key-value，通过函数 AddToMinHeapOrCheckStatus构造底层结构堆，堆中的元素顺序是由用户参数option.comparator指定，默认是BytewiseComparator支持的lexicographical order，也就是字典顺序。 12345678void MergingIterator::AddToMinHeapOrCheckStatus(IteratorWrapper* child) { if (child-&gt;Valid()) { assert(child-&gt;status().ok()); minHeap_.push(child); } else { considerStatus(child-&gt;status()); }} 通过SeekToFirst和Next指针处理元素 回到ProcessKeyValueCompaction函数,使用构造好的internalIterator再构造一个包含所有状态的CompactionIterator，直接初始化就可以，构造完成需要将CompactionIterator的内部指针放在整个迭代器最开始的部位，通过Next指针来获取下一个key-value，同时还需要需要在每次迭代器元素内部移动的时候除了调整底层堆中的字典序结构之外，还兼顾处理各个不同type的key数据，将kValueType，kTypeDeletion，kTypeSingleDeletion，kValueDeleteRange,kTypeMerge 等不同的key type处理完成。 1234567891011c_iter-&gt;SeekToFirst();......while (status.ok() &amp;&amp; !cfd-&gt;IsDropped() &amp;&amp; c_iter-&gt;Valid()) { // Invariant: c_iter.status() is guaranteed to be OK if c_iter-&gt;Valid() // returns true. const Slice&amp; key = c_iter-&gt;key(); const Slice&amp; value = c_iter-&gt;value(); ...... c_iter-&gt;Next(); ...} Write keys 这一步也在ProcessKeyValueCompaction函数中，将key-value写入SST文件中。 确认key 的valueType类型，如果是data_block或者index_block类型，则放入builder状态机中 优先创建filter_buiilder和index_builder，index builer创建成 分层格式(两层index leve, 第一层多个restart点，用来索引具体的datablock；第二层索引第一层的index block)，方便加载到内存进行二分查找，节约内存消耗，加速查找；其次再写data_block_builder 如果key的 valueType类型是 range_deletion，则加入到range_delete_block_builder之中 先将data_block builder 利用绑定的输出的文件的writer写入底层文件 将filter_block / index_builder / compress_builder/range_del_builder/properties_builder 按照对应的格式加入到 meta_data_builder之中，利用绑定ouput 文件的 writer写入底层存储 利用meta_data_handle 和 index_handle 封装footer,写入底层存储 将builder与输出文件的writer绑定 默认的blockbase table SST文件有很多不同的block，除了data block之外，其他的block都是需要先写入到一个临时的数据结构builder，然后由builder通过其绑定的output文件的writer写入到底层磁盘形成磁盘的sst文件结构。 这里的逻辑就是将builder与output文件的writer进行绑定，创建好table builder。 1234567// Open output file if necessaryif (sub_compact-&gt;builder == nullptr) { status = OpenCompactionOutputFile(sub_compact); if (!status.ok()) { break; }} 通过table_builder的状态机添加block数据 然后调用builder-&gt;Add函数构造对应的builder结构，添加的过程主要是通过拥有三个状态的状态机完成不同block的builder创建，状态机是由构造tablebuilder的时候创建的。 1234status = sub_compact-&gt;AddToBuilder(key, value);if (!status.ok()) { break;} 1234567891011Status AddToBuilder(const Slice&amp; key, const Slice&amp; value) { auto curr = current_output(); assert(builder != nullptr); assert(curr != nullptr); Status s = curr-&gt;validator.Add(key, value); if (!s.ok()) { return s; } builder-&gt;Add(key, value); return Status::OK(); } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106void BlockBasedTableBuilder::Add(const Slice&amp; key, const Slice&amp; value) { Rep* r = rep_; assert(rep_-&gt;state != Rep::State::kClosed); if (!ok()) return; ValueType value_type = ExtractValueType(key); if (IsValueType(value_type)) {#ifndef NDEBUG if (r-&gt;props.num_entries &gt; r-&gt;props.num_range_deletions) { assert(r-&gt;internal_comparator.Compare(key, Slice(r-&gt;last_key)) &gt; 0); }#endif // !NDEBUG auto should_flush = r-&gt;flush_block_policy-&gt;Update(key, value); if (should_flush) { assert(!r-&gt;data_block.empty()); r-&gt;first_key_in_next_block = &amp;key; Flush(); if (r-&gt;state == Rep::State::kBuffered) { bool exceeds_buffer_limit = (r-&gt;buffer_limit != 0 &amp;&amp; r-&gt;data_begin_offset &gt; r-&gt;buffer_limit); bool is_cache_full = false; // Increase cache reservation for the last buffered data block // only if the block is not going to be unbuffered immediately // and there exists a cache reservation manager if (!exceeds_buffer_limit &amp;&amp; r-&gt;cache_rev_mng != nullptr) { Status s = r-&gt;cache_rev_mng-&gt;UpdateCacheReservation&lt; CacheEntryRole::kCompressionDictionaryBuildingBuffer&gt;( r-&gt;data_begin_offset); is_cache_full = s.IsIncomplete(); } if (exceeds_buffer_limit || is_cache_full) { EnterUnbuffered(); } } // Add item to index block. // We do not emit the index entry for a block until we have seen the // first key for the next data block. This allows us to use shorter // keys in the index block. For example, consider a block boundary // between the keys &quot;the quick brown fox&quot; and &quot;the who&quot;. We can use // &quot;the r&quot; as the key for the index block entry since it is &gt;= all // entries in the first block and &lt; all entries in subsequent // blocks. if (ok() &amp;&amp; r-&gt;state == Rep::State::kUnbuffered) { if (r-&gt;IsParallelCompressionEnabled()) { r-&gt;pc_rep-&gt;curr_block_keys-&gt;Clear(); } else { r-&gt;index_builder-&gt;AddIndexEntry(&amp;r-&gt;last_key, &amp;key, r-&gt;pending_handle); } } } // Note: PartitionedFilterBlockBuilder requires key being added to filter // builder after being added to index builder. if (r-&gt;state == Rep::State::kUnbuffered) { if (r-&gt;IsParallelCompressionEnabled()) { r-&gt;pc_rep-&gt;curr_block_keys-&gt;PushBack(key); } else { if (r-&gt;filter_builder != nullptr) { size_t ts_sz = r-&gt;internal_comparator.user_comparator()-&gt;timestamp_size(); r-&gt;filter_builder-&gt;Add(ExtractUserKeyAndStripTimestamp(key, ts_sz)); } } } r-&gt;last_key.assign(key.data(), key.size()); r-&gt;data_block.Add(key, value); if (r-&gt;state == Rep::State::kBuffered) { // Buffered keys will be replayed from data_block_buffers during // `Finish()` once compression dictionary has been finalized. } else { if (!r-&gt;IsParallelCompressionEnabled()) { r-&gt;index_builder-&gt;OnKeyAdded(key); } } // TODO offset passed in is not accurate for parallel compression case NotifyCollectTableCollectorsOnAdd(key, value, r-&gt;get_offset(), r-&gt;table_properties_collectors, r-&gt;ioptions.logger); } else if (value_type == kTypeRangeDeletion) { r-&gt;range_del_block.Add(key, value); // TODO offset passed in is not accurate for parallel compression case NotifyCollectTableCollectorsOnAdd(key, value, r-&gt;get_offset(), r-&gt;table_properties_collectors, r-&gt;ioptions.logger); } else { assert(false); } r-&gt;props.num_entries++; r-&gt;props.raw_key_size += key.size(); r-&gt;props.raw_value_size += value.size(); if (value_type == kTypeDeletion || value_type == kTypeSingleDeletion) { r-&gt;props.num_deletions++; } else if (value_type == kTypeRangeDeletion) { r-&gt;props.num_deletions++; r-&gt;props.num_range_deletions++; } else if (value_type == kTypeMerge) { r-&gt;props.num_merge_operands++; }} kBuffered为状态机的初始状态。处于这个状态的时候，内存有较多缓存的未压缩的datablock。在该状态的过程中，通过 EnterUnbuffered 函数构造compression block，依此构建对应的index block和filterblock。最终将状态置为下一个状态的：kUnbuffered。 kUnbuffered这个状态时，compressing block已经通过之前的buffer中的data初步构造完成，且接下来将在这个状态通过 Finish 完成各个block的写入 或者通过 Abandon 丢弃当前的写入。 kClosed这个状态之前已经完成了table builder的finish或者abandon，那么接下来将析构当前的table builder。 对于第一个状态，进入下面的逻辑。如果data block能够满足flush的条件，则直接flush datablock的数据到当前bulider对应的datablock存储结构中。 123456789101112131415161718192021222324252627282930313233343536373839404142auto should_flush = r-&gt;flush_block_policy-&gt;Update(key, value); if (should_flush) { assert(!r-&gt;data_block.empty()); r-&gt;first_key_in_next_block = &amp;key; Flush(); if (r-&gt;state == Rep::State::kBuffered) { bool exceeds_buffer_limit = (r-&gt;buffer_limit != 0 &amp;&amp; r-&gt;data_begin_offset &gt; r-&gt;buffer_limit); bool is_cache_full = false; // Increase cache reservation for the last buffered data block // only if the block is not going to be unbuffered immediately // and there exists a cache reservation manager if (!exceeds_buffer_limit &amp;&amp; r-&gt;cache_rev_mng != nullptr) { Status s = r-&gt;cache_rev_mng-&gt;UpdateCacheReservation&lt; CacheEntryRole::kCompressionDictionaryBuildingBuffer&gt;( r-&gt;data_begin_offset); is_cache_full = s.IsIncomplete(); } if (exceeds_buffer_limit || is_cache_full) { EnterUnbuffered(); } } // Add item to index block. // We do not emit the index entry for a block until we have seen the // first key for the next data block. This allows us to use shorter // keys in the index block. For example, consider a block boundary // between the keys &quot;the quick brown fox&quot; and &quot;the who&quot;. We can use // &quot;the r&quot; as the key for the index block entry since it is &gt;= all // entries in the first block and &lt; all entries in subsequent // blocks. if (ok() &amp;&amp; r-&gt;state == Rep::State::kUnbuffered) { if (r-&gt;IsParallelCompressionEnabled()) { r-&gt;pc_rep-&gt;curr_block_keys-&gt;Clear(); } else { r-&gt;index_builder-&gt;AddIndexEntry(&amp;r-&gt;last_key, &amp;key, r-&gt;pending_handle); } } } EnterUnbuffered函数主要逻辑是构造compression block，如果我们开启了compression的选项则会构造。 同时依据之前flush添加到datablock中的数据来构造index block和filter block，用来索引datablock的数据。选择在这里构造的话主要还是因为flush的时候表示一个完整的datablock已经写入完成，这里需要通过一个完整的datablock数据才有必要构造一条indexblock的数据。 其中data_block_and_keys_buffers数组存放的是未经过压缩的datablock数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657for (size_t i = 0; ok() &amp;&amp; i &lt; r-&gt;data_block_buffers.size(); ++i) { if (iter == nullptr) { iter = get_iterator_for_block(i); assert(iter != nullptr); }; if (i + 1 &lt; r-&gt;data_block_buffers.size()) { next_block_iter = get_iterator_for_block(i + 1); } auto&amp; data_block = r-&gt;data_block_buffers[i]; if (r-&gt;IsParallelCompressionEnabled()) { Slice first_key_in_next_block; const Slice* first_key_in_next_block_ptr = &amp;first_key_in_next_block; if (i + 1 &lt; r-&gt;data_block_buffers.size()) { assert(next_block_iter != nullptr); first_key_in_next_block = next_block_iter-&gt;key(); } else { first_key_in_next_block_ptr = r-&gt;first_key_in_next_block; } std::vector&lt;std::string&gt; keys; for (; iter-&gt;Valid(); iter-&gt;Next()) { keys.emplace_back(iter-&gt;key().ToString()); } ParallelCompressionRep::BlockRep* block_rep = r-&gt;pc_rep-&gt;PrepareBlock( r-&gt;compression_type, first_key_in_next_block_ptr, &amp;data_block, &amp;keys); assert(block_rep != nullptr); r-&gt;pc_rep-&gt;file_size_estimator.EmitBlock(block_rep-&gt;data-&gt;size(), r-&gt;get_offset()); r-&gt;pc_rep-&gt;EmitBlock(block_rep); } else { for (; iter-&gt;Valid(); iter-&gt;Next()) { Slice key = iter-&gt;key(); if (r-&gt;filter_builder != nullptr) { size_t ts_sz = r-&gt;internal_comparator.user_comparator()-&gt;timestamp_size(); r-&gt;filter_builder-&gt;Add(ExtractUserKeyAndStripTimestamp(key, ts_sz)); } r-&gt;index_builder-&gt;OnKeyAdded(key); } WriteBlock(Slice(data_block), &amp;r-&gt;pending_handle, BlockType::kData); if (ok() &amp;&amp; i + 1 &lt; r-&gt;data_block_buffers.size()) { assert(next_block_iter != nullptr); Slice first_key_in_next_block = next_block_iter-&gt;key(); Slice* first_key_in_next_block_ptr = &amp;first_key_in_next_block; iter-&gt;SeekToLast(); std::string last_key = iter-&gt;key().ToString(); r-&gt;index_builder-&gt;AddIndexEntry(&amp;last_key, first_key_in_next_block_ptr, r-&gt;pending_handle); } } 在EnterUnbuffered函数中创建index block。 123456789101112if (table_options.index_type == BlockBasedTableOptions::kTwoLevelIndexSearch) { p_index_builder_ = PartitionedIndexBuilder::CreateIndexBuilder( &amp;internal_comparator, use_delta_encoding_for_index_values, table_options); index_builder.reset(p_index_builder_);} else { index_builder.reset(IndexBuilder::CreateIndexBuilder( table_options.index_type, &amp;internal_comparator, &amp;this-&gt;internal_prefix_transform, use_delta_encoding_for_index_values, table_options));} 回到ProcessKeyValueCompaction中的while循环中，不断遍历迭代器中的key，将其添加到对应的datablock，并完善indeblock和filter block，以及compression block。 通过构建的meta_index_builder和Footer完成数据的固化 接下来将通过FinishCompactionOutputFil对之前添加的builder数据进行整合，处理一些delete range的block以及更新当前compaction的边界。 这个函数调用是当之前累计的builder中block数据的大小达到可以写入的sst文件本身的大小max_output_file_size，会触发当前函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Close output file if it is big enough. Two possibilities determine it's // time to close it: (1) the current key should be this file's last key, (2) // the next key should not be in this file. // // TODO(aekmekji): determine if file should be closed earlier than this // during subcompactions (i.e. if output size, estimated by input size, is // going to be 1.2MB and max_output_file_size = 1MB, prefer to have 0.6MB // and 0.6MB instead of 1MB and 0.2MB) bool output_file_ended = false; if (sub_compact-&gt;compaction-&gt;output_level() != 0 &amp;&amp; sub_compact-&gt;current_output_file_size &gt;= sub_compact-&gt;compaction-&gt;max_output_file_size()) { // (1) this key terminates the file. For historical reasons, the iterator // status before advancing will be given to FinishCompactionOutputFile(). output_file_ended = true; } TEST_SYNC_POINT_CALLBACK( &quot;CompactionJob::Run():PausingManualCompaction:2&quot;, reinterpret_cast&lt;void*&gt;( const_cast&lt;std::atomic&lt;int&gt;*&gt;(manual_compaction_paused_))); if (partitioner.get()) { last_key_for_partitioner.assign(c_iter-&gt;user_key().data_, c_iter-&gt;user_key().size_); } c_iter-&gt;Next(); if (c_iter-&gt;status().IsManualCompactionPaused()) { break; } if (!output_file_ended &amp;&amp; c_iter-&gt;Valid()) { if (((partitioner.get() &amp;&amp; partitioner-&gt;ShouldPartition(PartitionerRequest( last_key_for_partitioner, c_iter-&gt;user_key(), sub_compact-&gt;current_output_file_size)) == kRequired) || (sub_compact-&gt;compaction-&gt;output_level() != 0 &amp;&amp; sub_compact-&gt;ShouldStopBefore( c_iter-&gt;key(), sub_compact-&gt;current_output_file_size))) &amp;&amp; sub_compact-&gt;builder != nullptr) { // (2) this key belongs to the next file. For historical reasons, the // iterator status after advancing will be given to // FinishCompactionOutputFile(). output_file_ended = true; } } if (output_file_ended) { const Slice* next_key = nullptr; if (c_iter-&gt;Valid()) { next_key = &amp;c_iter-&gt;key(); } CompactionIterationStats range_del_out_stats; status = FinishCompactionOutputFile(input-&gt;status(), sub_compact, &amp;range_del_agg, &amp;range_del_out_stats, next_key); RecordDroppedKeys(range_del_out_stats, &amp;sub_compact-&gt;compaction_job_stats); } FinishCompactionOutputFile函数内部最终调用s=sub_compact-&gt;builder-&gt;Finish()完成所有数据的固化写入。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354Status BlockBasedTableBuilder::Finish() { Rep* r = rep_; assert(r-&gt;state != Rep::State::kClosed); bool empty_data_block = r-&gt;data_block.empty(); r-&gt;first_key_in_next_block = nullptr; Flush(); if (r-&gt;state == Rep::State::kBuffered) { EnterUnbuffered(); } if (r-&gt;IsParallelCompressionEnabled()) { StopParallelCompression();#ifndef NDEBUG for (const auto&amp; br : r-&gt;pc_rep-&gt;block_rep_buf) { assert(br.status.ok()); }#endif // !NDEBUG } else { // To make sure properties block is able to keep the accurate size of index // block, we will finish writing all index entries first. if (ok() &amp;&amp; !empty_data_block) { r-&gt;index_builder-&gt;AddIndexEntry( &amp;r-&gt;last_key, nullptr /* no next data block */, r-&gt;pending_handle); } } // Write meta blocks, metaindex block and footer in the following order. // 1. [meta block: filter] // 2. [meta block: index] // 3. [meta block: compression dictionary] // 4. [meta block: range deletion tombstone] // 5. [meta block: properties] // 6. [metaindex block] // 7. Footer BlockHandle metaindex_block_handle, index_block_handle; MetaIndexBuilder meta_index_builder; WriteFilterBlock(&amp;meta_index_builder); WriteIndexBlock(&amp;meta_index_builder, &amp;index_block_handle); WriteCompressionDictBlock(&amp;meta_index_builder); WriteRangeDelBlock(&amp;meta_index_builder); WritePropertiesBlock(&amp;meta_index_builder); if (ok()) { // flush the meta index block WriteRawBlock(meta_index_builder.Finish(), kNoCompression, &amp;metaindex_block_handle, BlockType::kMetaIndex); } if (ok()) { WriteFooter(metaindex_block_handle, index_block_handle); } r-&gt;state = Rep::State::kClosed; r-&gt;SetStatus(r-&gt;CopyIOStatus()); Status ret_status = r-&gt;CopyStatus(); assert(!ret_status.ok() || io_status().ok()); return ret_status;} Compaction参数设置 参数 说明 默认值 write_buffer_size 限定Memtable的大小 64MB level0_file_num_compaction_trigger 限定Level 0层的文件数量 4 target_file_size_base 每一层单个目标文件的大小 64MB target_file_size_multiplier 每一层单个目标文件的乘法因子 1 max_bytes_for_level_base 每一层所有文件的大小 256MB max_bytes_for_level_multiplier 每一层所有文件的乘法因子 10 level_compaction_dynamic_level_bytes 是否将Compact的策略改为层级从下往上应用 False num_levels LSM的层级数量 7 参数target_file_size_base和target_file_size_multiplier用来限定Compact之后的每一层的单个文件大小。target_file_size_base是Level-1中每个文件的大小，Level N层可以用target_file_size_base * target_file_size_multiplier ^ (L -1) 计算。target_file_size_base 默认为64MB，target_file_size_multiplier默认为1。 参数max_bytes_for_level_base和max_bytes_for_level_multiplier用来限定每一层所有文件的限定大小。 max_bytes_for_level_base是Level-1层的所有文件的限定大小。Level N层的所有文件的限定大小可以用 (max_bytes_for_level_base) * (max_bytes_for_level_multiplier ^ (L-1))计算。max_bytes_for_level_base的默认为256MB，max_bytes_for_level_multiplier默认为10。 参数level_compaction_dynamic_level_bytes用来指示Compact的策略改为层级从下往上应用。Target_Size(Ln-1) = Target_Size(Ln) / max_bytes_for_level_multiplier来限定大小：假如 max_bytes_for_level_base是 1GB, num_levels设为6。最底层的实际容量是276GB, 所以L1-L6层的大小分别是 0, 0, 0.276GB, 2.76GB, 27.6GB and 276GB。 MutableDBOptions 123456789101112131415161718192021222324252627struct MutableDBOptions { static const char* kName() { return &quot;MutableDBOptions&quot;; } MutableDBOptions(); explicit MutableDBOptions(const MutableDBOptions&amp; options) = default; explicit MutableDBOptions(const DBOptions&amp; options); void Dump(Logger* log) const; int max_background_jobs; int base_background_compactions; int max_background_compactions; uint32_t max_subcompactions; bool avoid_flush_during_shutdown; size_t writable_file_max_buffer_size; uint64_t delayed_write_rate; uint64_t max_total_wal_size; uint64_t delete_obsolete_files_period_micros; unsigned int stats_dump_period_sec; unsigned int stats_persist_period_sec; size_t stats_history_buffer_size; int max_open_files; uint64_t bytes_per_sync; uint64_t wal_bytes_per_sync; bool strict_bytes_per_sync; size_t compaction_readahead_size; int max_background_flushes;}; mutable_cf_options_ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253explicit MutableCFOptions(const ColumnFamilyOptions&amp; options) : write_buffer_size(options.write_buffer_size), max_write_buffer_number(options.max_write_buffer_number), arena_block_size(options.arena_block_size), memtable_prefix_bloom_size_ratio( options.memtable_prefix_bloom_size_ratio), memtable_whole_key_filtering(options.memtable_whole_key_filtering), memtable_huge_page_size(options.memtable_huge_page_size), max_successive_merges(options.max_successive_merges), inplace_update_num_locks(options.inplace_update_num_locks), prefix_extractor(options.prefix_extractor), disable_auto_compactions(options.disable_auto_compactions), soft_pending_compaction_bytes_limit( options.soft_pending_compaction_bytes_limit), hard_pending_compaction_bytes_limit( options.hard_pending_compaction_bytes_limit), level0_file_num_compaction_trigger( options.level0_file_num_compaction_trigger), level0_slowdown_writes_trigger(options.level0_slowdown_writes_trigger), level0_stop_writes_trigger(options.level0_stop_writes_trigger), max_compaction_bytes(options.max_compaction_bytes), target_file_size_base(options.target_file_size_base), target_file_size_multiplier(options.target_file_size_multiplier), max_bytes_for_level_base(options.max_bytes_for_level_base), max_bytes_for_level_multiplier(options.max_bytes_for_level_multiplier), ttl(options.ttl), periodic_compaction_seconds(options.periodic_compaction_seconds), max_bytes_for_level_multiplier_additional( options.max_bytes_for_level_multiplier_additional), compaction_options_fifo(options.compaction_options_fifo), compaction_options_universal(options.compaction_options_universal), enable_blob_files(options.enable_blob_files), min_blob_size(options.min_blob_size), blob_file_size(options.blob_file_size), blob_compression_type(options.blob_compression_type), enable_blob_garbage_collection(options.enable_blob_garbage_collection), blob_garbage_collection_age_cutoff( options.blob_garbage_collection_age_cutoff), max_sequential_skip_in_iterations( options.max_sequential_skip_in_iterations), check_flush_compaction_key_order( options.check_flush_compaction_key_order), paranoid_file_checks(options.paranoid_file_checks), report_bg_io_stats(options.report_bg_io_stats), compression(options.compression), bottommost_compression(options.bottommost_compression), compression_opts(options.compression_opts), bottommost_compression_opts(options.bottommost_compression_opts), bottommost_temperature(options.bottommost_temperature), sample_for_compression( options.sample_for_compression) { // TODO: is 0 fine here? RefreshDerivedOptions(options.num_levels, options.compaction_style); } Some Concepts Slice is a simple structure containing a pointer into some external storage and a size. parents &amp;&amp; grandparents: parent=level+1 grandparent==level+2 column family(cfd) compaction filter compression sst file maneger(sfm) background(bg) Reference RocksDB Compaction Wiki Rocksdb Compaction 源码详解（一）：SST文件详细格式源码解析 Rocksdb Compaction源码详解（二）：Compaction 完整实现过程 概览 Dynamic Level Size for Level-Based Compaction 通过base level减少space amplification RocksDB的Compact compaction_pri compaction filter","link":"/2021/09/24/Embedded/rocksdb-compaction/"}],"tags":[{"name":"RocksDB","slug":"RocksDB","link":"/tags/RocksDB/"},{"name":"db_bench","slug":"db-bench","link":"/tags/db-bench/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"cpp","slug":"cpp","link":"/tags/cpp/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"buffer pool","slug":"buffer-pool","link":"/tags/buffer-pool/"},{"name":"recursion","slug":"recursion","link":"/tags/recursion/"},{"name":"ffmpeg","slug":"ffmpeg","link":"/tags/ffmpeg/"},{"name":"sort","slug":"sort","link":"/tags/sort/"},{"name":"array","slug":"array","link":"/tags/array/"},{"name":"queue","slug":"queue","link":"/tags/queue/"},{"name":"heap","slug":"heap","link":"/tags/heap/"},{"name":"graph","slug":"graph","link":"/tags/graph/"},{"name":"list","slug":"list","link":"/tags/list/"},{"name":"indexed binary search tree","slug":"indexed-binary-search-tree","link":"/tags/indexed-binary-search-tree/"},{"name":"stack","slug":"stack","link":"/tags/stack/"},{"name":"hash","slug":"hash","link":"/tags/hash/"},{"name":"binary tree","slug":"binary-tree","link":"/tags/binary-tree/"},{"name":"compression","slug":"compression","link":"/tags/compression/"},{"name":"sparse matrix","slug":"sparse-matrix","link":"/tags/sparse-matrix/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"compaction","slug":"compaction","link":"/tags/compaction/"}],"categories":[{"name":"Embedded","slug":"Embedded","link":"/categories/Embedded/"},{"name":"Configuration","slug":"Configuration","link":"/categories/Configuration/"},{"name":"Tricks","slug":"Tricks","link":"/categories/Tricks/"},{"name":"KV store","slug":"Embedded/KV-store","link":"/categories/Embedded/KV-store/"},{"name":"Computer Science","slug":"Computer-Science","link":"/categories/Computer-Science/"},{"name":"Tools","slug":"Tools","link":"/categories/Tools/"},{"name":"Data Structures","slug":"Computer-Science/Data-Structures","link":"/categories/Computer-Science/Data-Structures/"},{"name":"Secret","slug":"Secret","link":"/categories/Secret/"},{"name":"Computer Networks","slug":"Computer-Science/Computer-Networks","link":"/categories/Computer-Science/Computer-Networks/"}]}